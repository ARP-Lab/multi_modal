{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings(Text, Audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arplab/project/paradeigma/multi_modal/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, Data2VecAudioModel\n",
    "from datasets import load_dataset, Dataset, Audio, Features\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/home/arplab/project/paradeigma/multi_modal/model/data/paradeigma_KEMDY20_annotation_nonmissing.pkl', 'rb') as f:\n",
    "    annotation_20_nonmissing = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment ID</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>emotion_vector</th>\n",
       "      <th>valence_vector</th>\n",
       "      <th>arousal_vector</th>\n",
       "      <th>EDA</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>EDA length</th>\n",
       "      <th>TEMP length</th>\n",
       "      <th>Scaled EDA</th>\n",
       "      <th>Scaled TEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sess01_script01_User002M_001</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[10, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 6, 4, 0]</td>\n",
       "      <td>[0, 1, 9, 0, 0]</td>\n",
       "      <td>[-0.06791500000000017, -0.110201, -0.025627999...</td>\n",
       "      <td>[34.81, 34.81, 34.81, 34.79, 34.79, 34.79, 34....</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>[-0.3956120608509403, -0.6460741139849967, -0....</td>\n",
       "      <td>[-0.5852354223355396, -0.5852354223355396, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sess01_script01_User002M_002</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[10, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 9, 1, 0]</td>\n",
       "      <td>[0, 1, 9, 0, 0]</td>\n",
       "      <td>[0.006407000000000274, -0.021784000000000248, ...</td>\n",
       "      <td>[34.79, 34.79, 34.79, 34.77, 34.77, 34.77, 34....</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>[-0.12237588402818134, -0.09202025752503212, 0...</td>\n",
       "      <td>[-0.7735061037287296, -0.7735061037287296, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sess01_script01_User002M_003</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[10, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 9, 1, 0]</td>\n",
       "      <td>[0, 0, 10, 0, 0]</td>\n",
       "      <td>[0.07944700000000005, 0.05125599999999997, 0.0...</td>\n",
       "      <td>[34.75, 34.75, 34.75, 34.75, 34.79, 34.79, 34....</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>[0.27229464490531313, 0.1280920921549497, 0.15...</td>\n",
       "      <td>[-1.1500474665150429, -1.1500474665150429, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sess01_script01_User002M_004</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>[9, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 3, 7, 0]</td>\n",
       "      <td>[0, 0, 9, 1, 0]</td>\n",
       "      <td>[0.0038439999999999586, -0.03331699999999982, ...</td>\n",
       "      <td>[34.77, 34.77, 34.77, 34.77, 34.77, 34.77, 34....</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>[-1.6858831480351115, -0.8661805406159092, -0....</td>\n",
       "      <td>[-0.9617767851218528, -0.9617767851218528, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sess01_script01_User001F_001</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>[6, 4, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 3, 6, 1]</td>\n",
       "      <td>[0, 2, 8, 0, 0]</td>\n",
       "      <td>[0.1241910000000006, 0.09474499999999964, 0.03...</td>\n",
       "      <td>[34.55, 34.55, 34.55, 34.55, 34.55, 34.55, 34....</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>[1.8771197424131327, 1.4195480026451441, 0.544...</td>\n",
       "      <td>[-2.4621880639731812, -2.4621880639731812, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12710</th>\n",
       "      <td>Sess40_script06_User079F_043</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>[10, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 10, 0, 0]</td>\n",
       "      <td>[0, 0, 5, 5, 0]</td>\n",
       "      <td>[-0.023063999999999973, -0.02050200000000002, ...</td>\n",
       "      <td>[35.07, 35.07, 35.07, 35.07, 35.05, 35.05, 35....</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>[-0.5026723961033952, 0.31424983410693796, -0....</td>\n",
       "      <td>[1.3222897297499479, 1.3222897297499479, 1.322...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12711</th>\n",
       "      <td>Sess40_script06_User079F_044</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>[10, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 9, 0, 0]</td>\n",
       "      <td>[0, 1, 7, 2, 0]</td>\n",
       "      <td>[-0.0064070000000000515, -0.005125000000000046...</td>\n",
       "      <td>[35.05, 35.05, 35.07, 35.07, 35.07, 35.07, 35....</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[-0.09417143502076045, -0.29842191556206893, -...</td>\n",
       "      <td>[0.8683417878619597, 0.8683417878619597, 1.322...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12712</th>\n",
       "      <td>Sess40_script06_User079F_045</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>[9, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[0, 4, 6, 0, 0]</td>\n",
       "      <td>[0, 0, 4, 6, 0]</td>\n",
       "      <td>[-0.007688000000000028, -0.002561999999999953,...</td>\n",
       "      <td>[35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35....</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.8683417878619597, 0.8683417878619597, 0.868...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12713</th>\n",
       "      <td>Sess40_script06_User079F_046</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>[8, 0, 1, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 3, 7, 0, 0]</td>\n",
       "      <td>[0, 0, 7, 3, 0]</td>\n",
       "      <td>[-0.0064069999999999405, -0.003844000000000069...</td>\n",
       "      <td>[35.05, 35.07, 35.07, 35.07, 35.07, 35.07, 35....</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.8683417878619597, 1.3222897297499479, 1.322...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12714</th>\n",
       "      <td>Sess40_script06_User079F_047</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[9, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[0, 1, 9, 0, 0]</td>\n",
       "      <td>[0, 0, 6, 4, 0]</td>\n",
       "      <td>[-0.002562999999999982, 0.0012819999999998943,...</td>\n",
       "      <td>[35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1.3222897297499479, 1.3222897297499479, 1.322...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12715 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Segment ID  Emotion  Valence  Arousal  \\\n",
       "0      Sess01_script01_User002M_001  neutral      3.4      2.9   \n",
       "1      Sess01_script01_User002M_002  neutral      3.1      2.9   \n",
       "2      Sess01_script01_User002M_003  neutral      3.1      3.0   \n",
       "3      Sess01_script01_User002M_004  neutral      3.7      3.1   \n",
       "4      Sess01_script01_User001F_001  neutral      3.8      2.8   \n",
       "...                             ...      ...      ...      ...   \n",
       "12710  Sess40_script06_User079F_043  neutral      3.0      3.5   \n",
       "12711  Sess40_script06_User079F_044  neutral      2.9      3.1   \n",
       "12712  Sess40_script06_User079F_045  neutral      2.6      3.6   \n",
       "12713  Sess40_script06_User079F_046  neutral      2.7      3.3   \n",
       "12714  Sess40_script06_User079F_047  neutral      2.9      3.4   \n",
       "\n",
       "               emotion_vector    valence_vector    arousal_vector  \\\n",
       "0      [10, 0, 0, 0, 0, 0, 0]   [0, 0, 6, 4, 0]   [0, 1, 9, 0, 0]   \n",
       "1      [10, 0, 0, 0, 0, 0, 0]   [0, 0, 9, 1, 0]   [0, 1, 9, 0, 0]   \n",
       "2      [10, 0, 0, 0, 0, 0, 0]   [0, 0, 9, 1, 0]  [0, 0, 10, 0, 0]   \n",
       "3       [9, 1, 0, 0, 0, 0, 0]   [0, 0, 3, 7, 0]   [0, 0, 9, 1, 0]   \n",
       "4       [6, 4, 0, 0, 0, 0, 0]   [0, 0, 3, 6, 1]   [0, 2, 8, 0, 0]   \n",
       "...                       ...               ...               ...   \n",
       "12710  [10, 0, 0, 0, 0, 0, 0]  [0, 0, 10, 0, 0]   [0, 0, 5, 5, 0]   \n",
       "12711  [10, 0, 0, 0, 0, 0, 0]   [0, 1, 9, 0, 0]   [0, 1, 7, 2, 0]   \n",
       "12712   [9, 0, 0, 0, 0, 0, 1]   [0, 4, 6, 0, 0]   [0, 0, 4, 6, 0]   \n",
       "12713   [8, 0, 1, 1, 0, 0, 0]   [0, 3, 7, 0, 0]   [0, 0, 7, 3, 0]   \n",
       "12714   [9, 0, 0, 1, 0, 0, 0]   [0, 1, 9, 0, 0]   [0, 0, 6, 4, 0]   \n",
       "\n",
       "                                                     EDA  \\\n",
       "0      [-0.06791500000000017, -0.110201, -0.025627999...   \n",
       "1      [0.006407000000000274, -0.021784000000000248, ...   \n",
       "2      [0.07944700000000005, 0.05125599999999997, 0.0...   \n",
       "3      [0.0038439999999999586, -0.03331699999999982, ...   \n",
       "4      [0.1241910000000006, 0.09474499999999964, 0.03...   \n",
       "...                                                  ...   \n",
       "12710  [-0.023063999999999973, -0.02050200000000002, ...   \n",
       "12711  [-0.0064070000000000515, -0.005125000000000046...   \n",
       "12712  [-0.007688000000000028, -0.002561999999999953,...   \n",
       "12713  [-0.0064069999999999405, -0.003844000000000069...   \n",
       "12714  [-0.002562999999999982, 0.0012819999999998943,...   \n",
       "\n",
       "                                                    TEMP  EDA length  \\\n",
       "0      [34.81, 34.81, 34.81, 34.79, 34.79, 34.79, 34....          32   \n",
       "1      [34.79, 34.79, 34.79, 34.77, 34.77, 34.77, 34....          47   \n",
       "2      [34.75, 34.75, 34.75, 34.75, 34.79, 34.79, 34....          33   \n",
       "3      [34.77, 34.77, 34.77, 34.77, 34.77, 34.77, 34....          45   \n",
       "4      [34.55, 34.55, 34.55, 34.55, 34.55, 34.55, 34....           9   \n",
       "...                                                  ...         ...   \n",
       "12710  [35.07, 35.07, 35.07, 35.07, 35.05, 35.05, 35....          22   \n",
       "12711  [35.05, 35.05, 35.07, 35.07, 35.07, 35.07, 35....          10   \n",
       "12712  [35.05, 35.05, 35.05, 35.05, 35.05, 35.05, 35....          27   \n",
       "12713  [35.05, 35.07, 35.07, 35.07, 35.07, 35.07, 35....          11   \n",
       "12714  [35.07, 35.07, 35.07, 35.07, 35.07, 35.07, 35....           8   \n",
       "\n",
       "       TEMP length                                         Scaled EDA  \\\n",
       "0               32  [-0.3956120608509403, -0.6460741139849967, -0....   \n",
       "1               47  [-0.12237588402818134, -0.09202025752503212, 0...   \n",
       "2               33  [0.27229464490531313, 0.1280920921549497, 0.15...   \n",
       "3               45  [-1.6858831480351115, -0.8661805406159092, -0....   \n",
       "4                9  [1.8771197424131327, 1.4195480026451441, 0.544...   \n",
       "...            ...                                                ...   \n",
       "12710           22  [-0.5026723961033952, 0.31424983410693796, -0....   \n",
       "12711           10  [-0.09417143502076045, -0.29842191556206893, -...   \n",
       "12712           27                                                 []   \n",
       "12713           11                                                 []   \n",
       "12714            8                                                 []   \n",
       "\n",
       "                                             Scaled TEMP  \n",
       "0      [-0.5852354223355396, -0.5852354223355396, -0....  \n",
       "1      [-0.7735061037287296, -0.7735061037287296, -0....  \n",
       "2      [-1.1500474665150429, -1.1500474665150429, -1....  \n",
       "3      [-0.9617767851218528, -0.9617767851218528, -0....  \n",
       "4      [-2.4621880639731812, -2.4621880639731812, -2....  \n",
       "...                                                  ...  \n",
       "12710  [1.3222897297499479, 1.3222897297499479, 1.322...  \n",
       "12711  [0.8683417878619597, 0.8683417878619597, 1.322...  \n",
       "12712  [0.8683417878619597, 0.8683417878619597, 0.868...  \n",
       "12713  [0.8683417878619597, 1.3222897297499479, 1.322...  \n",
       "12714  [1.3222897297499479, 1.3222897297499479, 1.322...  \n",
       "\n",
       "[12715 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_20_nonmissing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lst = annotation_20_nonmissing['Segment ID']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_file_lst = []\n",
    "for segment in file_lst:\n",
    "    session = segment[4:6]\n",
    "    wav_file_lst.append(f'/home/arplab/project/paradeigma/multi_modal/org_KEMDy20/Session{session}/' + segment + '.wav')\n",
    "wav_file_lst = pd.Series(wav_file_lst)\n",
    "sampling_rate = 16000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/data2vec-audio-large-960h were not used when initializing Data2VecAudioModel: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing Data2VecAudioModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Data2VecAudioModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/data2vec-audio-large-960h were not used when initializing Data2VecAudioModel: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing Data2VecAudioModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Data2VecAudioModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "check_point_wav_model = 'facebook/data2vec-audio-large-960h'\n",
    "processor = AutoProcessor.from_pretrained(check_point_wav_model)\n",
    "model_wav = Data2VecAudioModel.from_pretrained(check_point_wav_model)\n",
    "model_wav_cuda = Data2VecAudioModel.from_pretrained(check_point_wav_model).to('cuda')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### audio embedding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_check(segment_id, sess):\n",
    "    if sess in segment_id:\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# padding: https://huggingface.co/docs/transformers/pad_truncation\n",
    "def wav_embeddings_func(wav_file_lst, processor, model):\n",
    "    dataset = Dataset.from_dict({\"wav\": wav_file_lst }).cast_column(\"wav\", Audio())\n",
    "    wav_array = [dataset[i]['wav']['array'] for i in range(len(wav_file_lst))]\n",
    "    inputs = processor(wav_array, sampling_rate = sampling_rate, return_tensors = 'pt', padding = 'max_length', max_length= 48000, truncation = True)\n",
    "    with torch.no_grad():\n",
    "        output = model_wav(**inputs)\n",
    "    return output\n",
    "\n",
    "def make_wav_embedding_pickle(file_lst, processor, model, sess_lst):\n",
    "    \n",
    "    for session in tqdm(sess_lst):\n",
    "        wav_embeddings = wav_embeddings_func(file_lst[file_lst.apply(session_check, sess=session)], processor, model)\n",
    "        wav_embeddings = wav_embeddings['last_hidden_state']\n",
    "        with open(f'/home/arplab/project/paradeigma/multi_modal/model/data/embedding/KEMDY20/paradeigma_KEMDY20_wav_embedding_{session}.pkl', 'wb') as f:\n",
    "            pickle.dump(wav_embeddings, f, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        del wav_embeddings\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "def load_wav_embedding_pickle(path_list):\n",
    "    result = {}\n",
    "    for path in path_list:\n",
    "        session = path[-10:-4]\n",
    "        with open(f'/home/arplab/project/paradeigma/multi_modal/model/data/embedding/KEMDY20/{path}', 'rb') as f:\n",
    "            wav_embedding = pickle.load(f)\n",
    "            \n",
    "        result[session] = wav_embedding\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_lst = ['Sess20',\n",
    "       'Sess21', 'Sess22', 'Sess23', 'Sess24', 'Sess25', 'Sess26',\n",
    "       'Sess27', 'Sess28', 'Sess29', 'Sess30', 'Sess31', 'Sess32',\n",
    "       'Sess33', 'Sess34', 'Sess35', 'Sess36', 'Sess37', 'Sess38',\n",
    "       'Sess39', 'Sess40']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_lst = annotation_20_nonmissing['Segment ID'].apply(lambda x: x[:6]).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]2023-04-10 00:13:04.518463: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-10 00:13:05.575108: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11/include:/usr/local/cuda-11/lib64::/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-04-10 00:13:05.575197: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11/include:/usr/local/cuda-11/lib64::/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-04-10 00:13:05.575205: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "100%|██████████| 21/21 [1:03:50<00:00, 182.39s/it]\n"
     ]
    }
   ],
   "source": [
    "make_wav_embedding_pickle(wav_file_lst, processor, model_wav_cuda, sess_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_path = '/home/arplab/project/paradeigma/multi_modal/model/data/embedding/KEMDY20'\n",
    "file_list = os.listdir(dir_path)\n",
    "wav_path_list = sorted([file for file in file_list if 'KEMDY20_wav' in file ])\n",
    "\n",
    "embeddings_wav_dict = load_wav_embedding_pickle(wav_path_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Embedding\n",
    "- 참고: https://huggingface.co/docs/datasets/nlp_load\n",
    "- 참고: https://huggingface.co/docs/transformers/v4.27.2/en/model_doc/data2vec#transformers.Data2VecTextModel\n",
    "- 참고 한국어 pretrained model: https://huggingface.co/Junmai/KR-Data2VecText-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, BartModel\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text data loading\n",
    "txt_file_lst = []\n",
    "for segment in file_lst:\n",
    "    session = segment[4:6]\n",
    "    txt_file_lst.append(f'/home/arplab/project/paradeigma/multi_modal/org_KEMDy20/Session{session}/' + segment + '.txt')\n",
    "\n",
    "txt_file_lst = pd.Series(txt_file_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(35002, 768)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = 'Junmai/KR-Data2VecText-v1'\n",
    "model_txt = AutoModel.from_pretrained(checkpoint) \n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "model_txt.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text embedding method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_embeddings_func(txt_file_lst, tokenizer, model):\n",
    "    sentences = []\n",
    "\n",
    "    for i in txt_file_lst:    \n",
    "        f = open(i, 'r')\n",
    "        line = f.readline()\n",
    "        line = re.sub('\\n', '', line)\n",
    "        line = re.sub('  ', ' ', line)\n",
    "        line = line.rstrip().lstrip()\n",
    "        sentences.append(line)\n",
    "        f.close()\n",
    "    \n",
    "    inputs = tokenizer(sentences, padding='max_length', max_length = 80, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        txt_embeddings= model_txt(**inputs)\n",
    "    return txt_embeddings['last_hidden_state']\n",
    "\n",
    "def make_txt_embedding_pickle(file_lst, tokenizer, model, sess_lst):\n",
    "    \n",
    "    for session in tqdm(sess_lst):\n",
    "        txt_embeddings = text_embeddings_func(file_lst[file_lst.apply(session_check, sess=session)], tokenizer, model)\n",
    "        with open(f'/home/arplab/project/paradeigma/multi_modal/model/data/embedding/KEMDY20/paradeigma_KEMDY20_txt_embedding_{session}.pkl', 'wb') as f:\n",
    "            pickle.dump(txt_embeddings, f, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "        del txt_embeddings\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "def load_txt_embedding_pickle(path_list):\n",
    "    result = {}\n",
    "    for path in path_list:\n",
    "        session = path[-10:-4]\n",
    "        with open(f'/home/arplab/project/paradeigma/multi_modal/model/data/embedding/KEMDY20/{path}', 'rb') as f:\n",
    "            txt_embedding = pickle.load(f)\n",
    "        result[session] = txt_embedding\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [12:56<00:00, 20.44s/it]\n"
     ]
    }
   ],
   "source": [
    "sess_lst = annotation_20_nonmissing['Segment ID'].apply(lambda x: x[:6]).unique()\n",
    "\n",
    "make_txt_embedding_pickle(txt_file_lst, tokenizer, model_txt, sess_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "dir_path = '/home/arplab/project/paradeigma/multi_modal/model/data/embedding/KEMDY20'\n",
    "file_list = os.listdir(dir_path)\n",
    "txt_path_list = sorted([file for file in file_list if 'KEMDY20_txt' in file ])\n",
    "\n",
    "embeddings_txt_dict = load_txt_embedding_pickle(txt_path_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_for_dataset = [embeddings_wav_dict, embeddings_txt_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/arplab/project/paradeigma/multi_modal/model/data/paradeigma_KEMDY20_embedding_for_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_for_dataset, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/arplab/project/paradeigma/multi_modal/model/data/paradeigma_KEMDY20_embedding_for_dataset.pkl', 'rb') as f:\n",
    "    embedding_for_dataset = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bdc1fd12ca460d5768d71e9df3d9063ef832ce64a62e55a1a523c8c99752868e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
