{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working model for tensorfusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torchmetrics import F1Score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import random\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wav, text데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../paradeigma/multi_modal/model/data/paradeigma_KEMDY19_annotation_nonmissing.pkl',\n",
       " '../../../paradeigma/multi_modal/model/data/paradeigma_KEMDY19_embedding_for_dataset.pkl',\n",
       " '../../../paradeigma/multi_modal/model/data/paradeigma_KEMDY20_annotation_nonmissing.pkl',\n",
       " '../../../paradeigma/multi_modal/model/data/paradeigma_KEMDY20_embedding_for_dataset.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wav and text data load\n",
    "dataset_file_lst = ['../../../paradeigma/multi_modal/model/data/paradeigma_KEMDY19_annotation_nonmissing.pkl',\n",
    "                    '../../../paradeigma/multi_modal/model/data/paradeigma_KEMDY19_embedding_for_dataset.pkl',\n",
    "                    '../../../paradeigma/multi_modal/model/data/paradeigma_KEMDY20_annotation_nonmissing.pkl',\n",
    "                    '../../../paradeigma/multi_modal/model/data/paradeigma_KEMDY20_embedding_for_dataset.pkl']\n",
    "dataset_file_lst = sorted(dataset_file_lst)\n",
    "dataset_file_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../paradeigma/multi_modal/model/data/paradeigma_KEMDY19_annotation_nonmissing.pkl kemdy19_annot\n",
      "../../../paradeigma/multi_modal/model/data/paradeigma_KEMDY19_embedding_for_dataset.pkl kemdy19_emb\n",
      "../../../paradeigma/multi_modal/model/data/paradeigma_KEMDY20_annotation_nonmissing.pkl kemdy20_annot\n",
      "../../../paradeigma/multi_modal/model/data/paradeigma_KEMDY20_embedding_for_dataset.pkl kemdy20_emb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "var_names = ['kemdy19_annot', 'kemdy19_emb', 'kemdy20_annot', 'kemdy20_emb']\n",
    "for file, var_name in zip(dataset_file_lst, var_names):\n",
    "    print(file, var_name)\n",
    "    with open(file, 'rb') as f:\n",
    "        globals()[var_name] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  paradeigma가 섞어놓은 label들..되돌리기\n",
    "# {'neutral': 0, 'happy': 0, 'surprise':0, 'disgust': 0, 'angry': 0, 'sad':0, 'fear': 0}\n",
    "# {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
    "\n",
    "def change_label_order(lst, new_order = [4, 3, 6, 1, 0, 5, 2]):\n",
    "    return [lst[i] for i in new_order]\n",
    "\n",
    "kemdy20_annot['emotion_vector'] = kemdy20_annot['emotion_vector'].apply(change_label_order)\n",
    "kemdy19_annot['emotion_vector'] = kemdy19_annot['emotion_vector'].apply(change_label_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment ID</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>emotion_vector</th>\n",
       "      <th>valence_vector</th>\n",
       "      <th>arousal_vector</th>\n",
       "      <th>EDA</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>EDA length</th>\n",
       "      <th>TEMP length</th>\n",
       "      <th>Scaled EDA</th>\n",
       "      <th>Scaled TEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sess01_script01_M001</td>\n",
       "      <td>surprise</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 9]</td>\n",
       "      <td>[4, 5, 1, 0, 0]</td>\n",
       "      <td>[1, 0, 0, 6, 3]</td>\n",
       "      <td>[4.408951, 4.403825, 4.410233, 4.421767, 4.429...</td>\n",
       "      <td>[34.66, 34.66, 34.66, 34.66, 34.66, 34.68, 34....</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>[-0.926455937246618, -0.9285481420682529, -0.9...</td>\n",
       "      <td>[1.6900874192514124, 1.6900874192514124, 1.690...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sess01_script01_F001</td>\n",
       "      <td>fear</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>[0, 0, 7, 0, 1, 0, 2]</td>\n",
       "      <td>[5, 5, 0, 0, 0]</td>\n",
       "      <td>[1, 0, 2, 6, 1]</td>\n",
       "      <td>[0.145914, 0.140794, 0.144634, 0.145914, 0.140...</td>\n",
       "      <td>[30.69, 30.69, 30.69, 30.69, 30.71, 30.71, 30....</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>[-1.407155706494133, -1.4312942323175069, -1.4...</td>\n",
       "      <td>[-1.1135528407658513, -1.1135528407658513, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sess01_script01_M002</td>\n",
       "      <td>angry</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>[10, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[7, 3, 0, 0, 0]</td>\n",
       "      <td>[1, 0, 0, 3, 6]</td>\n",
       "      <td>[4.478828, 4.396809, 4.334012, 4.322478, 4.346...</td>\n",
       "      <td>[34.61, 34.61, 34.61, 34.61, 34.61, 34.61, 34....</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>[-0.8979352590723317, -0.9314117606848334, -0....</td>\n",
       "      <td>[1.6164861115016742, 1.6164861115016742, 1.616...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Segment ID   Emotion  Valence  Arousal          emotion_vector  \\\n",
       "0  Sess01_script01_M001  surprise      1.7      4.0   [0, 0, 1, 0, 0, 0, 9]   \n",
       "1  Sess01_script01_F001      fear      1.5      3.6   [0, 0, 7, 0, 1, 0, 2]   \n",
       "2  Sess01_script01_M002     angry      1.3      4.3  [10, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "    valence_vector   arousal_vector  \\\n",
       "0  [4, 5, 1, 0, 0]  [1, 0, 0, 6, 3]   \n",
       "1  [5, 5, 0, 0, 0]  [1, 0, 2, 6, 1]   \n",
       "2  [7, 3, 0, 0, 0]  [1, 0, 0, 3, 6]   \n",
       "\n",
       "                                                 EDA  \\\n",
       "0  [4.408951, 4.403825, 4.410233, 4.421767, 4.429...   \n",
       "1  [0.145914, 0.140794, 0.144634, 0.145914, 0.140...   \n",
       "2  [4.478828, 4.396809, 4.334012, 4.322478, 4.346...   \n",
       "\n",
       "                                                TEMP  EDA length  TEMP length  \\\n",
       "0  [34.66, 34.66, 34.66, 34.66, 34.66, 34.68, 34....          33           33   \n",
       "1  [30.69, 30.69, 30.69, 30.69, 30.71, 30.71, 30....          17           17   \n",
       "2  [34.61, 34.61, 34.61, 34.61, 34.61, 34.61, 34....          27           27   \n",
       "\n",
       "                                          Scaled EDA  \\\n",
       "0  [-0.926455937246618, -0.9285481420682529, -0.9...   \n",
       "1  [-1.407155706494133, -1.4312942323175069, -1.4...   \n",
       "2  [-0.8979352590723317, -0.9314117606848334, -0....   \n",
       "\n",
       "                                         Scaled TEMP  \n",
       "0  [1.6900874192514124, 1.6900874192514124, 1.690...  \n",
       "1  [-1.1135528407658513, -1.1135528407658513, -1....  \n",
       "2  [1.6164861115016742, 1.6164861115016742, 1.616...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kemdy19_annot.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<2020년>\n",
    "'angry;disqust',  'angry;disqust;fear;neutral;sad',  'angry;disqust;neutral', 'angry;happy;neutral', 'angry;neutral', 'disqust;happy;neutral', 'disqust;neutral', 'disqust;neutral;sad', 'fear;happy', 'fear;happy;neutral', 'fear;neutral', 'happy;neutral', 'happy;neutral;surprise', 'happy;sad', 'happy;surprise', 'neutral;sad', 'neutral;surprise'\n",
    "\n",
    "<2019년>\n",
    "'angry;disgust;fear;neutral;surprise', 'angry;fear', 'angry;fear;neutral', 'angry;fear;surprise', 'angry;happy', 'angry;neutral;surprise', 'angry;sad', 'angry;surprise', 'disgust;fear', 'disgust;happy','disgust;neutral;surprise', 'disgust;sad', 'disgust;surprise', 'fear;neutral;surprise', 'fear;sad', 'fear;surprise', 'happy;neutral;sad', 'neutral;sad;surprise', 'sad;surprise'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_dict = {'angry':0, 'disgust':1, 'fear':2,'happy':3,'neutral':4, 'sad':5, 'surprise':6,  \n",
    "               'neutral;surprise': 450, 'neutral;sad': 460, 'happy;neutral': 340, \n",
    "               'angry;neutral': 40, 'disgust;neutral': 140, 'fear;neutral': 240, \n",
    "               'happy;surprise': 350, 'angry;happy;neutral': 7340, 'angry;disgust': 10, \n",
    "               'happy;neutral;surprise': 3450, 'fear;happy': 230,'fear;happy;neutral': 2340,\n",
    "               'angry;disgust;neutral': 7140, 'disgust;neutral;sad': 1460, \n",
    "               'happy;sad': 360, 'disgust;happy;neutral': 3410, 'angry;fear': 20, 'angry;fear;neutral':7240,\n",
    "               'angry;fear;surprise': 7250, 'angry;happy': 730, 'angry;neutral;surprise':7450, \n",
    "               'angry;sad': 60, 'angry;surprise': 50, 'disgust;fear':120, 'disgust;happy': 130,\n",
    "               'disgust;neutral;surprise':1450, 'disgust;sad': 160, 'disgust;surprise':150, \n",
    "               'fear;neutral;surprise':2450, 'fear;sad': 260, 'fear;surprise':250, 'happy;neutral;sad':3460,\n",
    "               'neutral;sad;surprise':4560, 'sad;surprise': 560,\n",
    "               'angry;disgust;fear;neutral;sad': 10000,'angry;disgust;fear;neutral;surprise':20000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6, 'angry;disgust': 10, 'angry;fear': 20, 'angry;neutral': 40, 'angry;surprise': 50, 'angry;sad': 60, 'disgust;fear': 120, 'disgust;happy': 130, 'disgust;neutral': 140, 'disgust;surprise': 150, 'disgust;sad': 160, 'fear;happy': 230, 'fear;neutral': 240, 'fear;surprise': 250, 'fear;sad': 260, 'happy;neutral': 340, 'happy;surprise': 350, 'happy;sad': 360, 'neutral;surprise': 450, 'neutral;sad': 460, 'sad;surprise': 560, 'angry;happy': 730, 'disgust;neutral;surprise': 1450, 'disgust;neutral;sad': 1460, 'fear;happy;neutral': 2340, 'fear;neutral;surprise': 2450, 'disgust;happy;neutral': 3410, 'happy;neutral;surprise': 3450, 'happy;neutral;sad': 3460, 'neutral;sad;surprise': 4560, 'angry;disgust;neutral': 7140, 'angry;fear;neutral': 7240, 'angry;fear;surprise': 7250, 'angry;happy;neutral': 7340, 'angry;neutral;surprise': 7450, 'angry;disgust;fear;neutral;sad': 10000, 'angry;disgust;fear;neutral;surprise': 20000}\n"
     ]
    }
   ],
   "source": [
    "encode_dict = {k: v for k, v in sorted(encode_dict.items(), key=lambda item: item[1])}\n",
    "print(encode_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6, 'angry;disgust': 10, 'angry;fear': 20, 'angry;neutral': 40, 'angry;surprise': 50, 'angry;sad': 60, 'disgust;fear': 120, 'disgust;happy': 130, 'disgust;neutral': 140, 'disgust;surprise': 150, 'disgust;sad': 160, 'fear;happy': 230, 'fear;neutral': 240, 'fear;surprise': 250, 'fear;sad': 260, 'happy;neutral': 340, 'happy;surprise': 350, 'happy;sad': 360, 'neutral;surprise': 450, 'neutral;sad': 460, 'sad;surprise': 560, 'angry;happy': 730, 'disgust;neutral;surprise': 1450, 'disgust;neutral;sad': 1460, 'fear;happy;neutral': 2340, 'fear;neutral;surprise': 2450, 'disgust;happy;neutral': 3410, 'happy;neutral;surprise': 3450, 'happy;neutral;sad': 3460, 'neutral;sad;surprise': 4560, 'angry;disgust;neutral': 7140, 'angry;fear;neutral': 7240, 'angry;fear;surprise': 7250, 'angry;happy;neutral': 7340, 'angry;neutral;surprise': 7450, 'angry;disgust;fear;neutral;sad': 10000, 'angry;disgust;fear;neutral;surprise': 20000} \n",
      " {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise', 10: 'angry;disgust', 20: 'angry;fear', 40: 'angry;neutral', 50: 'angry;surprise', 60: 'angry;sad', 120: 'disgust;fear', 130: 'disgust;happy', 140: 'disgust;neutral', 150: 'disgust;surprise', 160: 'disgust;sad', 230: 'fear;happy', 240: 'fear;neutral', 250: 'fear;surprise', 260: 'fear;sad', 340: 'happy;neutral', 350: 'happy;surprise', 360: 'happy;sad', 450: 'neutral;surprise', 460: 'neutral;sad', 560: 'sad;surprise', 730: 'angry;happy', 1450: 'disgust;neutral;surprise', 1460: 'disgust;neutral;sad', 2340: 'fear;happy;neutral', 2450: 'fear;neutral;surprise', 3410: 'disgust;happy;neutral', 3450: 'happy;neutral;surprise', 3460: 'happy;neutral;sad', 4560: 'neutral;sad;surprise', 7140: 'angry;disgust;neutral', 7240: 'angry;fear;neutral', 7250: 'angry;fear;surprise', 7340: 'angry;happy;neutral', 7450: 'angry;neutral;surprise', 10000: 'angry;disgust;fear;neutral;sad', 20000: 'angry;disgust;fear;neutral;surprise'}\n"
     ]
    }
   ],
   "source": [
    "# encoding Emotion for whole data\n",
    "# 사전에 실제로 encoding한 끝 수가 마지막 linear layer의 끝자리랑 맞아야 합니다. 아니면 CUDA error: CUBLAS_STATUS_EXECUTION_FAILED가 나는 것 같아요.\n",
    "# 예를 들어, label이 0~9, 11,13이렇게 12개가 되었어도, 0~13은 14개니까 마지막 레이어에서 14개 unit을 받아야 multiclass classification이 에러없이 진행됩니다!\n",
    "# 데이터에서 정답 라벨 인코딩: ['neutral', 'happy', 'surprise', 'disgust', 'angry', 'sad', 'fear']\n",
    "# 이 순서를 지켜서 라벨링을 해야함\n",
    "decode_dict = {b:i for i, b in encode_dict.items()}\n",
    "print(encode_dict, '\\n', decode_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    6\n",
       " 1    2\n",
       " 2    0\n",
       " Name: Emotion, dtype: int64,\n",
       " 0    4\n",
       " 1    4\n",
       " 2    4\n",
       " Name: Emotion, dtype: int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kemdy19_annot.Emotion = list(kemdy19_annot.Emotion.map(encode_dict))\n",
    "kemdy20_annot.Emotion = list(kemdy20_annot.Emotion.map(encode_dict))\n",
    "kemdy19_annot.Emotion[:3], kemdy20_annot.Emotion[:3]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA, TEMP Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def add_padding(pd_series, length = 50):\n",
    "    if isinstance(pd_series, float):\n",
    "        if math.isnan(pd_series):\n",
    "            return np.zeros(10)\n",
    "    if len(pd_series) < length:\n",
    "        pd_series = np.concatenate([pd_series, np.zeros(length - len(pd_series))])\n",
    "        return np.array(pd_series)\n",
    "    elif len(pd_series) == length:\n",
    "        return np.array(pd_series)\n",
    "    elif len(pd_series) > length:\n",
    "        pd_series = pd_series[:length]\n",
    "        return np.array(pd_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9008.000000\n",
       "mean       22.596470\n",
       "std        19.693268\n",
       "min         1.000000\n",
       "25%         9.000000\n",
       "50%        17.000000\n",
       "75%        30.000000\n",
       "max       314.000000\n",
       "Name: EDA, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kemdy19_annot.EDA.map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.33301774,  0.55311825, -0.16032486, -0.10719511,  0.09773054,\n",
       "         0.10531797,  0.12809209,  0.40890977,  0.23435159, -0.29694591,\n",
       "        -0.36525051, -0.25140359, -0.46391666, -0.14514408,  0.05978157,\n",
       "         0.74286905,  0.61383542, -3.12036271,  2.16975526,  1.91929321,\n",
       "        -0.29693999, -0.19827383, -0.94967184,  0.18880927,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]),\n",
       " array([-0.21123698, -0.18926761, -0.18665215, -0.1861293 , -0.1861293 ,\n",
       "        -0.18874476, -0.20757542, -0.25517533, -0.29074444, -0.29179054,\n",
       "        -0.30434459, -0.24105233, -0.24628284, -0.48480603, -0.52822112,\n",
       "        -0.60860162, -0.77337071, -0.85676544, -0.78562721, -0.72181169,\n",
       "        -0.65747333, -0.89756547, -0.72181169, -0.67891945, -0.63655006,\n",
       "        -0.63602721, -0.62085771, -0.58842731, -0.57796588, -0.59156562,\n",
       "        -0.60725797,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]),\n",
       " array([-0.96177679, -0.96177679, -0.96177679, -0.96177679, -0.96177679,\n",
       "        -0.96177679, -0.96177679, -0.96177679, -0.96177679, -0.96177679,\n",
       "        -0.96177679, -0.96177679, -0.96177679, -0.96177679, -0.96177679,\n",
       "        -1.15004747, -1.15004747, -1.15004747, -1.15004747, -1.15004747,\n",
       "        -1.15004747, -1.15004747, -1.15004747, -0.96177679, -0.96177679,\n",
       "        -0.96177679, -0.96177679, -1.15004747, -1.15004747, -1.15004747,\n",
       "        -1.15004747, -1.15004747, -1.15004747, -1.15004747, -1.15004747,\n",
       "        -1.15004747, -1.15004747, -1.15004747, -1.15004747, -1.15004747,\n",
       "        -1.15004747, -1.15004747, -1.15004747, -1.33831815, -1.33831815,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]),\n",
       " array([0.7038299 , 0.7038299 , 0.67438937, 0.67438937, 0.67438937,\n",
       "        0.67438937, 0.67438937, 0.67438937, 0.67438937, 0.67438937,\n",
       "        0.64494885, 0.64494885, 0.64494885, 0.64494885, 0.7038299 ,\n",
       "        0.7038299 , 0.7038299 , 0.7038299 , 0.71855016, 0.71855016,\n",
       "        0.71855016, 0.71855016, 0.7038299 , 0.7038299 , 0.7038299 ,\n",
       "        0.7038299 , 0.67438937, 0.67438937, 0.67438937, 0.67438937,\n",
       "        0.67438937, 0.67438937, 0.67438937, 0.67438937, 0.64494885,\n",
       "        0.64494885, 0.64494885, 0.64494885, 0.67438937, 0.67438937,\n",
       "        0.67438937, 0.67438937, 0.7038299 , 0.7038299 , 0.7038299 ,\n",
       "        0.7038299 , 0.7038299 , 0.7038299 , 0.7038299 , 0.7038299 ]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kemdy19_annot['Scaled EDA'] = kemdy19_annot['Scaled EDA'].apply(add_padding)\n",
    "kemdy20_annot['Scaled EDA'] = kemdy20_annot['Scaled EDA'].apply(add_padding)\n",
    "kemdy19_annot['Scaled TEMP'] = kemdy19_annot['Scaled TEMP'].apply(add_padding)\n",
    "kemdy20_annot['Scaled TEMP'] = kemdy20_annot['Scaled TEMP'].apply(add_padding)\n",
    "# check\n",
    "kemdy20_annot['Scaled EDA'][10], kemdy19_annot['Scaled EDA'][10], kemdy20_annot['Scaled TEMP'][3],kemdy19_annot['Scaled TEMP'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session 19 length: wav - 9008, txt - 9008\n",
      "session 20 length: wav - 12715, txt - 12715\n"
     ]
    }
   ],
   "source": [
    "lengt_wav = 0\n",
    "lengt_txt = 0\n",
    "for i,j in zip(kemdy19_emb[0], kemdy19_emb[1]):\n",
    "    lengt_wav += len(kemdy19_emb[0][i])\n",
    "    lengt_txt += len(kemdy19_emb[1][j])\n",
    "    # lengt += len(i)\n",
    "print(f'session 19 length: wav - {lengt_wav}, txt - {lengt_txt}')\n",
    "\n",
    "lengt_wav = 0\n",
    "lengt_txt = 0\n",
    "for i,j in zip(kemdy20_emb[0], kemdy20_emb[1]):\n",
    "    lengt_wav += len(kemdy20_emb[0][i])\n",
    "    lengt_txt += len(kemdy20_emb[1][j])\n",
    "    \n",
    "print(f'session 20 length: wav - {lengt_wav}, txt - {lengt_txt}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session pick \n",
    "- test(.2), validation(.2), train(.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choice_and_remove_list(original_list, k = 8):\n",
    "    removed_new_list = []\n",
    "    chosen_list = random.sample(original_list, k = k)\n",
    "    for session in original_list:\n",
    "        if session in chosen_list:\n",
    "            pass\n",
    "        else:\n",
    "            removed_new_list.append(session) \n",
    "    return sorted(removed_new_list), sorted(chosen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sess01', 'Sess02', 'Sess03', 'Sess07', 'Sess10', 'Sess11', 'Sess13', 'Sess15', 'Sess16', 'Sess19', 'Sess22', 'Sess23', 'Sess24', 'Sess25', 'Sess26', 'Sess30', 'Sess31', 'Sess32', 'Sess33', 'Sess34', 'Sess37', 'Sess38']\n",
      "['Sess05', 'Sess06', 'Sess18', 'Sess21', 'Sess28', 'Sess29', 'Sess36', 'Sess40']\n",
      "['Sess04', 'Sess08', 'Sess09', 'Sess14', 'Sess20', 'Sess27', 'Sess35', 'Sess39']\n",
      "\n",
      "\n",
      "['Sess01', 'Sess02', 'Sess03', 'Sess04', 'Sess05', 'Sess06', 'Sess07', 'Sess08', 'Sess09', 'Sess10', 'Sess11', 'Sess12', 'Sess13', 'Sess14', 'Sess15', 'Sess16', 'Sess17', 'Sess18', 'Sess19', 'Sess20']\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# session을 train vs test&val로 나눠줌\n",
    "session_20_lst = ['Sess0' + str(i+1) if i < 9 else 'Sess' + str(i+1) for i in range(40)]\n",
    "session_20_lst.remove('Sess12')\n",
    "session_20_lst.remove('Sess17')\n",
    "sessions_20_train_lst, sessions_20_test_lst = choice_and_remove_list(session_20_lst, k = 8)\n",
    "sessions_20_train_lst, sessions_20_val_lst = choice_and_remove_list(sessions_20_train_lst, k = 8)\n",
    "print(sessions_20_train_lst, sessions_20_test_lst, sessions_20_val_lst, sep = '\\n')\n",
    "\n",
    "session_19_lst = ['Sess0' + str(i+1) if i < 9 else 'Sess' + str(i+1) for i in range(20)]\n",
    "sessions_19_train_lst, sessions_19_test_lst = choice_and_remove_list(session_19_lst, k = 0)\n",
    "sessions_19_train_lst, sessions_19_val_lst = choice_and_remove_list(sessions_19_train_lst, k = 0)\n",
    "print('\\n', sessions_19_train_lst,sessions_19_test_lst, sessions_19_val_lst, sep = '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data reconstruct\n",
    "- dict - session - txt, wav, segment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "kemdy20_emb_new = {}\n",
    "for session in kemdy20_emb[0].keys():\n",
    "    kemdy20_emb_new[session] = {}\n",
    "    kemdy20_emb_new[session]['wav'] = kemdy20_emb[0][session]\n",
    "    kemdy20_emb_new[session]['txt'] = kemdy20_emb[1][session]\n",
    "    kemdy20_emb_new[session]['segment_id'] = kemdy20_annot['Segment ID'][kemdy20_annot['Segment ID'].str.startswith(session)]\n",
    "    # print(session, len(kemdy20_emb_new[session]['wav']), len(kemdy20_emb_new[session]['txt']), len(kemdy20_emb_new[session]['segment_id']))\n",
    "\n",
    "# print('\\n')\n",
    "kemdy19_emb_new = {}\n",
    "for session in kemdy19_emb[0].keys():\n",
    "    kemdy19_emb_new[session] = {}\n",
    "    kemdy19_emb_new[session]['wav'] = kemdy19_emb[0][session]\n",
    "    kemdy19_emb_new[session]['txt'] = kemdy19_emb[1][session]\n",
    "    kemdy19_emb_new[session]['segment_id'] = kemdy19_annot['Segment ID'][kemdy19_annot['Segment ID'].str.startswith(session)]\n",
    "    # print(session, len(kemdy19_emb_new[session]['wav']), len(kemdy19_emb_new[session]['txt']), len(kemdy19_emb_new[session]['segment_id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나눠준 세션을 emb(wav, text순), annot set에 적용\n",
    "def get_data_by_session(data, session_lst):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        print('dataframe')\n",
    "        for idx, session in enumerate(session_lst):\n",
    "            if idx == 0:\n",
    "                dataframe = data[data['Segment ID'].str.startswith(session)]\n",
    "            else:\n",
    "                dataframe = pd.concat([dataframe, data[data['Segment ID'].str.startswith(session)]])\n",
    "        return dataframe\n",
    "    \n",
    "    elif isinstance(data, dict):\n",
    "        print('dict')\n",
    "        emb_data = {}\n",
    "        emb_data['wav'] = []\n",
    "        emb_data['txt'] = []\n",
    "        emb_data['segment_id'] = []\n",
    "        for session in session_lst:\n",
    "            emb_data['wav'].extend(data[session]['wav'])\n",
    "            emb_data['txt'].extend(data[session]['txt'])\n",
    "            emb_data['segment_id'].extend(data[session]['segment_id'])            \n",
    "        return emb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe\n",
      "dataframe\n",
      "dataframe\n",
      "dataframe\n"
     ]
    }
   ],
   "source": [
    "kemdy19_annot_train = get_data_by_session(kemdy19_annot, sessions_19_train_lst)\n",
    "# kemdy19_annot_test = get_data_by_session(kemdy19_annot, sessions_19_test_lst)\n",
    "# kemdy19_annot_val = get_data_by_session(kemdy19_annot, sessions_19_val_lst)\n",
    "\n",
    "kemdy20_annot_train = get_data_by_session(kemdy20_annot, sessions_20_train_lst)\n",
    "kemdy20_annot_test = get_data_by_session(kemdy20_annot, sessions_20_test_lst)\n",
    "kemdy20_annot_val = get_data_by_session(kemdy20_annot, sessions_20_val_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict\n",
      "dict\n",
      "dict\n",
      "dict\n"
     ]
    }
   ],
   "source": [
    "# session 정보가 없어집니다. \n",
    "kemdy19_emb_train = get_data_by_session(kemdy19_emb_new, sessions_19_train_lst)\n",
    "# kemdy19_emb_test = get_data_by_session(kemdy19_emb_new, sessions_19_test_lst)\n",
    "# kemdy19_emb_val = get_data_by_session(kemdy19_emb_new, sessions_19_val_lst)\n",
    "\n",
    "kemdy20_emb_train = get_data_by_session(kemdy20_emb_new, sessions_20_train_lst)\n",
    "kemdy20_emb_test = get_data_by_session(kemdy20_emb_new, sessions_20_test_lst)\n",
    "kemdy20_emb_val = get_data_by_session(kemdy20_emb_new, sessions_20_val_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # kemdy 19 - 9008이 정상\n",
    "# print(len(kemdy19_emb_train['wav']), len(kemdy19_emb_train['txt']), len(kemdy19_emb_train['segment_id']))\n",
    "# print(len(kemdy19_emb_test['wav']), len(kemdy19_emb_test['txt']), len(kemdy19_emb_test['segment_id']))\n",
    "# print(len(kemdy19_emb_val['wav']), len(kemdy19_emb_val['txt']), len(kemdy19_emb_val['segment_id']))\n",
    "# # print(len(kemdy19_emb_train['wav']) + len(kemdy19_emb_test['wav']) + len(kemdy19_emb_val['wav']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7514 7514 7514\n",
      "2442 2442 2442\n",
      "2759 2759 2759\n",
      "12715\n"
     ]
    }
   ],
   "source": [
    "# kemdy 20 - 12715가 정상\n",
    "print(len(kemdy20_emb_train['wav']), len(kemdy20_emb_train['txt']), len(kemdy20_emb_train['segment_id']))\n",
    "print(len(kemdy20_emb_test['wav']), len(kemdy20_emb_test['txt']), len(kemdy20_emb_test['segment_id']))\n",
    "print(len(kemdy20_emb_val['wav']), len(kemdy20_emb_val['txt']), len(kemdy20_emb_val['segment_id']))\n",
    "print(len(kemdy20_emb_train['wav']) + len(kemdy20_emb_test['wav'])+ len(kemdy20_emb_val['wav']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(kemdy19_emb_train.keys(), kemdy19_emb_test.keys(), kemdy19_emb_val.keys(),\n",
    "#       kemdy20_emb_train.keys(),kemdy20_emb_test.keys(), kemdy20_emb_val.keys(),sep = '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data neutral pick하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kemdy19에서 0개, kemdy20에서 5000개 추출\n"
     ]
    }
   ],
   "source": [
    "# 각 데이터 셋에서 몇개 뽑아야 되는지 계산 neutral: 4\n",
    "target_neutral_num = 5000\n",
    "\n",
    "target_neutral_num_19 = 0\n",
    "# target_neutral_num_19 = int(target_neutral_num / (Counter(kemdy19_annot['Emotion'])[4] + Counter(kemdy20_annot['Emotion'])[4]) * Counter(kemdy19_annot['Emotion'])[4])\n",
    "target_neutral_num_20 = target_neutral_num - target_neutral_num_19\n",
    "print(f'kemdy19에서 {target_neutral_num_19}개, kemdy20에서 {target_neutral_num_20}개 추출')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11925"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 train dataset에서 뽑아야 되는 갯수만큼 랜덤으로 뽑아옴\n",
    "kemdy19_annot_train_not_neut = kemdy19_annot_train[kemdy19_annot_train['Emotion'] != 4]\n",
    "kemdy20_annot_train_not_neut = kemdy20_annot_train[kemdy20_annot_train['Emotion'] != 4]\n",
    "\n",
    "kemdy19_annot_train_neut = kemdy19_annot_train[kemdy19_annot_train['Emotion'] == 4].sample(target_neutral_num_19)\n",
    "kemdy20_annot_train_neut = kemdy20_annot_train[kemdy20_annot_train['Emotion'] == 4].sample(target_neutral_num_20)\n",
    "len(kemdy19_annot_train_not_neut) + len(kemdy19_annot_train_neut) + len(kemdy20_annot_train_not_neut) + len(kemdy20_annot_train_neut)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding, Test and validation dataset 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2442 2442 2442\n"
     ]
    }
   ],
   "source": [
    "emb_test_final = {}\n",
    "emb_test_final['wav'] = []\n",
    "emb_test_final['txt'] = []\n",
    "emb_test_final['segment_id'] = []\n",
    "\n",
    "# emb_test_final['wav'] = kemdy19_emb_test['wav']\n",
    "emb_test_final['wav'].extend(kemdy20_emb_test['wav'])\n",
    "\n",
    "# emb_test_final['txt'] = kemdy19_emb_test['txt']\n",
    "emb_test_final['txt'].extend(kemdy20_emb_test['txt'])\n",
    "\n",
    "\n",
    "# emb_test_final['segment_id'] = kemdy19_emb_test['segment_id']\n",
    "emb_test_final['segment_id'].extend(kemdy20_emb_test['segment_id'])\n",
    "\n",
    "\n",
    "print(len(emb_test_final['wav']), len(emb_test_final['txt']), len(emb_test_final['segment_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2759 2759 2759\n"
     ]
    }
   ],
   "source": [
    "emb_val_final = {}\n",
    "emb_val_final['wav'] = []\n",
    "emb_val_final['txt'] = []\n",
    "emb_val_final['segment_id'] = []\n",
    "\n",
    "# emb_val_final['wav'] = kemdy19_emb_val['wav']\n",
    "emb_val_final['wav'].extend(kemdy20_emb_val['wav'])\n",
    "\n",
    "# emb_val_final['txt'] = kemdy19_emb_val['txt']\n",
    "emb_val_final['txt'].extend(kemdy20_emb_val['txt'])\n",
    "\n",
    "# emb_val_final['segment_id'] = kemdy19_emb_val['segment_id']\n",
    "emb_val_final['segment_id'].extend(kemdy20_emb_val['segment_id'])\n",
    "\n",
    "print(len(emb_val_final['wav']), len(emb_val_final['txt']), len(emb_val_final['segment_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11925 2442 2759\n"
     ]
    }
   ],
   "source": [
    "\n",
    "annot_train_final = pd.concat([kemdy19_annot_train_neut, kemdy20_annot_train_neut, kemdy19_annot_train_not_neut, kemdy20_annot_train_not_neut])\n",
    "# annot_test_final = pd.concat([kemdy19_annot_test, kemdy20_annot_test])\n",
    "# annot_val_final = pd.concat([kemdy19_annot_val, kemdy20_annot_val])\n",
    "\n",
    "annot_test_final = pd.concat([kemdy20_annot_test])\n",
    "annot_val_final = pd.concat([kemdy20_annot_val])\n",
    "\n",
    "\n",
    "annot_train_final.reset_index(drop=True, inplace=True)\n",
    "annot_test_final.reset_index(drop=True, inplace=True)\n",
    "annot_val_final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(len(annot_train_final), len(annot_test_final), len(annot_val_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11925 11925 11925\n"
     ]
    }
   ],
   "source": [
    "# train dataset neutral 4000개로 랜덤 뽑은 것 생성\n",
    "emb_train_final = {}\n",
    "emb_train_final['wav'] = []\n",
    "emb_train_final['txt'] = []\n",
    "emb_train_final['segment_id'] = []\n",
    "for segment_annot_id in kemdy19_annot_train_neut['Segment ID']:\n",
    "    for wav, txt, segment_emb_id in zip(kemdy19_emb_train['wav'], kemdy19_emb_train['txt'], kemdy19_emb_train['segment_id']):\n",
    "        if segment_annot_id == segment_emb_id:\n",
    "            emb_train_final['wav'].append(wav)\n",
    "            emb_train_final['txt'].append(txt)\n",
    "            emb_train_final['segment_id'].append(segment_emb_id)\n",
    "            \n",
    "for segment_annot_id in kemdy19_annot_train_not_neut['Segment ID']:\n",
    "    for wav, txt, segment_emb_id in zip(kemdy19_emb_train['wav'], kemdy19_emb_train['txt'], kemdy19_emb_train['segment_id']):\n",
    "        if segment_annot_id == segment_emb_id:\n",
    "            emb_train_final['wav'].append(wav)\n",
    "            emb_train_final['txt'].append(txt)\n",
    "            emb_train_final['segment_id'].append(segment_emb_id)\n",
    "        \n",
    "\n",
    "for segment_annot_id in kemdy20_annot_train_neut['Segment ID']:\n",
    "    for wav, txt, segment_emb_id in zip(kemdy20_emb_train['wav'], kemdy20_emb_train['txt'], kemdy20_emb_train['segment_id']):\n",
    "        if segment_emb_id == segment_annot_id:\n",
    "            emb_train_final['wav'].append(wav)\n",
    "            emb_train_final['txt'].append(txt)\n",
    "            emb_train_final['segment_id'].append(segment_emb_id)\n",
    "        \n",
    "for segment_annot_id in kemdy20_annot_train_not_neut['Segment ID']:\n",
    "    for wav, txt, segment_emb_id in zip(kemdy20_emb_train['wav'], kemdy20_emb_train['txt'], kemdy20_emb_train['segment_id']):\n",
    "        if segment_annot_id == segment_emb_id:\n",
    "            emb_train_final['wav'].append(wav)\n",
    "            emb_train_final['txt'].append(txt)\n",
    "            emb_train_final['segment_id'].append(segment_emb_id)\n",
    "            \n",
    "print(len(emb_train_final['wav']), len(emb_train_final['txt']), len(emb_train_final['segment_id']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch dataset 만들기\n",
    "- 참고: https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float32)\n",
    "print(torch.get_default_dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EtriDataset(Dataset):\n",
    "    def __init__(self, file_names, \n",
    "                 text_embeddings, \n",
    "                 wav_embeddings, \n",
    "                 Temp,\n",
    "                 EDA,\n",
    "                 Emotion,\n",
    "                 Emotion_vec, \n",
    "                 Arousal, \n",
    "                 Valence):\n",
    "        self.file_names = file_names\n",
    "        self.text_embeddings = text_embeddings\n",
    "        self.wav_embeddings = wav_embeddings\n",
    "        self.temp = Temp\n",
    "        self.eda = EDA\n",
    "        self.label_emotion = Emotion\n",
    "        self.label_emotion_vec = Emotion_vec\n",
    "        self.label_arousal = Arousal\n",
    "        self.label_valence = Valence\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_embeddings = self.text_embeddings[idx]\n",
    "        wav_embeddings = self.wav_embeddings[idx]\n",
    "        temp = self.temp[idx]\n",
    "        eda = self.eda[idx]\n",
    "        label_emotion = self.label_emotion[idx]\n",
    "        label_emotion_ext = self.label_emotion_vec[idx]\n",
    "        label_arousal = self.label_arousal[idx]\n",
    "        label_valence = self.label_valence[idx]\n",
    "        return text_embeddings, wav_embeddings, temp, eda, label_emotion, label_emotion_ext, label_arousal, label_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Segment ID', 'Emotion', 'Valence', 'Arousal', 'emotion_vector',\n",
       "       'valence_vector', 'arousal_vector', 'EDA', 'TEMP', 'EDA length',\n",
       "       'TEMP length', 'Scaled EDA', 'Scaled TEMP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_train_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.0672257114501823, -1.1190632255018322, 0.46...\n",
       "1        [0.022837937219205698, -0.8803725498531865, 2....\n",
       "2        [0.6005758414230128, 0.14718366123743523, -0.4...\n",
       "3        [-0.04966521073827487, -0.04966521073827487, -...\n",
       "4        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "                               ...                        \n",
       "11920    [1.0248824293032237, -0.8716879365334415, -0.1...\n",
       "11921    [0.9738374515615607, -0.011967660642870578, -0...\n",
       "11922    [-0.011967660642870578, -0.011967660642870578,...\n",
       "11923    [-0.011967660642870578, -0.011967660642870578,...\n",
       "11924    [-0.16042779153088987, -0.16061282278609879, 0...\n",
       "Name: Scaled EDA, Length: 11925, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_train_final['Scaled EDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load 및 나누기: https://076923.github.io/posts/Python-pytorch-11/\n",
    "\n",
    "# annot_train_final, annot_test_final, annot_val_final\n",
    "# emb_train_final, emb_test_final, emb_val_final\n",
    "\n",
    "# session을 통합시킨 데이터 셋을 만들었을 때\n",
    "dataset_train = EtriDataset(file_names = annot_train_final['Segment ID'],\n",
    "                      text_embeddings = torch.stack(emb_train_final['txt']),\n",
    "                      wav_embeddings = torch.stack(emb_train_final['wav']),\n",
    "                      Emotion = annot_train_final['Emotion'],\n",
    "                      Arousal = annot_train_final['Arousal'],\n",
    "                      Valence = annot_train_final['Valence'],\n",
    "                      EDA = torch.Tensor(annot_train_final['Scaled EDA']), \n",
    "                      Temp = torch.Tensor(annot_train_final['Scaled TEMP']), \n",
    "                      Emotion_vec = torch.Tensor(annot_train_final['emotion_vector'])) \n",
    "\n",
    "\n",
    "dataset_test = EtriDataset(file_names = annot_test_final['Segment ID'],\n",
    "                      text_embeddings = torch.stack(emb_test_final['txt']),\n",
    "                      wav_embeddings = torch.stack(emb_test_final['wav']),\n",
    "                      Emotion = annot_test_final['Emotion'],\n",
    "                      Arousal = annot_test_final['Arousal'],\n",
    "                      Valence = annot_test_final['Valence'],\n",
    "                      EDA = torch.Tensor(annot_test_final['Scaled EDA']), \n",
    "                      Temp = torch.Tensor(annot_test_final['Scaled TEMP']), \n",
    "                      Emotion_vec = torch.Tensor(annot_test_final['emotion_vector']))\n",
    "\n",
    "dataset_val = EtriDataset(file_names = annot_val_final['Segment ID'],\n",
    "                      text_embeddings = torch.stack(emb_val_final['txt']),\n",
    "                      wav_embeddings = torch.stack(emb_val_final['wav']),\n",
    "                      Emotion = annot_val_final['Emotion'],\n",
    "                      Arousal = annot_val_final['Arousal'],\n",
    "                      Valence = annot_val_final['Valence'],\n",
    "                      EDA = torch.Tensor(annot_val_final['Scaled EDA']), \n",
    "                      Temp = torch.Tensor(annot_val_final['Scaled TEMP']), \n",
    "                      Emotion_vec = torch.Tensor(annot_val_final['emotion_vector'])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size : 11925\n",
      "Validation Data Size : 2759\n",
      "Testing Data Size : 2442\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Size : {len(dataset_train)}\")\n",
    "print(f\"Validation Data Size : {len(dataset_val)}\")\n",
    "print(f\"Testing Data Size : {len(dataset_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset_train, batch_size=512, shuffle=True, drop_last=True)\n",
    "validation_dataloader = DataLoader(dataset_val, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(dataset_test, batch_size=128, shuffle=True, drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetWork 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNetwork_pre(nn.Module):\n",
    "    def __init__(self, input_length, input_width):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_length*input_width, 768)\n",
    "        self.gelu1 = nn.GELU()\n",
    "        self.bn1 = nn.BatchNorm1d(768)\n",
    "        self.fc2 = nn.Linear(768, 512)\n",
    "        self.gelu2 = nn.GELU()\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 32)\n",
    "        self.gelu3 = nn.GELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.gelu2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc3(x)\n",
    "        output = self.gelu3(x)\n",
    "        return output\n",
    "    \n",
    "class ConvNetwork_pre(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels = 1, out_channels= 1, kernel_size = 16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.transpose(x, 1,2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        output = self.relu2(x)\n",
    "        return output\n",
    "\n",
    "class ConvNetwork_middle(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=1, kernel_size=11)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        output = self.relu1(x)\n",
    "        return output.squeeze()\n",
    "\n",
    "class ConvNetwork_final(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv2d_1 = nn.Conv2d(in_channels = 10, out_channels = 64, kernel_size=2)\n",
    "        self.leakyrelu_1 = nn.LeakyReLU()\n",
    "        self.maxpool2d_1 = nn.MaxPool2d(2)\n",
    "        self.conv2d_2 = nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size=2)\n",
    "        self.leakyrelu_2 = nn.LeakyReLU()\n",
    "        self.maxpool2d_2 = nn.MaxPool2d(2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(1568, 64)\n",
    "        self.leakyrelu_3 = nn.LeakyReLU()\n",
    "        self.batchnorm = nn.BatchNorm1d(64)\n",
    "        self.drop = nn.Dropout(p=0.25)\n",
    "        self.fc2 = nn.Linear(64, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d_1(x)\n",
    "        x = self.leakyrelu_1(x)\n",
    "        x = self.maxpool2d_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.leakyrelu_2(x)\n",
    "        x = self.maxpool2d_2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.leakyrelu_3(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.drop(x)\n",
    "        output = self.fc2(x)\n",
    "        return output\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorFusionMixer(nn.Module):\n",
    "    def __init__(self, ModelA, ModelB, ModelC, ModelD, ModelE, ModelF):\n",
    "        super().__init__()\n",
    "        self.ModelA = ModelA\n",
    "        self.ModelB = ModelB\n",
    "        self.ModelC = ModelC\n",
    "        self.ModelD = ModelD\n",
    "        self.ModelE = ModelE\n",
    "        self.Model_cnn_final = ModelF\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def tensor_fusion(self, batch_arr1, batch_arr2, batch_arr3):\n",
    "        fusion_matrix_lst = []\n",
    "        for i, (arr1, arr2, arr3) in enumerate(zip(batch_arr1, batch_arr2, batch_arr3)):\n",
    "            # arr1 = arr1.unsqueeze(-1).unsqueeze(-1)\n",
    "            # arr2 = arr2.unsqueeze(0).unsqueeze(-1)\n",
    "            # arr3 = arr3.squeeze().unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "            arr1 = arr1.unsqueeze(0).unsqueeze(0)\n",
    "            arr2 = arr2.unsqueeze(0).unsqueeze(-1)\n",
    "            arr3 = arr3.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "            # outer_matrix = torch.einsum('i,j,kp->ijk', arr1, arr2, arr3)\n",
    "            kron_matrix = torch.kron(arr3, torch.kron(arr2, arr1,))\n",
    "            l, w, d = kron_matrix.shape\n",
    "\n",
    "            kron_matrix = kron_matrix.view(-1, l, w, d)\n",
    "            fusion_matrix_lst.append(kron_matrix)\n",
    "\n",
    "        fusion_matrix = torch.concat(fusion_matrix_lst)\n",
    "        # fusion_matrix = fusion_matrix.unsqueeze(-1)\n",
    "\n",
    "        return fusion_matrix\n",
    "    \n",
    "    def forward(self, x1, x2, x3, x4):\n",
    "            x1 = self.ModelA(x1)\n",
    "            x2 = self.ModelB(x2)\n",
    "            x3 = self.ModelC(x3)\n",
    "            x4 = self.ModelD(x4)\n",
    "            x5 = torch.concat([x3, x4], dim=1)\n",
    "            x5 = self.ModelE(x5)\n",
    "            # print(x1.shape, x2.shape, x5.shape)\n",
    "            fusion_matrix = self.tensor_fusion(x1, x2, x5)\n",
    "            # x5 = torch.cat([x3,x4], dim=0)\n",
    "            output = self.Model_cnn_final(fusion_matrix) \n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n",
      "DataParallel(\n",
      "  (module): TensorFusionMixer(\n",
      "    (ModelA): MLPNetwork_pre(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=61440, out_features=768, bias=True)\n",
      "      (gelu1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc2): Linear(in_features=768, out_features=512, bias=True)\n",
      "      (gelu2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc3): Linear(in_features=512, out_features=32, bias=True)\n",
      "      (gelu3): GELU(approximate='none')\n",
      "    )\n",
      "    (ModelB): MLPNetwork_pre(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=152576, out_features=768, bias=True)\n",
      "      (gelu1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc2): Linear(in_features=768, out_features=512, bias=True)\n",
      "      (gelu2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc3): Linear(in_features=512, out_features=32, bias=True)\n",
      "      (gelu3): GELU(approximate='none')\n",
      "    )\n",
      "    (ModelC): ConvNetwork_pre(\n",
      "      (conv1): Conv1d(1, 1, kernel_size=(16,), stride=(1,))\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv1d(1, 1, kernel_size=(16,), stride=(1,))\n",
      "      (relu2): ReLU()\n",
      "    )\n",
      "    (ModelD): ConvNetwork_pre(\n",
      "      (conv1): Conv1d(1, 1, kernel_size=(16,), stride=(1,))\n",
      "      (relu1): ReLU()\n",
      "      (conv2): Conv1d(1, 1, kernel_size=(16,), stride=(1,))\n",
      "      (relu2): ReLU()\n",
      "    )\n",
      "    (ModelE): ConvNetwork_middle(\n",
      "      (conv1): Conv1d(2, 1, kernel_size=(11,), stride=(1,))\n",
      "      (relu1): ReLU()\n",
      "    )\n",
      "    (Model_cnn_final): ConvNetwork_final(\n",
      "      (conv2d_1): Conv2d(10, 64, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (leakyrelu_1): LeakyReLU(negative_slope=0.01)\n",
      "      (maxpool2d_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (conv2d_2): Conv2d(64, 32, kernel_size=(2, 2), stride=(1, 1))\n",
      "      (leakyrelu_2): LeakyReLU(negative_slope=0.01)\n",
      "      (maxpool2d_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=1568, out_features=64, bias=True)\n",
      "      (leakyrelu_3): LeakyReLU(negative_slope=0.01)\n",
      "      (batchnorm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop): Dropout(p=0.25, inplace=False)\n",
      "      (fc2): Linear(in_features=64, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# txt_input_length, txt_input_width = raw_dataset[session]['textembeddings'][0].shape | 마지막엔 지울 것\n",
    "# , wav_input_length, wav_input_width = raw_dataset[session]['wav_embeddings'][0].shape\n",
    "txt_input_length, txt_input_width = torch.Tensor(emb_train_final['txt'][0]).shape\n",
    "wav_input_length, wav_input_width = torch.Tensor(emb_train_final['wav'][0]).shape\n",
    "# temp_input_length = annot_train_final['Scaled EDA'][0].shape[0]\n",
    "# eda_input_length = annot_train_final['Scaled TEMP'][0].shape[0]\n",
    "\n",
    "# tf_mixer에 들어갈 wav mlp, txt mlp 선언\n",
    "model_mlp_txt = MLPNetwork_pre(txt_input_length,txt_input_width).to(device)\n",
    "model_mlp_wav = MLPNetwork_pre(wav_input_length,wav_input_width).to(device)\n",
    "\n",
    "model_conv_temp = ConvNetwork_pre().to(device)\n",
    "model_conv_eda = ConvNetwork_pre().to(device)\n",
    "\n",
    "model_conv_middle = ConvNetwork_middle().to(device)\n",
    "\n",
    "model_cnn_final = ConvNetwork_final().to(device)\n",
    "\n",
    "# 최종 모델 선언\n",
    "model_tf_cnn_mixer = TensorFusionMixer(ModelA = model_mlp_txt, \n",
    "                                   ModelB = model_mlp_wav,\n",
    "                                   ModelC = model_conv_temp,\n",
    "                                   ModelD = model_conv_eda,\n",
    "                                   ModelE = model_conv_middle,\n",
    "                                   ModelF = model_cnn_final).to(device)\n",
    "\n",
    "# model 병렬 학습 처리\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model_mlp_txt = nn.DataParallel(model_mlp_txt).to(device)\n",
    "    model_mlp_wav = nn.DataParallel(model_mlp_wav).to(device)\n",
    "    model_conv_temp = nn.DataParallel(model_conv_temp).to(device)\n",
    "    model_conv_eda = nn.DataParallel(model_conv_eda).to(device)\n",
    "    model_tf_cnn_mixer = nn.DataParallel(model_tf_cnn_mixer).to(device)\n",
    "\n",
    "print(model_tf_cnn_mixer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습을 위한 train, test method 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)    \n",
    "    # data 순서: text_embeddings, wav_embeddings, temp, eda, label_emotion, label_emotion_ext, label_arousal, label_valence\n",
    "    for batch, (X_txt, X_wav, X_temp, X_eda, \n",
    "                    label_emotion, label_emotion_vec, label_arousal, label_valence) in enumerate(dataloader): \n",
    "        y = label_emotion_vec # 라벨을 변경하고자 하면 이 변수만 바꿔주면 나머지는 y로 적용\n",
    "        # 예측 오류 계산 \n",
    "        X_txt, X_wav, X_temp, X_eda, y= X_txt.to(device), X_wav.to(device), X_temp.to(device), X_eda.to(device),y.type(torch.float32).to(device)\n",
    "        \n",
    "        X_temp = X_temp.unsqueeze(dim=-1)\n",
    "        X_eda = X_eda.unsqueeze(dim=-1)\n",
    "        \n",
    "        pred = model(X_txt, X_wav, X_temp, X_eda)\n",
    "        y = F.softmax(y, dim = 1)\n",
    "        \n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.mean().backward() # weighted MSE를 사용할 경우 중간에 sum() or mean()을 넣어줌\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.mean().mean().item(), batch * len(X_txt) # weighted MSE를 사용할 경우 중간에 sum() or mean()을 넣어줌\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_multiple_class(probs, threshold = 0.1):\n",
    "    values = probs.topk(2)\n",
    "    pred_list = []\n",
    "    # print(values)\n",
    "    diffs = abs(torch.diff(values.values))\n",
    "    for idx,diff in zip(values.indices, diffs):\n",
    "        if diff <= threshold:\n",
    "            sorted, idx = torch.sort(idx)\n",
    "            if sorted[0] == 0:\n",
    "                pred_list.append(100*7 + 10*sorted[1].item())\n",
    "            else:\n",
    "                pred_list.append(100*sorted[0].item() + 10*sorted[1].item())\n",
    "        else:\n",
    "            pred_list.append(idx[0].item())\n",
    "    return torch.Tensor(pred_list).to(device), probs.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn, mode = 'test'):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    f1 = F1Score(task= 'multiclass', num_classes=37).to(device)   # 바로 multiclassification할 경우\n",
    "    preds = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # data 순서: text_embeddings, wav_embeddings, temp, eda, label_emotion, label_emotion_ext, label_arousal, label_valence\n",
    "        for batch, (X_txt, X_wav, X_temp, X_eda, \n",
    "                        label_emotion, label_emotion_vec, label_arousal, label_valence) in enumerate(dataloader): \n",
    "            y = label_emotion_vec # 라벨을 변경하고자 하면 이 변수만 바꿔주면 나머지는 y로 적용\n",
    "            # 예측 오류 계산\n",
    "            X_txt, X_wav, X_temp, X_eda, y= X_txt.to(device), X_wav.to(device), X_temp.to(device), X_eda.to(device),y.type(torch.float32).to(device)\n",
    "            \n",
    "            X_temp = X_temp.unsqueeze(dim=-1)\n",
    "            X_eda = X_eda.unsqueeze(dim=-1)\n",
    "            \n",
    "            pred = model(X_txt, X_wav, X_temp, X_eda)\n",
    "            pred_for_acc, _ = cal_multiple_class(pred)\n",
    "            \n",
    "            preds.append(pred_for_acc)\n",
    "            y = F.softmax(y, dim = 1)\n",
    "            # preds.append(pred.argmax(1)) # multi regression후 classification으로 변환할 경우\n",
    "\n",
    "            targets.append(label_emotion) # classification을 할 경우 언제나 사용\n",
    "            # print('예측라벨분포:',pred[:2], '정답라벨 분포:', label_emotion_ext[:2], '예측정답:', pred.argmax(1)[:2],'정답:', label_emotion[:2])\n",
    "            # print('예측:', pred.argmax(1).tolist()[:2],'\\n', '정답:', label_emotion.tolist()[:2])\n",
    "            # https://discuss.pytorch.org/t/loss-backward-raises-error-grad-can-be-implicitly-created-only-for-scalar-outputs/12152/6\n",
    "            test_loss += loss_fn(pred, y).mean().item()# weighted MSE를 사용할 경우 중간에 sum() or mean()을 넣어줌 \n",
    "            \n",
    "            correct += (pred.argmax(1) == label_emotion.to(device)).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    f1_score = f1(torch.cat(preds).to(device), torch.cat(targets).to(device))\n",
    "    accuracy = (100*correct)\n",
    "    \n",
    "    if mode == 'test':\n",
    "        print(torch.cat(preds), torch.cat(preds).shape)\n",
    "        print(\"f1 score: \", f1_score)\n",
    "        print(f\"Test Error: Accuracy: {(accuracy):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")\n",
    "    elif mode == 'val':\n",
    "        print(f\"Validation Error: Accuracy: {(accuracy):>0.1f}%, Avg val loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    return f1_score, accuracy, test_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total obs:  10975\n",
      "Counter({4: 5000, 3: 1856, 0: 1603, 6: 1008, 5: 731, 1: 394, 2: 383, 340: 345, 40: 128, 450: 105, 460: 90, 140: 77, 10: 41, 350: 31, 250: 23, 240: 21, 50: 13, 60: 13, 20: 9, 7140: 6, 560: 6, 7340: 4, 260: 3, 150: 3, 730: 3, 7240: 3, 120: 3, 1450: 2, 230: 2, 4560: 2, 3450: 2, 2340: 2, 1460: 2, 360: 2, 7250: 1, 7450: 1, 2450: 1, 3460: 1, 130: 1, 20000: 1, 160: 1, 10000: 1, 3410: 1})\n",
      "0 is in single emotion\n",
      "1 is in single emotion\n",
      "2 is in single emotion\n",
      "3 is in single emotion\n",
      "4 is in single emotion\n",
      "5 is in single emotion\n",
      "6 is in single emotion\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.8540, 0.9639, 0.9653, 0.8311, 0.5444, 0.9336, 0.9082],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weigted loss for imbalance data: https://naadispeaks.wordpress.com/2021/07/31/handling-imbalanced-classes-with-weighted-loss-in-pytorch/\n",
    "# weight 계산\n",
    "single_emotion = [0,1,2,3,4,5,6]\n",
    "total_obs = 0\n",
    "for i in single_emotion:\n",
    "    total_obs += Counter(annot_train_final['Emotion'])[i]\n",
    "print('total obs: ', total_obs)\n",
    "\n",
    "weight_for_class = []\n",
    "print(Counter(annot_train_final['Emotion']))\n",
    "for key, value in sorted(Counter(annot_train_final['Emotion']).items()):\n",
    "    if key in single_emotion:\n",
    "        print(f'{key} is in single emotion')\n",
    "        if key == 'neutral':\n",
    "            weight_for_class.append(1 - (1440/total_obs))\n",
    "        else:\n",
    "            weight_for_class.append(1 - (value/total_obs))\n",
    "weight_for_class = torch.Tensor(weight_for_class).type(torch.float16)\n",
    "weight_for_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class weighted_MSELoss(nn.Module):\n",
    "    def __init__(self, weight):\n",
    "        super().__init__()\n",
    "        self.weight = weight.to(device)\n",
    "    def forward(self,inputs,targets):\n",
    "        return ((inputs - targets)**2) * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 지난 저장한 모델이 있다면\n",
    "# PATH = './data/test_model.pkl'\n",
    "# model_tf_mixer = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.CrossEntropyLoss(weight=weight_for_class).to(device)\n",
    "# loss_fn = nn.CrossEntropyLoss().to(device) # weigth를 주기위해 위의 loss로 임시 변경\n",
    "loss_fn = weighted_MSELoss(weight = weight_for_class).to(device) # multi target regression(감정별로 count 한 타겟)\n",
    "# loss_fn = nn.MSELoss().to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "# optimizer = optim.SGD(model_tf_mixer.parameters(), lr=lr) # classification\n",
    "optimizer = optim.Adagrad(model_tf_cnn_mixer.parameters(), lr=lr) # regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start training mlp fusion mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/arplab/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "!wandb login --relogin \"9bccad4ccb69d37aa82b7b6b8e2e2d3c54f79ab1\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:43lxceex) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.57992</td></tr><tr><td>loss</td><td>0.07625</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sunny-darkness-1</strong> at: <a href='https://wandb.ai/toez/ETRI-lou-multiclassification/runs/43lxceex' target=\"_blank\">https://wandb.ai/toez/ETRI-lou-multiclassification/runs/43lxceex</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230411_165010-43lxceex/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:43lxceex). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/arplab/project/lou/multi_modal/experimental/wandb/run-20230411_165145-cwox04rr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/toez/ETRI-lou-multiclassification/runs/cwox04rr' target=\"_blank\">Experiment Name</a></strong> to <a href='https://wandb.ai/toez/ETRI-lou-multiclassification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/toez/ETRI-lou-multiclassification' target=\"_blank\">https://wandb.ai/toez/ETRI-lou-multiclassification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/toez/ETRI-lou-multiclassification/runs/cwox04rr' target=\"_blank\">https://wandb.ai/toez/ETRI-lou-multiclassification/runs/cwox04rr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/toez/ETRI-lou-multiclassification/runs/cwox04rr?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe9879172b0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wandb\n",
    "epochs = 50\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"ETRI-lou-multiclassification\",\n",
    "    name = f'Experiment Name',\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": lr,\n",
    "    \"architecture\": \"CNN Tensor Fusion Mixer\",\n",
    "    \"dataset\": \"ETRI Kemdy20\",\n",
    "    \"epochs\": epochs,\n",
    "    \"Optimizer\": optimizer.__class__.__name__,\n",
    "    \"Loss\": loss_fn.__class__.__name__\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch 1----------------\n",
      "loss: 0.084427  [    0/11925]\n",
      "Validation Error: Accuracy: 81.2%, Avg val loss: 0.038802 \n",
      "\n",
      "best_acc: 81.15259151866618\n",
      "best_f1: tensor(0.8103, device='cuda:0')\n",
      "---------------Epoch 2----------------\n",
      "loss: 0.062894  [    0/11925]\n",
      "Validation Error: Accuracy: 79.5%, Avg val loss: 0.038152 \n",
      "\n",
      "---------------Epoch 3----------------\n",
      "loss: 0.062250  [    0/11925]\n",
      "Validation Error: Accuracy: 76.0%, Avg val loss: 0.044005 \n",
      "\n",
      "---------------Epoch 4----------------\n",
      "loss: 0.067057  [    0/11925]\n",
      "Validation Error: Accuracy: 76.8%, Avg val loss: 0.040807 \n",
      "\n",
      "---------------Epoch 5----------------\n",
      "loss: 0.060425  [    0/11925]\n",
      "Validation Error: Accuracy: 63.1%, Avg val loss: 0.051768 \n",
      "\n",
      "---------------Epoch 6----------------\n",
      "loss: 0.063029  [    0/11925]\n",
      "Validation Error: Accuracy: 79.6%, Avg val loss: 0.035154 \n",
      "\n",
      "---------------Epoch 7----------------\n",
      "loss: 0.059550  [    0/11925]\n",
      "Validation Error: Accuracy: 69.2%, Avg val loss: 0.044627 \n",
      "\n",
      "---------------Epoch 8----------------\n",
      "loss: 0.061465  [    0/11925]\n",
      "Validation Error: Accuracy: 73.1%, Avg val loss: 0.043189 \n",
      "\n",
      "---------------Epoch 9----------------\n",
      "loss: 0.059320  [    0/11925]\n",
      "Validation Error: Accuracy: 43.7%, Avg val loss: 0.056620 \n",
      "\n",
      "---------------Epoch 10----------------\n",
      "loss: 0.061188  [    0/11925]\n",
      "Validation Error: Accuracy: 71.4%, Avg val loss: 0.042693 \n",
      "\n",
      "---------------Epoch 11----------------\n",
      "loss: 0.056625  [    0/11925]\n",
      "Validation Error: Accuracy: 53.6%, Avg val loss: 0.051140 \n",
      "\n",
      "---------------Epoch 12----------------\n",
      "loss: 0.057737  [    0/11925]\n",
      "Validation Error: Accuracy: 72.2%, Avg val loss: 0.039168 \n",
      "\n",
      "---------------Epoch 13----------------\n",
      "loss: 0.056454  [    0/11925]\n",
      "Validation Error: Accuracy: 43.1%, Avg val loss: 0.057616 \n",
      "\n",
      "---------------Epoch 14----------------\n",
      "loss: 0.053562  [    0/11925]\n",
      "Validation Error: Accuracy: 67.6%, Avg val loss: 0.048736 \n",
      "\n",
      "---------------Epoch 15----------------\n",
      "loss: 0.060239  [    0/11925]\n",
      "Validation Error: Accuracy: 58.4%, Avg val loss: 0.048897 \n",
      "\n",
      "---------------Epoch 16----------------\n",
      "loss: 0.053289  [    0/11925]\n",
      "Validation Error: Accuracy: 34.5%, Avg val loss: 0.062450 \n",
      "\n",
      "---------------Epoch 17----------------\n",
      "loss: 0.055751  [    0/11925]\n",
      "Validation Error: Accuracy: 64.5%, Avg val loss: 0.044611 \n",
      "\n",
      "---------------Epoch 18----------------\n",
      "loss: 0.053089  [    0/11925]\n",
      "Validation Error: Accuracy: 38.7%, Avg val loss: 0.061132 \n",
      "\n",
      "---------------Epoch 19----------------\n",
      "loss: 0.047708  [    0/11925]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     12\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m---------------Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m----------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     train(train_dataloader, model_tf_cnn_mixer, loss_fn, optimizer)\n\u001b[1;32m     14\u001b[0m     f1_score, accuracy, loss \u001b[39m=\u001b[39m test(validation_dataloader, model_tf_cnn_mixer, loss_fn, mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[39mif\u001b[39;00m accuracy \u001b[39m>\u001b[39m best_acc:\n",
      "Cell \u001b[0;32mIn[94], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m# 역전파\u001b[39;00m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 20\u001b[0m loss\u001b[39m.\u001b[39;49mmean()\u001b[39m.\u001b[39;49mbackward() \u001b[39m# weighted MSE를 사용할 경우 중간에 sum() or mean()을 넣어줌\u001b[39;00m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m \u001b[39mif\u001b[39;00m batch \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/project/lou/multi_modal/.venv/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/project/lou/multi_modal/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set the Training Parameters\n",
    "from copy import deepcopy\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "best_acc_model = None \n",
    "best_f1_model = None\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"---------------Epoch {epoch+1}----------------\")\n",
    "    train(train_dataloader, model_tf_cnn_mixer, loss_fn, optimizer)\n",
    "    f1_score, accuracy, loss = test(validation_dataloader, model_tf_cnn_mixer, loss_fn, mode = 'val')\n",
    "    if accuracy > best_acc:\n",
    "        best_acc = accuracy\n",
    "        best_acc_model = deepcopy(model_tf_cnn_mixer.state_dict())\n",
    "        print('best_acc:', best_acc)\n",
    "    if f1_score > best_f1:\n",
    "        best_f1 = f1_score\n",
    "        best_f1_model = deepcopy(model_tf_cnn_mixer.state_dict())\n",
    "        print('best_f1:', best_f1)\n",
    "    loss_list.append(loss)\n",
    "    acc_list.append(accuracy)\n",
    "    wandb.log({'accuracy': accuracy, 'loss': loss})\n",
    "wandb.finish()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험을 위해 모델 저장\n",
    "PATH = '../model/data/model_multilabel_CNNf1_8103.pkl'\n",
    "torch.save(best_f1_model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 4, 4,  ..., 4, 0, 4], device='cuda:0') torch.Size([4480])\n",
      "f1 score:  tensor(0.4583, device='cuda:0')\n",
      "Test Error: Accuracy: 45.4%, Avg loss: 0.065306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(test_dataloader, model_tf_cnn_mixer, loss_fn, mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4593, -0.0085, -1.1601,  ..., -0.7082,  1.1274, -0.3243],\n",
      "         [-0.5511,  0.0475, -1.1391,  ..., -0.6807,  1.1464, -0.2989],\n",
      "         [-0.4926,  0.0148, -1.1642,  ..., -0.6688,  1.1545, -0.3236],\n",
      "         ...,\n",
      "         [-0.4815,  0.0169, -1.2180,  ..., -0.6512,  0.9577, -0.3519],\n",
      "         [-0.4815,  0.0169, -1.2180,  ..., -0.6512,  0.9577, -0.3519],\n",
      "         [-0.4815,  0.0169, -1.2180,  ..., -0.6512,  0.9577, -0.3519]],\n",
      "\n",
      "        [[-0.4723,  0.0884, -1.1636,  ..., -0.7154,  1.0938, -0.2687],\n",
      "         [-0.5448,  0.1459, -1.0904,  ..., -0.6576,  1.0684, -0.1930],\n",
      "         [-0.5538,  0.0875, -1.1415,  ..., -0.7035,  1.1440, -0.2562],\n",
      "         ...,\n",
      "         [-0.4962,  0.1042, -1.2488,  ..., -0.6564,  0.9447, -0.2766],\n",
      "         [-0.4962,  0.1042, -1.2488,  ..., -0.6564,  0.9447, -0.2766],\n",
      "         [-0.4962,  0.1042, -1.2488,  ..., -0.6564,  0.9447, -0.2766]],\n",
      "\n",
      "        [[-0.5212, -0.0179, -1.0805,  ..., -0.7620,  1.1764, -0.2533],\n",
      "         [-0.5802,  0.0212, -1.0472,  ..., -0.7233,  1.1818, -0.2263],\n",
      "         [-0.5491, -0.0063, -1.0969,  ..., -0.7256,  1.1983, -0.2622],\n",
      "         ...,\n",
      "         [-0.5483,  0.0113, -1.1442,  ..., -0.7065,  1.0225, -0.2707],\n",
      "         [-0.5483,  0.0113, -1.1442,  ..., -0.7065,  1.0225, -0.2707],\n",
      "         [-0.5483,  0.0113, -1.1442,  ..., -0.7065,  1.0225, -0.2707]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4774,  0.0820, -1.1522,  ..., -0.7827,  1.1248, -0.2341],\n",
      "         [-0.5791,  0.0820, -1.0858,  ..., -0.7487,  1.1600, -0.1844],\n",
      "         [-0.5664,  0.0886, -1.1400,  ..., -0.7462,  1.1454, -0.1980],\n",
      "         ...,\n",
      "         [-0.5004,  0.0955, -1.2355,  ..., -0.7213,  0.9594, -0.2433],\n",
      "         [-0.5004,  0.0955, -1.2355,  ..., -0.7213,  0.9594, -0.2433],\n",
      "         [-0.5004,  0.0955, -1.2355,  ..., -0.7213,  0.9594, -0.2433]],\n",
      "\n",
      "        [[-0.5092, -0.0530, -1.1063,  ..., -0.6780,  1.1165, -0.2738],\n",
      "         [-0.5826, -0.0258, -1.0494,  ..., -0.6435,  1.1324, -0.2526],\n",
      "         [-0.5594, -0.0298, -1.1109,  ..., -0.6398,  1.1158, -0.2563],\n",
      "         ...,\n",
      "         [-0.5243, -0.0202, -1.1658,  ..., -0.6289,  0.9787, -0.2839],\n",
      "         [-0.5243, -0.0202, -1.1658,  ..., -0.6289,  0.9787, -0.2839],\n",
      "         [-0.5243, -0.0202, -1.1658,  ..., -0.6289,  0.9787, -0.2839]],\n",
      "\n",
      "        [[-0.4837,  0.0969, -1.1368,  ..., -0.7883,  1.1092, -0.1925],\n",
      "         [-0.5713,  0.1160, -1.0732,  ..., -0.7524,  1.1324, -0.1692],\n",
      "         [-0.5483,  0.1169, -1.1391,  ..., -0.7453,  1.1138, -0.1759],\n",
      "         ...,\n",
      "         [-0.5109,  0.1030, -1.2231,  ..., -0.7225,  0.9405, -0.1992],\n",
      "         [-0.5109,  0.1030, -1.2231,  ..., -0.7225,  0.9405, -0.1992],\n",
      "         [-0.5109,  0.1030, -1.2231,  ..., -0.7225,  0.9405, -0.1992]]]) tensor([[[-3.8033e-01, -2.7109e-02,  3.4648e-02,  ...,  2.1921e-01,\n",
      "           6.4893e-01,  2.6749e-01],\n",
      "         [-3.4468e-01, -1.2350e-02,  2.9507e-02,  ...,  2.0305e-01,\n",
      "           6.3606e-01,  2.7359e-01],\n",
      "         [-3.2831e-01, -4.7343e-03,  1.6509e-02,  ...,  2.0603e-01,\n",
      "           6.2386e-01,  2.7197e-01],\n",
      "         ...,\n",
      "         [-7.1180e-01,  5.6639e-02, -2.8992e-01,  ...,  6.0867e-02,\n",
      "           5.3483e-01,  2.3623e-01],\n",
      "         [-5.2346e-01,  2.0899e-02,  1.8176e-01,  ...,  2.3753e-02,\n",
      "           3.7932e-01, -1.3780e-01],\n",
      "         [-5.0459e-01, -7.0285e-03,  1.7921e-01,  ...,  3.7433e-02,\n",
      "           3.9000e-01, -1.3797e-01]],\n",
      "\n",
      "        [[-5.8722e-01, -2.1874e-01, -7.4303e-02,  ...,  2.4708e-01,\n",
      "           7.6697e-01, -2.2795e-01],\n",
      "         [-6.9905e-01, -3.4792e-01, -5.6795e-01,  ...,  1.3873e-01,\n",
      "           5.8137e-01, -1.0161e-02],\n",
      "         [ 1.0338e-01, -3.0758e-01, -1.8659e-01,  ..., -1.0697e-01,\n",
      "          -1.1314e-01,  1.2956e-01],\n",
      "         ...,\n",
      "         [-2.7439e-01, -4.0000e-01, -5.5112e-04,  ...,  1.0715e-01,\n",
      "           3.5650e-01,  6.8740e-02],\n",
      "         [-3.6645e-01, -8.3343e-02,  5.7059e-02,  ...,  3.7596e-01,\n",
      "           3.8723e-01, -1.0159e-02],\n",
      "         [-3.2531e-01,  1.1564e-02, -3.7108e-02,  ...,  3.7419e-01,\n",
      "           5.2608e-01, -6.6456e-02]],\n",
      "\n",
      "        [[-1.2130e-01,  2.4251e-01,  2.5018e-01,  ...,  4.9886e-01,\n",
      "           3.7773e-01,  4.1605e-01],\n",
      "         [-1.2127e-01,  2.3352e-01,  2.5693e-01,  ...,  4.9089e-01,\n",
      "           3.6562e-01,  4.0686e-01],\n",
      "         [-1.1372e-01,  2.3318e-01,  2.5701e-01,  ...,  4.8914e-01,\n",
      "           3.5867e-01,  4.0021e-01],\n",
      "         ...,\n",
      "         [-1.0296e-01,  2.3409e-01,  2.3863e-01,  ...,  4.8939e-01,\n",
      "           3.7096e-01,  3.9090e-01],\n",
      "         [-1.1564e-01,  2.4011e-01,  2.3428e-01,  ...,  4.9759e-01,\n",
      "           3.8460e-01,  4.0253e-01],\n",
      "         [-1.2278e-01,  2.4901e-01,  2.3762e-01,  ...,  5.1610e-01,\n",
      "           3.9287e-01,  4.2293e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.6707e-01,  5.8217e-02,  3.3509e-02,  ...,  2.5813e-01,\n",
      "           6.0430e-01,  2.6431e-01],\n",
      "         [-2.2910e-01,  2.5953e-02,  3.1570e-02,  ...,  2.5217e-01,\n",
      "           5.5197e-01,  2.3743e-01],\n",
      "         [-2.0979e-01,  1.9027e-03,  4.0171e-02,  ...,  2.5232e-01,\n",
      "           5.1460e-01,  2.2468e-01],\n",
      "         ...,\n",
      "         [-1.6345e-01, -7.0868e-02, -9.5470e-02,  ..., -5.0804e-02,\n",
      "           4.6483e-02,  3.7892e-01],\n",
      "         [-4.2645e-01, -1.0804e-01,  3.2781e-01,  ...,  2.5926e-01,\n",
      "           2.5963e-01,  4.2513e-01],\n",
      "         [-5.6160e-01,  1.5638e-01,  2.4388e-01,  ...,  4.1009e-01,\n",
      "           4.3831e-01,  1.1669e-01]],\n",
      "\n",
      "        [[-6.2627e-01,  2.3976e-01, -6.3896e-02,  ...,  3.4014e-01,\n",
      "           5.4542e-01,  2.8852e-01],\n",
      "         [-3.0381e-01,  9.8474e-02, -3.2466e-01,  ...,  2.4244e-02,\n",
      "           2.9982e-01,  3.5498e-01],\n",
      "         [-2.0625e-01,  1.8346e-01, -3.3164e-01,  ..., -3.3276e-02,\n",
      "           8.3076e-02,  3.4018e-01],\n",
      "         ...,\n",
      "         [-3.3234e-01,  1.9394e-01,  5.6493e-02,  ...,  2.1982e-01,\n",
      "           5.7581e-01,  3.3577e-01],\n",
      "         [-5.4721e-01,  1.9541e-01,  8.1447e-02,  ...,  3.6694e-01,\n",
      "           6.5101e-01,  2.3516e-01],\n",
      "         [-6.8703e-01,  2.6167e-01,  3.1632e-01,  ...,  4.0166e-01,\n",
      "           1.8155e-01, -7.6250e-02]],\n",
      "\n",
      "        [[-2.9175e-01,  1.2017e-01,  4.1349e-03,  ...,  3.9326e-01,\n",
      "           9.1072e-01,  3.5795e-01],\n",
      "         [-2.7765e-01,  1.7788e-01,  6.2286e-02,  ...,  4.0709e-01,\n",
      "           9.4441e-01,  3.6168e-01],\n",
      "         [-4.0020e-01,  1.2780e-01,  1.2256e-01,  ...,  3.4034e-01,\n",
      "           8.2295e-01,  3.4263e-01],\n",
      "         ...,\n",
      "         [-3.4848e-01,  2.0928e-01,  4.2759e-01,  ...,  1.5145e-01,\n",
      "           1.4951e-01, -1.7239e-01],\n",
      "         [-3.3241e-01,  1.0672e-01,  3.7093e-01,  ...,  2.8598e-01,\n",
      "           3.4305e-01, -2.1342e-01],\n",
      "         [-3.4599e-01,  1.1406e-01,  3.5756e-01,  ...,  3.1322e-01,\n",
      "           3.3963e-01, -1.8142e-01]]]) tensor([  0, 460,   0,   4,   4,   4,   4,   4,   4,   4,   4, 340,   1,   4,\n",
      "          3,   4,   6,   3, 130,   3,   4,   4,   3,   4,   4,   5,   4,   6,\n",
      "          4,   4,   0,   4,   4,   4,   4,   4,   0,   4,   4,   3,   4, 340,\n",
      "          4,   4,   0,   0,   3,   4,   3,   4,   4,   0,   0,   5,   3, 340,\n",
      "          4,   4,   4, 340,   4,   4,   4,   3,   4,   4,   4,   4,   4,   4,\n",
      "          6,   4,   2,   4,   3,   4,   4,   4,   4,   4,   4,   0,   4,   4,\n",
      "          4,   3,   0,   4,   4,   4,   4,   5,   2,   4,   4,   4,   4,   4,\n",
      "          0,   4,   4,   4,   3,   4,   4,   4,   4,   4,   4,   4,   3,   5,\n",
      "          6,   4,   3,   4,   4,   4, 450,   4,   4,   3,   3,   6,   4,   3,\n",
      "          4,   4])\n",
      "tensor([[[-0.4366, -0.0319, -1.1206,  ..., -0.6677,  0.9764, -0.2134],\n",
      "         [-0.5398,  0.0054, -1.1133,  ..., -0.6723,  0.9736, -0.1669],\n",
      "         [-0.4704, -0.0062, -1.0779,  ..., -0.6151,  0.9499, -0.1751],\n",
      "         ...,\n",
      "         [-0.4556,  0.0064, -1.1788,  ..., -0.6076,  0.8351, -0.2270],\n",
      "         [-0.4556,  0.0064, -1.1788,  ..., -0.6076,  0.8351, -0.2270],\n",
      "         [-0.4556,  0.0064, -1.1788,  ..., -0.6076,  0.8351, -0.2270]],\n",
      "\n",
      "        [[-0.4597,  0.0033, -1.1125,  ..., -0.6875,  1.0352, -0.2838],\n",
      "         [-0.5375,  0.0620, -1.0834,  ..., -0.6389,  1.0300, -0.2494],\n",
      "         [-0.5148,  0.0262, -1.1157,  ..., -0.6424,  1.0354, -0.2641],\n",
      "         ...,\n",
      "         [-0.4751,  0.0389, -1.1697,  ..., -0.6380,  0.8887, -0.2938],\n",
      "         [-0.4751,  0.0389, -1.1697,  ..., -0.6380,  0.8887, -0.2938],\n",
      "         [-0.4751,  0.0389, -1.1697,  ..., -0.6380,  0.8887, -0.2938]],\n",
      "\n",
      "        [[-0.5198, -0.0315, -1.1131,  ..., -0.7302,  1.2042, -0.3241],\n",
      "         [-0.6367,  0.0073, -1.0713,  ..., -0.7393,  1.2516, -0.2692],\n",
      "         [-0.5765,  0.0174, -1.1096,  ..., -0.6704,  1.1898, -0.2944],\n",
      "         ...,\n",
      "         [-0.5394, -0.0045, -1.1763,  ..., -0.6836,  1.0494, -0.3461],\n",
      "         [-0.5394, -0.0045, -1.1763,  ..., -0.6836,  1.0494, -0.3461],\n",
      "         [-0.5394, -0.0045, -1.1763,  ..., -0.6836,  1.0494, -0.3461]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4767, -0.0239, -1.1777,  ..., -0.6964,  1.1552, -0.3473],\n",
      "         [-0.5533,  0.0328, -1.1487,  ..., -0.6593,  1.1466, -0.3132],\n",
      "         [-0.5289, -0.0041, -1.1799,  ..., -0.6622,  1.1508, -0.3307],\n",
      "         ...,\n",
      "         [-0.4916, -0.0051, -1.2306,  ..., -0.6580,  1.0076, -0.3695],\n",
      "         [-0.4916, -0.0051, -1.2306,  ..., -0.6580,  1.0076, -0.3695],\n",
      "         [-0.4916, -0.0051, -1.2306,  ..., -0.6580,  1.0076, -0.3695]],\n",
      "\n",
      "        [[-0.4833, -0.0329, -1.1364,  ..., -0.6892,  1.1652, -0.3504],\n",
      "         [-0.5706,  0.0182, -1.1075,  ..., -0.7031,  1.1795, -0.3009],\n",
      "         [-0.5147, -0.0043, -1.1252,  ..., -0.6478,  1.1879, -0.3462],\n",
      "         ...,\n",
      "         [-0.5032, -0.0145, -1.1896,  ..., -0.6522,  1.0144, -0.3568],\n",
      "         [-0.5032, -0.0145, -1.1896,  ..., -0.6522,  1.0144, -0.3568],\n",
      "         [-0.5032, -0.0145, -1.1896,  ..., -0.6522,  1.0144, -0.3568]],\n",
      "\n",
      "        [[-0.4965, -0.0739, -1.1355,  ..., -0.6396,  1.0489, -0.2733],\n",
      "         [-0.5612, -0.0349, -1.1336,  ..., -0.6083,  1.0248, -0.2428],\n",
      "         [-0.5519, -0.0761, -1.1359,  ..., -0.5872,  1.0820, -0.2923],\n",
      "         ...,\n",
      "         [-0.5138, -0.0348, -1.1891,  ..., -0.5819,  0.8899, -0.2909],\n",
      "         [-0.5138, -0.0348, -1.1891,  ..., -0.5819,  0.8899, -0.2909],\n",
      "         [-0.5138, -0.0348, -1.1891,  ..., -0.5819,  0.8899, -0.2909]]]) tensor([[[-0.2016,  0.1112, -0.1429,  ...,  0.2085,  0.4766,  0.5568],\n",
      "         [-0.1782,  0.1045, -0.1208,  ...,  0.1861,  0.4570,  0.5373],\n",
      "         [-0.1597,  0.1085, -0.1023,  ...,  0.1892,  0.4392,  0.5345],\n",
      "         ...,\n",
      "         [-0.3687,  0.1037,  0.1228,  ..., -0.0219,  0.2207, -0.4129],\n",
      "         [-0.3735,  0.1161,  0.1347,  ...,  0.0232,  0.2774, -0.3908],\n",
      "         [-0.4842,  0.0993,  0.1196,  ...,  0.0924,  0.3824, -0.2700]],\n",
      "\n",
      "        [[-0.2819,  0.0663, -0.0904,  ...,  0.3473,  0.8999,  0.3092],\n",
      "         [-0.2654,  0.0484, -0.0873,  ...,  0.3216,  0.9096,  0.3109],\n",
      "         [-0.2424,  0.0525, -0.0804,  ...,  0.3078,  0.8989,  0.3141],\n",
      "         ...,\n",
      "         [-0.4209,  0.1340,  0.2944,  ...,  0.3251,  0.5198, -0.0897],\n",
      "         [-0.4817,  0.0735,  0.1324,  ...,  0.5661,  0.6407, -0.0792],\n",
      "         [-0.4925,  0.0554,  0.0248,  ...,  0.6855,  0.6910, -0.0853]],\n",
      "\n",
      "        [[ 0.0904,  0.1385, -0.0884,  ...,  0.3538,  0.6142,  0.3455],\n",
      "         [ 0.1064,  0.1408, -0.1054,  ...,  0.3464,  0.6140,  0.3324],\n",
      "         [ 0.1265,  0.1490, -0.1180,  ...,  0.3458,  0.6059,  0.3245],\n",
      "         ...,\n",
      "         [-0.4723,  0.0950,  0.3333,  ...,  0.4191, -0.0881, -0.1829],\n",
      "         [-0.4549,  0.2271,  0.3841,  ...,  0.3308,  0.2099, -0.2322],\n",
      "         [-0.4735,  0.2335,  0.3838,  ...,  0.3291,  0.2176, -0.1661]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3819,  0.2287, -0.1659,  ...,  0.3078,  0.8173,  0.3262],\n",
      "         [-0.3714,  0.2325, -0.1558,  ...,  0.2923,  0.8433,  0.3195],\n",
      "         [-0.3580,  0.2425, -0.1503,  ...,  0.2825,  0.8624,  0.3173],\n",
      "         ...,\n",
      "         [-0.3268,  0.0952,  0.3178,  ...,  0.5060,  0.1231,  0.1414],\n",
      "         [-0.6063,  0.1707,  0.1164,  ...,  0.3257,  0.0933,  0.0149],\n",
      "         [-0.4792,  0.2290,  0.0096,  ...,  0.4991,  0.1804,  0.1072]],\n",
      "\n",
      "        [[-0.2171, -0.0029, -0.0397,  ...,  0.4240,  0.6230,  0.5795],\n",
      "         [-0.2058, -0.0193, -0.0428,  ...,  0.4026,  0.6003,  0.5691],\n",
      "         [-0.1838, -0.0237, -0.0378,  ...,  0.4022,  0.5701,  0.5662],\n",
      "         ...,\n",
      "         [-0.4510,  0.0791,  0.4736,  ...,  0.1024,  0.2009, -0.1602],\n",
      "         [-0.4064,  0.0646,  0.5521,  ...,  0.2191,  0.2174, -0.1295],\n",
      "         [-0.4157,  0.0585,  0.5565,  ...,  0.2422,  0.2229, -0.1046]],\n",
      "\n",
      "        [[-0.1696,  0.0687, -0.2656,  ...,  0.2026,  0.5399,  0.4558],\n",
      "         [-0.1541,  0.0745, -0.2592,  ...,  0.1942,  0.5584,  0.4520],\n",
      "         [-0.1431,  0.0859, -0.2569,  ...,  0.1953,  0.5519,  0.4524],\n",
      "         ...,\n",
      "         [-0.2001,  0.1401,  0.3345,  ..., -0.0178,  0.4260, -0.5759],\n",
      "         [-0.2756,  0.2001,  0.2820,  ...,  0.0732,  0.4035, -0.4258],\n",
      "         [-0.2896,  0.2054,  0.2569,  ...,  0.0970,  0.3996, -0.4006]]]) tensor([    4,     6,     4,     4,     6,     4,     4,     4,     4,     4,\n",
      "            4,     0,     1,     0,     4,   340,     3,     4,   460,     3,\n",
      "            4,     4,     4,     4,     4,     4,     4,     4,     4,     4,\n",
      "            4,     6,     3,     4,     4,     3,     4,     4,     4,     4,\n",
      "            4,     4,     3,     4,     4,     4,     4,     4,     4,     4,\n",
      "            0,     6,     3,     4,     3,     4,     4,     4,     4,     4,\n",
      "            3,     4,     3,     3,     4,     3,     4,     3,     4,     4,\n",
      "            4,     4,     0,     0,     2,     6,     4,     4,     3,     4,\n",
      "            4,   340,     4,     4,     3,     4,     4,     4,     1,     4,\n",
      "            4,     4,     4,     3,     4,   340,     4,     4,     4,     3,\n",
      "            4,     4,     4,     4,     0,     2,     4,     3,     4,     4,\n",
      "           40,     4,   340,     4,     4,     4,     4,     4,     4,     4,\n",
      "        20000,     5,     6,     0,   140,     6,     4,    40])\n",
      "tensor([[[-4.7656e-01, -2.4814e-04, -1.1819e+00,  ..., -7.3213e-01,\n",
      "           1.1307e+00, -2.6125e-01],\n",
      "         [-5.6958e-01,  5.0363e-02, -1.1749e+00,  ..., -7.3421e-01,\n",
      "           1.1531e+00, -2.0905e-01],\n",
      "         [-5.7804e-01,  1.6354e-02, -1.1746e+00,  ..., -7.0547e-01,\n",
      "           1.1430e+00, -2.1883e-01],\n",
      "         ...,\n",
      "         [-4.8934e-01,  1.2339e-02, -1.2466e+00,  ..., -6.7987e-01,\n",
      "           9.7046e-01, -2.8362e-01],\n",
      "         [-4.8934e-01,  1.2339e-02, -1.2466e+00,  ..., -6.7987e-01,\n",
      "           9.7046e-01, -2.8362e-01],\n",
      "         [-4.8934e-01,  1.2339e-02, -1.2466e+00,  ..., -6.7987e-01,\n",
      "           9.7046e-01, -2.8362e-01]],\n",
      "\n",
      "        [[-5.0108e-01,  7.5406e-02, -1.1512e+00,  ..., -7.5413e-01,\n",
      "           1.1334e+00, -2.2367e-01],\n",
      "         [-6.0298e-01,  7.5926e-02, -1.0868e+00,  ..., -7.2349e-01,\n",
      "           1.1705e+00, -1.7327e-01],\n",
      "         [-5.4923e-01,  5.8137e-02, -1.1155e+00,  ..., -7.4273e-01,\n",
      "           1.1677e+00, -1.3464e-01],\n",
      "         ...,\n",
      "         [-5.2033e-01,  8.5324e-02, -1.2317e+00,  ..., -6.9810e-01,\n",
      "           9.5454e-01, -2.2873e-01],\n",
      "         [-5.2033e-01,  8.5324e-02, -1.2317e+00,  ..., -6.9810e-01,\n",
      "           9.5454e-01, -2.2873e-01],\n",
      "         [-5.2033e-01,  8.5324e-02, -1.2317e+00,  ..., -6.9810e-01,\n",
      "           9.5454e-01, -2.2873e-01]],\n",
      "\n",
      "        [[-4.7134e-01,  1.0811e-01, -1.1666e+00,  ..., -7.6509e-01,\n",
      "           1.2248e+00, -2.1780e-01],\n",
      "         [-5.6269e-01,  1.6524e-01, -1.2084e+00,  ..., -7.3848e-01,\n",
      "           1.2199e+00, -1.7623e-01],\n",
      "         [-5.4295e-01,  1.1068e-01, -1.1643e+00,  ..., -7.3721e-01,\n",
      "           1.2472e+00, -2.0873e-01],\n",
      "         ...,\n",
      "         [-5.0106e-01,  1.2422e-01, -1.2661e+00,  ..., -6.8352e-01,\n",
      "           1.0477e+00, -2.3677e-01],\n",
      "         [-5.0106e-01,  1.2422e-01, -1.2661e+00,  ..., -6.8352e-01,\n",
      "           1.0477e+00, -2.3677e-01],\n",
      "         [-5.0106e-01,  1.2422e-01, -1.2661e+00,  ..., -6.8352e-01,\n",
      "           1.0477e+00, -2.3677e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.2738e-01, -1.3611e-02, -1.0872e+00,  ..., -6.8036e-01,\n",
      "           1.0637e+00, -2.9803e-01],\n",
      "         [-5.9954e-01,  4.2112e-02, -1.0856e+00,  ..., -6.6256e-01,\n",
      "           1.0541e+00, -2.6532e-01],\n",
      "         [-5.7669e-01,  2.1023e-02, -1.0793e+00,  ..., -6.4436e-01,\n",
      "           1.0604e+00, -2.6720e-01],\n",
      "         ...,\n",
      "         [-5.4138e-01,  2.1152e-02, -1.1459e+00,  ..., -6.3230e-01,\n",
      "           9.1955e-01, -3.0593e-01],\n",
      "         [-5.4138e-01,  2.1152e-02, -1.1459e+00,  ..., -6.3230e-01,\n",
      "           9.1955e-01, -3.0593e-01],\n",
      "         [-5.4138e-01,  2.1152e-02, -1.1459e+00,  ..., -6.3230e-01,\n",
      "           9.1955e-01, -3.0593e-01]],\n",
      "\n",
      "        [[-4.8093e-01,  1.1690e-02, -1.1053e+00,  ..., -6.5886e-01,\n",
      "           1.0637e+00, -2.8557e-01],\n",
      "         [-5.5005e-01,  6.5484e-02, -1.0741e+00,  ..., -6.1927e-01,\n",
      "           1.0565e+00, -2.5307e-01],\n",
      "         [-5.3020e-01,  2.9889e-02, -1.1066e+00,  ..., -6.2052e-01,\n",
      "           1.0634e+00, -2.6959e-01],\n",
      "         ...,\n",
      "         [-4.9537e-01,  3.0044e-02, -1.1592e+00,  ..., -6.1972e-01,\n",
      "           9.3062e-01, -2.9329e-01],\n",
      "         [-4.9537e-01,  3.0044e-02, -1.1592e+00,  ..., -6.1972e-01,\n",
      "           9.3062e-01, -2.9329e-01],\n",
      "         [-4.9537e-01,  3.0044e-02, -1.1592e+00,  ..., -6.1972e-01,\n",
      "           9.3062e-01, -2.9329e-01]],\n",
      "\n",
      "        [[-4.6992e-01,  3.8617e-03, -1.1319e+00,  ..., -6.5035e-01,\n",
      "           9.9008e-01, -3.1638e-01],\n",
      "         [-5.3996e-01,  4.7927e-02, -1.0842e+00,  ..., -6.0765e-01,\n",
      "           1.0266e+00, -2.4241e-01],\n",
      "         [-5.3437e-01,  3.6674e-03, -1.1213e+00,  ..., -6.3995e-01,\n",
      "           1.0224e+00, -2.9896e-01],\n",
      "         ...,\n",
      "         [-4.7646e-01,  4.4845e-02, -1.1796e+00,  ..., -6.0316e-01,\n",
      "           8.4586e-01, -3.2148e-01],\n",
      "         [-4.7646e-01,  4.4845e-02, -1.1796e+00,  ..., -6.0316e-01,\n",
      "           8.4586e-01, -3.2148e-01],\n",
      "         [-4.7646e-01,  4.4845e-02, -1.1796e+00,  ..., -6.0316e-01,\n",
      "           8.4586e-01, -3.2148e-01]]]) tensor([[[-0.5033,  0.0625, -0.2069,  ...,  0.2454,  0.8138,  0.0748],\n",
      "         [-0.5234, -0.1213, -0.2924,  ...,  0.1154,  0.6730,  0.1060],\n",
      "         [-0.2374, -0.1081, -0.2450,  ...,  0.0116,  0.3241,  0.1449],\n",
      "         ...,\n",
      "         [-0.5325, -0.0455, -0.1400,  ...,  0.1332,  0.0636, -0.0148],\n",
      "         [-0.6062,  0.0781,  0.2136,  ...,  0.1009,  0.4535,  0.0169],\n",
      "         [-0.6333,  0.0858,  0.1579,  ...,  0.1379,  0.5022, -0.0104]],\n",
      "\n",
      "        [[-0.1961,  0.2355,  0.0786,  ...,  0.3374,  0.7700,  0.2852],\n",
      "         [-0.1806,  0.2246,  0.0674,  ...,  0.2735,  0.7151,  0.2926],\n",
      "         [-0.2071,  0.2611,  0.1599,  ...,  0.2612,  0.6736,  0.2198],\n",
      "         ...,\n",
      "         [-0.4225, -0.1933,  0.2503,  ...,  0.1077,  0.2864, -0.0937],\n",
      "         [-0.5376,  0.0492,  0.2782,  ...,  0.2741,  0.2528, -0.1019],\n",
      "         [-0.4899,  0.0835,  0.2302,  ...,  0.3477,  0.2720, -0.0428]],\n",
      "\n",
      "        [[-0.4965, -0.1848,  0.0607,  ...,  0.1275,  0.2987,  0.3117],\n",
      "         [-0.5287, -0.2579, -0.0317,  ...,  0.0348,  0.1602,  0.3247],\n",
      "         [-0.2542,  0.0205, -0.1202,  ..., -0.0199, -0.1925,  0.3031],\n",
      "         ...,\n",
      "         [-0.4345, -0.3732,  0.6202,  ...,  0.1345, -0.0878, -0.3963],\n",
      "         [-0.3642, -0.3287,  0.5993,  ...,  0.0723, -0.0171, -0.4339],\n",
      "         [-0.3422, -0.2962,  0.3807,  ...,  0.1949,  0.0212, -0.3760]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1182, -0.1220, -0.1100,  ...,  0.3973,  0.5692,  0.4603],\n",
      "         [-0.1017, -0.1121, -0.1147,  ...,  0.3903,  0.5701,  0.4535],\n",
      "         [-0.0865, -0.1016, -0.1142,  ...,  0.3879,  0.5653,  0.4478],\n",
      "         ...,\n",
      "         [-0.2863,  0.5570,  0.3868,  ...,  0.0599,  0.5050,  0.1565],\n",
      "         [-0.5583,  0.3798,  0.4424,  ...,  0.2709,  0.4372, -0.0560],\n",
      "         [-0.5892,  0.3673,  0.3821,  ...,  0.3319,  0.4143, -0.0707]],\n",
      "\n",
      "        [[-0.2880,  0.0338, -0.0608,  ...,  0.3364,  0.5689,  0.4790],\n",
      "         [-0.2789,  0.0290, -0.0562,  ...,  0.3268,  0.5554,  0.4763],\n",
      "         [-0.2679,  0.0332, -0.0520,  ...,  0.3167,  0.5536,  0.4700],\n",
      "         ...,\n",
      "         [-0.6057,  0.0047,  0.3261,  ...,  0.2348,  0.4183, -0.0823],\n",
      "         [-0.5599, -0.0403,  0.2467,  ...,  0.4829,  0.4535, -0.0529],\n",
      "         [-0.5780, -0.0206,  0.2216,  ...,  0.5370,  0.4362, -0.0516]],\n",
      "\n",
      "        [[-0.0988, -0.0964,  0.0581,  ...,  0.2939,  0.7524,  0.4239],\n",
      "         [-0.0830, -0.0877,  0.0618,  ...,  0.2906,  0.7502,  0.4169],\n",
      "         [-0.0770, -0.0827,  0.0618,  ...,  0.2914,  0.7532,  0.4147],\n",
      "         ...,\n",
      "         [-0.6434,  0.1839,  0.2194,  ...,  0.5623,  0.3450, -0.3059],\n",
      "         [-0.7701,  0.1420,  0.1843,  ...,  0.6535,  0.2720, -0.1636],\n",
      "         [-0.7656,  0.1242,  0.2002,  ...,  0.6531,  0.2623, -0.1207]]]) tensor([  3,   4,   2,   4,   4,   4,   3,   4,   4,   4,   4,   5,   4,   4,\n",
      "          4,   3,   5,   1,   4,   4,   4,   4,   0,   5,   4,   4,   4, 450,\n",
      "          4,   4,   4,   4,   4,   4,   4,   6,   4,   3,   4,   4,   3,   0,\n",
      "          4,   4,   4,   0,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
      "          3,  10,   4,   1, 340,   4,   4,   1,   0,   4,   4,   4,   4,   4,\n",
      "          3,   4,   4,   4,   4,   4,   4,   4,   4,   0, 340,   3,   4,   4,\n",
      "          3,   4,   4,   4,   4,   4,   4,   0,   4,   4,   4,   4,   3,   3,\n",
      "          0,   2,   4,   4,   4,   4,   4,   4,   6,   4,   4,   4,   4,   4,\n",
      "          4,   3,   4,   1,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
      "          3,   4])\n",
      "tensor([[[-0.4698, -0.0461, -1.1327,  ..., -0.6567,  1.1021, -0.3500],\n",
      "         [-0.5457, -0.0120, -1.1293,  ..., -0.6629,  1.1113, -0.3035],\n",
      "         [-0.4992, -0.0218, -1.1384,  ..., -0.6150,  1.1268, -0.3461],\n",
      "         ...,\n",
      "         [-0.4940, -0.0163, -1.1838,  ..., -0.6123,  0.9520, -0.3510],\n",
      "         [-0.4940, -0.0163, -1.1838,  ..., -0.6123,  0.9520, -0.3510],\n",
      "         [-0.4940, -0.0163, -1.1838,  ..., -0.6123,  0.9520, -0.3510]],\n",
      "\n",
      "        [[-0.5270, -0.0851, -1.1430,  ..., -0.6827,  1.1178, -0.3260],\n",
      "         [-0.6040, -0.0241, -1.1030,  ..., -0.6625,  1.1080, -0.2867],\n",
      "         [-0.5716, -0.0519, -1.1209,  ..., -0.6453,  1.1130, -0.3146],\n",
      "         ...,\n",
      "         [-0.5441, -0.0474, -1.2077,  ..., -0.6404,  0.9715, -0.3364],\n",
      "         [-0.5441, -0.0474, -1.2077,  ..., -0.6404,  0.9715, -0.3364],\n",
      "         [-0.5441, -0.0474, -1.2077,  ..., -0.6404,  0.9715, -0.3364]],\n",
      "\n",
      "        [[-0.4897, -0.0840, -1.1383,  ..., -0.7146,  1.0522, -0.2472],\n",
      "         [-0.5352, -0.0351, -1.1251,  ..., -0.7035,  1.0750, -0.2029],\n",
      "         [-0.5281, -0.0643, -1.1310,  ..., -0.6719,  1.0848, -0.2162],\n",
      "         ...,\n",
      "         [-0.5072, -0.0337, -1.1989,  ..., -0.6525,  0.9131, -0.2578],\n",
      "         [-0.5072, -0.0337, -1.1989,  ..., -0.6525,  0.9131, -0.2578],\n",
      "         [-0.5072, -0.0337, -1.1989,  ..., -0.6525,  0.9131, -0.2578]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4990,  0.0177, -1.0516,  ..., -0.7218,  1.0473, -0.1789],\n",
      "         [-0.5571,  0.0571, -1.0011,  ..., -0.6872,  1.0500, -0.1421],\n",
      "         [-0.5183,  0.0349, -1.0280,  ..., -0.6683,  1.0284, -0.1805],\n",
      "         ...,\n",
      "         [-0.5123,  0.0483, -1.1088,  ..., -0.6626,  0.9007, -0.1842],\n",
      "         [-0.5123,  0.0483, -1.1088,  ..., -0.6626,  0.9007, -0.1842],\n",
      "         [-0.5123,  0.0483, -1.1088,  ..., -0.6626,  0.9007, -0.1842]],\n",
      "\n",
      "        [[-0.4717,  0.0699, -1.1586,  ..., -0.7144,  1.0978, -0.2089],\n",
      "         [-0.5465,  0.1016, -1.1412,  ..., -0.6774,  1.1105, -0.1805],\n",
      "         [-0.5354,  0.0526, -1.1226,  ..., -0.6900,  1.1190, -0.1879],\n",
      "         ...,\n",
      "         [-0.4918,  0.0855, -1.2330,  ..., -0.6585,  0.9340, -0.2190],\n",
      "         [-0.4918,  0.0855, -1.2330,  ..., -0.6585,  0.9340, -0.2190],\n",
      "         [-0.4918,  0.0855, -1.2330,  ..., -0.6585,  0.9340, -0.2190]],\n",
      "\n",
      "        [[-0.4690, -0.1400, -1.0979,  ..., -0.6995,  1.0002, -0.1977],\n",
      "         [-0.5557, -0.0947, -1.0911,  ..., -0.6879,  1.0265, -0.1676],\n",
      "         [-0.5253, -0.1254, -1.0902,  ..., -0.6435,  1.0298, -0.1735],\n",
      "         ...,\n",
      "         [-0.4824, -0.0941, -1.1446,  ..., -0.6477,  0.8612, -0.2063],\n",
      "         [-0.4824, -0.0941, -1.1446,  ..., -0.6477,  0.8612, -0.2063],\n",
      "         [-0.4824, -0.0941, -1.1446,  ..., -0.6477,  0.8612, -0.2063]]]) tensor([[[-0.0639, -0.0330, -0.0196,  ...,  0.2217,  0.4442,  0.4870],\n",
      "         [-0.0579, -0.0349, -0.0268,  ...,  0.2102,  0.4467,  0.4712],\n",
      "         [-0.0413, -0.0240, -0.0503,  ...,  0.2167,  0.4438,  0.4667],\n",
      "         ...,\n",
      "         [-0.4993, -0.1814,  0.3349,  ...,  0.4058,  0.5893, -0.4261],\n",
      "         [-0.3472, -0.2266,  0.3194,  ...,  0.1741,  0.4530, -0.3862],\n",
      "         [-0.3492, -0.2228,  0.3544,  ...,  0.1598,  0.4522, -0.4157]],\n",
      "\n",
      "        [[-0.1573, -0.1641, -0.0895,  ...,  0.1911,  0.4198,  0.4551],\n",
      "         [-0.1631, -0.1544, -0.0569,  ...,  0.1747,  0.3818,  0.4450],\n",
      "         [-0.1654, -0.1315, -0.0549,  ...,  0.1475,  0.3927,  0.4268],\n",
      "         ...,\n",
      "         [-0.1416, -0.1220, -0.1032,  ...,  0.1045,  0.4312,  0.3838],\n",
      "         [-0.1850, -0.0579, -0.0631,  ...,  0.0467,  0.5772,  0.3028],\n",
      "         [-0.4856, -0.1895, -0.0668,  ..., -0.0260,  0.1678, -0.3573]],\n",
      "\n",
      "        [[-0.2293, -0.1059, -0.0701,  ...,  0.2321,  0.9098,  0.2851],\n",
      "         [-0.2182, -0.1118, -0.0721,  ...,  0.2188,  0.8692,  0.2737],\n",
      "         [-0.2087, -0.1103, -0.0757,  ...,  0.2166,  0.8244,  0.2668],\n",
      "         ...,\n",
      "         [-0.0918,  0.1530,  0.0912,  ...,  0.2307,  0.8452,  0.1474],\n",
      "         [-0.1702,  0.2317,  0.1321,  ...,  0.2637,  0.7949,  0.1359],\n",
      "         [-0.1795,  0.2180,  0.1246,  ...,  0.2456,  0.8123,  0.1303]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2957,  0.1790, -0.0691,  ...,  0.2750,  0.7779,  0.4575],\n",
      "         [-0.2832,  0.1697, -0.0627,  ...,  0.2518,  0.7617,  0.4517],\n",
      "         [-0.2676,  0.1733, -0.0563,  ...,  0.1980,  0.7107,  0.4197],\n",
      "         ...,\n",
      "         [-0.2456, -0.0111,  0.0553,  ...,  0.2034,  0.3358,  0.4552],\n",
      "         [-0.4846, -0.0507,  0.0273,  ...,  0.2391,  0.3242,  0.2785],\n",
      "         [-0.5112, -0.0022,  0.0148,  ...,  0.2936,  0.3018,  0.0572]],\n",
      "\n",
      "        [[-0.2722, -0.0315, -0.1862,  ...,  0.2749,  0.8778,  0.3993],\n",
      "         [-0.2621, -0.0273, -0.1814,  ...,  0.2721,  0.8835,  0.3963],\n",
      "         [-0.2441, -0.0162, -0.1770,  ...,  0.2753,  0.8711,  0.3908],\n",
      "         ...,\n",
      "         [-0.1984,  0.0825,  0.3711,  ..., -0.0917,  0.4092, -0.3475],\n",
      "         [-0.3173,  0.0946,  0.3094,  ...,  0.0181,  0.3817, -0.2699],\n",
      "         [-0.3742,  0.0924,  0.2385,  ...,  0.0844,  0.3737, -0.2583]],\n",
      "\n",
      "        [[-0.0715,  0.0813,  0.0311,  ...,  0.2906,  0.6693,  0.5203],\n",
      "         [-0.0593,  0.0856,  0.0291,  ...,  0.2847,  0.6371,  0.5190],\n",
      "         [-0.0509,  0.0863,  0.0328,  ...,  0.2808,  0.6117,  0.5147],\n",
      "         ...,\n",
      "         [-0.0535,  0.0685,  0.1311,  ...,  0.2527,  0.5431,  0.4764],\n",
      "         [-0.1546,  0.1088,  0.1458,  ...,  0.2137,  0.7202,  0.4936],\n",
      "         [-0.7949,  0.0723,  0.2068,  ...,  0.5908,  0.5471, -0.0649]]]) tensor([  4,   4,   2,   4,   3,   4,   4,   0,   4,   4,   4,   4,   4,   4,\n",
      "          4,   4,   4,   3,   0,   2,   4,   4,   4,   4,   4,   0,   4,   6,\n",
      "          4,   4,   4,   4,   4,   4,   3,   4,   3, 460,   3,   4,   5,   0,\n",
      "          3,   4,   4,   4,   1,   4,   0,   0,   4,   4,   4,   4,   4,   4,\n",
      "          4,   4,   4,   4,   4, 340, 240,   4,   4,   3,   4,   4,   4,   4,\n",
      "          4,   4,   5,   4,   4,   4,   6,   1,   4,   4,   4,   3,   0,   5,\n",
      "          4,   4,   4,   5,   4,   4,   4,   0,   4, 460,   6,   0,   5,   3,\n",
      "          5,   4,   4,   4,   4,   4,   4,   4,   4,   6,   4,   4,   3,   6,\n",
      "          3, 340,   4,   4,   0,   4,   6,   4, 450,   4, 140,   4,   4,   0,\n",
      "          4,   4])\n"
     ]
    }
   ],
   "source": [
    "for batch, (X_txt, X_wav, X_temp, X_eda, \n",
    "                        label_emotion, label_emotion_ext, label_arousal, label_valence) in list(enumerate(test_dataloader))[:4]:\n",
    "    print(X_txt,X_wav,label_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "torch.return_types.topk(\n",
      "values=tensor([[0.1579, 0.1481],\n",
      "        [0.1575, 0.1474],\n",
      "        [0.1567, 0.1479],\n",
      "        [0.1591, 0.1482],\n",
      "        [0.1564, 0.1472],\n",
      "        [0.1607, 0.1521],\n",
      "        [0.1564, 0.1482],\n",
      "        [0.1627, 0.1531],\n",
      "        [0.1582, 0.1491],\n",
      "        [0.1610, 0.1504],\n",
      "        [0.1581, 0.1471],\n",
      "        [0.1606, 0.1497],\n",
      "        [0.1583, 0.1478],\n",
      "        [0.1581, 0.1475],\n",
      "        [0.1563, 0.1463],\n",
      "        [0.1566, 0.1463],\n",
      "        [0.1623, 0.1530],\n",
      "        [0.1608, 0.1532],\n",
      "        [0.1624, 0.1523],\n",
      "        [0.1566, 0.1467],\n",
      "        [0.1577, 0.1476],\n",
      "        [0.1590, 0.1485],\n",
      "        [0.1592, 0.1494],\n",
      "        [0.1565, 0.1462],\n",
      "        [0.1572, 0.1485],\n",
      "        [0.1581, 0.1482],\n",
      "        [0.1587, 0.1466],\n",
      "        [0.1602, 0.1511],\n",
      "        [0.1590, 0.1497],\n",
      "        [0.1575, 0.1488],\n",
      "        [0.1583, 0.1482],\n",
      "        [0.1561, 0.1462],\n",
      "        [0.1546, 0.1489],\n",
      "        [0.1563, 0.1468],\n",
      "        [0.1569, 0.1478],\n",
      "        [0.1575, 0.1464],\n",
      "        [0.1588, 0.1482],\n",
      "        [0.1569, 0.1466],\n",
      "        [0.1565, 0.1461],\n",
      "        [0.1574, 0.1490],\n",
      "        [0.1570, 0.1471],\n",
      "        [0.1567, 0.1466],\n",
      "        [0.1578, 0.1480],\n",
      "        [0.1572, 0.1479],\n",
      "        [0.1583, 0.1480],\n",
      "        [0.1569, 0.1479],\n",
      "        [0.1583, 0.1510],\n",
      "        [0.1597, 0.1520],\n",
      "        [0.1575, 0.1478],\n",
      "        [0.1574, 0.1472],\n",
      "        [0.1573, 0.1469],\n",
      "        [0.1641, 0.1536],\n",
      "        [0.1644, 0.1564],\n",
      "        [0.1575, 0.1457],\n",
      "        [0.1567, 0.1452],\n",
      "        [0.1584, 0.1491],\n",
      "        [0.1573, 0.1481],\n",
      "        [0.1602, 0.1491],\n",
      "        [0.1622, 0.1516],\n",
      "        [0.1576, 0.1487],\n",
      "        [0.1566, 0.1474],\n",
      "        [0.1567, 0.1476],\n",
      "        [0.1566, 0.1485],\n",
      "        [0.1575, 0.1477],\n",
      "        [0.1555, 0.1479],\n",
      "        [0.1562, 0.1465],\n",
      "        [0.1659, 0.1537],\n",
      "        [0.1571, 0.1470],\n",
      "        [0.1568, 0.1479],\n",
      "        [0.1596, 0.1505],\n",
      "        [0.1586, 0.1489],\n",
      "        [0.1569, 0.1477],\n",
      "        [0.1612, 0.1460],\n",
      "        [0.1571, 0.1482],\n",
      "        [0.1579, 0.1471],\n",
      "        [0.1567, 0.1458],\n",
      "        [0.1576, 0.1492],\n",
      "        [0.1567, 0.1471],\n",
      "        [0.1566, 0.1472],\n",
      "        [0.1582, 0.1491],\n",
      "        [0.1563, 0.1476],\n",
      "        [0.1621, 0.1519],\n",
      "        [0.1560, 0.1475],\n",
      "        [0.1568, 0.1467],\n",
      "        [0.1564, 0.1472],\n",
      "        [0.1640, 0.1513],\n",
      "        [0.1612, 0.1497],\n",
      "        [0.1600, 0.1508],\n",
      "        [0.1572, 0.1476],\n",
      "        [0.1565, 0.1468],\n",
      "        [0.1583, 0.1474],\n",
      "        [0.1628, 0.1522],\n",
      "        [0.1573, 0.1481],\n",
      "        [0.1575, 0.1487],\n",
      "        [0.1550, 0.1455],\n",
      "        [0.1563, 0.1464],\n",
      "        [0.1598, 0.1465],\n",
      "        [0.1585, 0.1509],\n",
      "        [0.1568, 0.1461],\n",
      "        [0.1626, 0.1540],\n",
      "        [0.1588, 0.1488],\n",
      "        [0.1593, 0.1478],\n",
      "        [0.1566, 0.1470],\n",
      "        [0.1562, 0.1467],\n",
      "        [0.1639, 0.1514],\n",
      "        [0.1578, 0.1497],\n",
      "        [0.1589, 0.1497],\n",
      "        [0.1586, 0.1466],\n",
      "        [0.1580, 0.1497],\n",
      "        [0.1579, 0.1465],\n",
      "        [0.1567, 0.1476],\n",
      "        [0.1571, 0.1456],\n",
      "        [0.1565, 0.1471],\n",
      "        [0.1582, 0.1479],\n",
      "        [0.1565, 0.1463],\n",
      "        [0.1568, 0.1463],\n",
      "        [0.1580, 0.1496],\n",
      "        [0.1579, 0.1491],\n",
      "        [0.1567, 0.1470],\n",
      "        [0.1566, 0.1463],\n",
      "        [0.1567, 0.1460],\n",
      "        [0.1577, 0.1493],\n",
      "        [0.1571, 0.1479],\n",
      "        [0.1601, 0.1491],\n",
      "        [0.1568, 0.1471],\n",
      "        [0.1565, 0.1469],\n",
      "        [0.1645, 0.1473],\n",
      "        [0.1567, 0.1474]], device='cuda:0', grad_fn=<TopkBackward0>),\n",
      "indices=tensor([[6, 3],\n",
      "        [6, 3],\n",
      "        [6, 4],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 4],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 4],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 4],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 4],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 0],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 0],\n",
      "        [6, 0],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3],\n",
      "        [6, 3]], device='cuda:0'))\n",
      "[360, 360, 460, 360, 360, 360, 460, 360, 360, 360, 760, 360, 360, 360, 760, 760, 360, 360, 360, 360, 360, 760, 360, 760, 360, 360, 360, 360, 360, 360, 360, 360, 760, 360, 360, 360, 360, 360, 760, 460, 360, 760, 360, 460, 360, 360, 360, 360, 360, 760, 360, 360, 360, 360, 760, 360, 360, 360, 360, 360, 360, 360, 760, 360, 460, 360, 360, 360, 360, 360, 360, 360, 760, 360, 360, 760, 360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 360, 760, 760, 760, 360, 760, 360, 360, 360, 360, 760, 360, 360, 360, 360, 360, 760, 360, 760, 360, 360, 360, 760, 360, 360, 360, 760, 760, 360, 360, 360, 360, 360, 360, 360]\n"
     ]
    }
   ],
   "source": [
    "X_temp_new = X_temp.unsqueeze(dim=-1)\n",
    "X_eda_new = X_eda.unsqueeze(dim=-1)\n",
    "\n",
    "probs = model_tf_cnn_mixer(X_txt.to(device), X_wav.to(device), X_temp_new.to(device), X_eda_new.to(device))\n",
    "\n",
    "print(probs.argmax(1))\n",
    "\n",
    "\n",
    "values = probs.topk(2)\n",
    "pred_list = []\n",
    "print(values)\n",
    "diffs = abs(torch.diff(values.values))\n",
    "for idx,diff in zip(values.indices, diffs):\n",
    "    if diff <= 0.1:\n",
    "        sorted_value, idx = torch.sort(idx)\n",
    "        if sorted_value[0] == 0:\n",
    "            pred_list.append(100*7 + 10*sorted_value[1].item())\n",
    "        else:\n",
    "            pred_list.append(100*sorted_value[0].item() + 10*sorted_value[1].item())\n",
    "    else:\n",
    "        pred_list.append(idx[0].item())\n",
    "print(pred_list)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bdc1fd12ca460d5768d71e9df3d9063ef832ce64a62e55a1a523c8c99752868e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
