{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working model for tensorfusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arplab/project/paradeigma/multi_modal/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torchmetrics import F1Score\n",
    "import pandas as pd\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['file_names', 'text_embeddings', 'wav_embeddings', 'Emotion', 'Arousal', 'Valence'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data load\n",
    "# Raw dataset의 key는 ['file_names', 'text_embeddings', 'wav_embeddings', 'Emotion', 'Arousal', 'Valence']로 구성\n",
    "\n",
    "with open('../model/data/paradeigma_dataset_1_3.pkl', 'rb') as f:\n",
    "    raw_dataset = pickle.load(f)\n",
    "\n",
    "# with open('../model/data/paradeigma_dataset_1_4.pkl', 'rb') as f:\n",
    "#     raw_dataset = pickle.load(f)\n",
    "    \n",
    "sessions = ['Session01', 'Session02']\n",
    "session = sessions[0]\n",
    "raw_dataset[session].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 40개 세션의 감정 종류는 24개\n",
    "\n",
    "from glob import glob\n",
    "annot_lst = glob('../org_KEMDy20/annotation/*.csv')\n",
    "emotion_list = []\n",
    "for annot_file in annot_lst:\n",
    "    annot = pd.read_csv(annot_file, skiprows=1)\n",
    "    emotion_list.append(annot['Emotion'])\n",
    "emotion_list = list(pd.Series([j for i in emotion_list for j in i]).unique())\n",
    "len(emotion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      neutral\n",
       "1      neutral\n",
       "2      neutral\n",
       "3      neutral\n",
       "4      neutral\n",
       "        ...   \n",
       "306    neutral\n",
       "307    neutral\n",
       "308    neutral\n",
       "309    neutral\n",
       "310    neutral\n",
       "Name: Emotion, Length: 311, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['Session01']['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 세션 1,2 의 감정 종류는 7개\n",
    "\n",
    "emotion_lst = []\n",
    "sessions = ['Session01', 'Session02']\n",
    "for session in sessions:\n",
    "    emotion_lst.append(raw_dataset[session]['Emotion'].unique())\n",
    "emotion_lst = [j for i in emotion_lst for j in i]\n",
    "emotion_lst = list(pd.Series(emotion_lst).unique())\n",
    "len(emotion_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'happy': 0,\n",
       "  'neutral': 1,\n",
       "  'surprise': 2,\n",
       "  'surprise;neutral': 3,\n",
       "  'sad': 4,\n",
       "  'neutral;sad': 5,\n",
       "  'happy;neutral': 6,\n",
       "  'angry;neutral': 7,\n",
       "  'neutral;disqust': 8,\n",
       "  'angry': 9,\n",
       "  'fear': 10,\n",
       "  'neutral;fear': 11,\n",
       "  'disqust': 12,\n",
       "  'happy;surprise': 13,\n",
       "  'happy;angry;neutral': 14,\n",
       "  'angry;disqust': 15,\n",
       "  'happy;surprise;neutral': 16,\n",
       "  'happy;fear': 17,\n",
       "  'happy;neutral;fear': 18,\n",
       "  'angry;neutral;disqust': 19,\n",
       "  'neutral;disqust;sad': 20,\n",
       "  'angry;neutral;disqust;fear;sad': 21,\n",
       "  'happy;sad': 22,\n",
       "  'happy;neutral;disqust': 23},\n",
       " {0: 'happy',\n",
       "  1: 'neutral',\n",
       "  2: 'surprise',\n",
       "  3: 'surprise;neutral',\n",
       "  4: 'sad',\n",
       "  5: 'neutral;sad',\n",
       "  6: 'happy;neutral',\n",
       "  7: 'angry;neutral',\n",
       "  8: 'neutral;disqust',\n",
       "  9: 'angry',\n",
       "  10: 'fear',\n",
       "  11: 'neutral;fear',\n",
       "  12: 'disqust',\n",
       "  13: 'happy;surprise',\n",
       "  14: 'happy;angry;neutral',\n",
       "  15: 'angry;disqust',\n",
       "  16: 'happy;surprise;neutral',\n",
       "  17: 'happy;fear',\n",
       "  18: 'happy;neutral;fear',\n",
       "  19: 'angry;neutral;disqust',\n",
       "  20: 'neutral;disqust;sad',\n",
       "  21: 'angry;neutral;disqust;fear;sad',\n",
       "  22: 'happy;sad',\n",
       "  23: 'happy;neutral;disqust'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emotion target에 대한 정수 인코딩, 디코딩\n",
    "\n",
    "encode_dict = {b:i for i, b in enumerate(emotion_list)}\n",
    "decode_dict = {i:b for i, b in enumerate(emotion_list)}\n",
    "encode_dict, decode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['file_names', 'text_embeddings', 'wav_embeddings', 'Emotion', 'Arousal', 'Valence'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['Session01'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['file_names', 'text_embeddings', 'wav_embeddings', 'Emotion', 'Arousal', 'Valence'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## dataset을 합치는 과정\n",
    "## 다시 리뷰해야 할 것\n",
    "\n",
    "merged_dataset = {}\n",
    "for session_key in raw_dataset.keys():\n",
    "    raw_dataset[session_key]['Emotion'] = raw_dataset[session_key]['Emotion'].map(encode_dict)\n",
    "    for data_name in raw_dataset[session_key].keys():\n",
    "        if data_name in merged_dataset.keys():\n",
    "            for data in raw_dataset[session_key][data_name]:\n",
    "                merged_dataset[data_name].append(data)\n",
    "        else:\n",
    "            merged_dataset[data_name] = []\n",
    "            for data in raw_dataset[session_key][data_name]:\n",
    "                merged_dataset[data_name].append(data)\n",
    "    \n",
    "for data_name in merged_dataset.keys():\n",
    "    if data_name == 'text_embeddings' or data_name == 'wav_embeddings':\n",
    "        merged_dataset[data_name] = torch.stack(merged_dataset[data_name])\n",
    "\n",
    "merged_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 6, 7, 13]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "sorted(Counter(merged_dataset['Emotion']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_names:  576\n",
      "text_embeddings:  576\n",
      "wav_embeddings:  576\n",
      "Emotion:  576\n",
      "Arousal:  576\n",
      "Valence:  576\n"
     ]
    }
   ],
   "source": [
    "for i in merged_dataset.keys():\n",
    "    print(f\"{i}: \", len(merged_dataset[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch dataset 만들기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load 및 나누기: https://076923.github.io/posts/Python-pytorch-11/\n",
    "\n",
    "class EtriDataset(Dataset):\n",
    "    def __init__(self, file_names, text_embeddings, wave_embeddings, Emotion, Arousal, Valence):\n",
    "        self.file_names = file_names\n",
    "        self.text_embeddings = text_embeddings\n",
    "        self.wav_embeddings = wave_embeddings\n",
    "        self.label_emotion = Emotion\n",
    "        self.label_arousal = Arousal\n",
    "        self.label_valence = Valence\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text_embeddings = self.text_embeddings[idx]\n",
    "        wav_embeddings = self.wav_embeddings[idx]\n",
    "        label_emotion = self.label_emotion[idx]\n",
    "        label_arousal = self.label_arousal[idx]\n",
    "        label_valence = self.label_valence[idx]\n",
    "        return text_embeddings, wav_embeddings, label_emotion, label_arousal, label_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 session 데이터 셋을 만들었을 때 \n",
    "# dataset = EtriDataset(raw_dataset[session]['file_names'],\n",
    "#                       raw_dataset[session]['text_embeddings'],\n",
    "#                       raw_dataset[session]['wav_embeddings'],\n",
    "#                       raw_dataset[session]['Emotion'],\n",
    "#                       raw_dataset[session]['Arousal'],\n",
    "#                       raw_dataset[session]['Valence'])\n",
    "\n",
    "# session을 통합시킨 데이터 셋을 만들었을 때 \n",
    "dataset = EtriDataset(merged_dataset['file_names'],\n",
    "                      merged_dataset['text_embeddings'],\n",
    "                      merged_dataset['wav_embeddings'],                     \n",
    "                      merged_dataset['Emotion'],\n",
    "                      merged_dataset['Arousal'],\n",
    "                      merged_dataset['Valence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.7)\n",
    "validation_size = int(dataset_size * 0.15)\n",
    "test_size = dataset_size- (train_size + validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403 87 86\n",
      "Training Data Size : 403\n",
      "Validation Data Size : 86\n",
      "Testing Data Size : 87\n"
     ]
    }
   ],
   "source": [
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
    "\n",
    "print(train_size, test_size, validation_size)\n",
    "print(f\"Training Data Size : {len(train_dataset)}\")\n",
    "print(f\"Validation Data Size : {len(validation_dataset)}\")\n",
    "print(f\"Testing Data Size : {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size = 128, shuffle= True, drop_last = True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size = 32, shuffle= True, drop_last = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 32, shuffle= True, drop_last = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetWork 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNetwork_pre(nn.Module):\n",
    "    def __init__(self, input_length, input_width):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_length*input_width, 768)\n",
    "        self.gelu1 = nn.GELU()\n",
    "        self.bn1 = nn.BatchNorm1d(768)\n",
    "        self.fc2 = nn.Linear(768, 512)\n",
    "        self.gelu2 = nn.GELU()\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512,32)\n",
    "        self.gelu3 = nn.GELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.gelu2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc3(x)\n",
    "        output = self.gelu3(x)\n",
    "        return output\n",
    "    \n",
    "class MLPNetwork_final(nn.Module):\n",
    "    def __init__(self, input_length, input_width):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_length*input_width, 256)\n",
    "        self.gelu1 = nn.GELU()\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.gelu2 = nn.GELU()\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.gelu2(x)\n",
    "        x = self.bn2(x)\n",
    "        output = self.fc3(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorFusionMixer(nn.Module):\n",
    "    def __init__(self, ModelA, ModelB):\n",
    "        super().__init__()\n",
    "        self.ModelA = ModelA\n",
    "        self.ModelB = ModelB\n",
    "        self.Model_mlp_final = MLPNetwork_final(32, 32).to(device)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def tensor_fusion(self, batch_arr1, batch_arr2):\n",
    "        fusion_matrix_lst = []\n",
    "        for i, (arr1, arr2) in enumerate(zip(batch_arr1, batch_arr2)):\n",
    "            outer_matrix = torch.outer(arr1, arr2)\n",
    "            l, w = outer_matrix.shape\n",
    "            outer_matrix = outer_matrix.view(1, l, w)\n",
    "            fusion_matrix_lst.append(outer_matrix)\n",
    "        fusion_matrix = torch.concat(fusion_matrix_lst)\n",
    "        \n",
    "        return fusion_matrix\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.ModelA(x1)\n",
    "        x2 = self.ModelB(x2)\n",
    "        fusion_matrix = self.tensor_fusion(x1, x2)\n",
    "        x = self.Model_mlp_final(fusion_matrix)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n",
      "DataParallel(\n",
      "  (module): TensorFusionMixer(\n",
      "    (ModelA): MLPNetwork_pre(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=61440, out_features=768, bias=True)\n",
      "      (gelu1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc2): Linear(in_features=768, out_features=512, bias=True)\n",
      "      (gelu2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc3): Linear(in_features=512, out_features=32, bias=True)\n",
      "      (gelu3): GELU(approximate='none')\n",
      "    )\n",
      "    (ModelB): MLPNetwork_pre(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=37632, out_features=768, bias=True)\n",
      "      (gelu1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc2): Linear(in_features=768, out_features=512, bias=True)\n",
      "      (gelu2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc3): Linear(in_features=512, out_features=32, bias=True)\n",
      "      (gelu3): GELU(approximate='none')\n",
      "    )\n",
      "    (Model_mlp_final): MLPNetwork_final(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      (gelu1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (gelu2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
      "    )\n",
      "    (softmax): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "txt_input_length, txt_input_width = merged_dataset['text_embeddings'][0].shape\n",
    "_, wav_input_length, wav_input_width = merged_dataset['wav_embeddings'][0].shape\n",
    "\n",
    "model_mlp_txt = MLPNetwork_pre(txt_input_length,txt_input_width).to(device)\n",
    "model_mlp_wav = MLPNetwork_pre(wav_input_length,wav_input_width).to(device)\n",
    "\n",
    "model_tf_mixer = TensorFusionMixer(ModelA = model_mlp_txt, ModelB = model_mlp_wav).to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model_mlp_txt = nn.DataParallel(model_mlp_txt).to(device)\n",
    "    model_mlp_wav = nn.DataParallel(model_mlp_wav).to(device)\n",
    "    model_tf_mixer = nn.DataParallel(model_tf_mixer).to(device)\n",
    "\n",
    "print(model_tf_mixer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CCC, self).__init__()\n",
    "        self.mean = torch.mean\n",
    "        self.var = torch.var\n",
    "        self.sum = torch.sum\n",
    "        self.sqrt = torch.sqrt\n",
    "        self.std = torch.std\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        mean_gt = self.mean (target, 0)\n",
    "        mean_pred = self.mean (pred, 0)\n",
    "        var_gt = self.var (target, 0)\n",
    "        var_pred = self.var (pred, 0)\n",
    "        v_pred = pred - mean_pred\n",
    "        v_gt = target - mean_gt\n",
    "        cor = self.sum (v_pred * v_gt) / (self.sqrt(self.sum(v_pred ** 2)) * self.sqrt(self.sum(v_gt ** 2)))\n",
    "        sd_gt = self.std(target)\n",
    "        sd_pred = self.std(pred)\n",
    "        numerator = 2 * cor * sd_gt * sd_pred\n",
    "        denominator = var_gt + var_pred + (mean_gt-mean_pred) ** 2\n",
    "        ccc = numerator / denominator\n",
    "        return ccc\n",
    "    \n",
    "ccc = CCC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1667)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccc(torch.tensor([1.0,2.0,3.0,4.0,5.0]),torch.tensor([6.0,7.0,8.0,9.0,10.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 1번\n",
    "        # 128,1 / 128, 1\n",
    "        pred_ccc_a = ccc(pred_a, y_a)\n",
    "        pred_ccc_v= ccc(pred_v, y_v)\n",
    "        # : 너희들 arousal valence -가지고 있는 관계성을 맞춰봐 ([1,2,3,.....,128],[1,2,3,.....128])\n",
    "        # : 평균 표준편차 의미가 있는 값?\n",
    "        \n",
    "        # 2번\n",
    "        # 128,1 / 128, 1\n",
    "        # ccc(pred_a, y_a) = 1\n",
    "        # ccc(pred_v, y_v) = 1\n",
    "        # : 너희들 예측 a 실제 a 관계를 1\n",
    "        # : 너희들 예측 v 실제 v 관계를 1 \n",
    "        # : accuracy 대체 \n",
    "        \n",
    "        # 3번\n",
    "        # : 우리가 예측한 a, v와 실제 a, v가 가지고 있는 관계성을 보여봐 ([0.0, 0.0],[0.0, 0.0]) \n",
    "        # : 1이 되기를 바람? \n",
    "        # 2,1 / 2,1\n",
    "        # ccc([pred_a , pred_v], [target_a, target_v])\n",
    "        # : ccc : 하나의 리스트의 평균이랑 표준편차 / 피어슨 상관계수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 순서: text_embeddings, wav_embeddings, label_emotion, label_arousal, label_valence\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X_txt, X_wav, _, y_a, y_v) in enumerate(dataloader):\n",
    "\n",
    "        X_txt, X_wav, y_a, y_v = X_txt.to(device), X_wav.to(device), y_a.type(torch.FloatTensor).to(device), y_v.type(torch.FloatTensor).to(device)\n",
    "        pred = model(X_txt, X_wav)\n",
    "        # 128,2\n",
    "        \n",
    "        pred_a = pred[:,0]\n",
    "        pred_v = pred[:,1]\n",
    "        \n",
    "        loss_a = loss_fn(pred_a, y_a)\n",
    "        loss_v = loss_fn(pred_v, y_v)\n",
    "        \n",
    "        pred_ccc_a = ccc(pred_a, y_a)\n",
    "        pred_ccc_v= ccc(pred_v, y_v)\n",
    "        \n",
    "        ccc_mean = (pred_ccc_a + pred_ccc_v) / 2\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_a.backward(retain_graph = True)\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss_a, loss_v, current = loss_a.item(), loss_v.item(), batch * len(X_txt)\n",
    "            print(f\"loss_a: {loss_a:>7f}, loss_b: {loss_v:>7f},  [{current:>5d}/{size:>5d}]\")\n",
    "            print(f\"ccc_mean : {ccc_mean:>9f}, Arousal_ccc : {pred_ccc_a:>9f}, Valence_ccc : {pred_ccc_v:>9f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, mode = 'test'):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss_a = 0\n",
    "    test_loss_v = 0\n",
    "    ccc_mean = 0\n",
    "    ccc_a = 0\n",
    "    ccc_v = 0\n",
    "    \n",
    "    preds = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch, (X_txt, X_wav, _, y_a, y_v) in enumerate(dataloader):\n",
    "\n",
    "            X_txt, X_wav, y_a, y_v = X_txt.to(device), X_wav.to(device), y_a.type(torch.FloatTensor).to(device), y_v.type(torch.FloatTensor).to(device)\n",
    "            pred = model(X_txt, X_wav)\n",
    "            \n",
    "            pred_a = pred[:,0]\n",
    "            pred_v = pred[:,1]\n",
    "            \n",
    "            preds.append([pred_a, pred_v])\n",
    "            targets.append([y_a, y_v])\n",
    "            \n",
    "            pred_ccc_a = ccc(pred_a, y_a)\n",
    "            pred_ccc_v = ccc(pred_v, y_v)\n",
    "            \n",
    "            ccc_a += pred_ccc_a\n",
    "            ccc_v += pred_ccc_v\n",
    "            ccc_mean += (pred_ccc_a + pred_ccc_v) / 2\n",
    "            \n",
    "            test_loss_a += loss_fn(pred_a, y_a).item()\n",
    "            test_loss_v += loss_fn(pred_v, y_v).item()\n",
    "            \n",
    "    test_loss_a /= num_batches\n",
    "    test_loss_v /= num_batches\n",
    "    ccc_mean /= num_batches\n",
    "    ccc_a /= num_batches\n",
    "    ccc_v /= num_batches\n",
    "\n",
    "    if mode == 'test':\n",
    "        print(torch.cat(preds), torch.cat(preds).shape)\n",
    "        print(f\"loss_a: {test_loss_a:>7f}, loss_v: {test_loss_v:>7f}\")\n",
    "        print(f\"Tess ccc_mean : {ccc_mean:>9f}, Arousal_ccc : {ccc_a:>9f}, Valence_ccc{ccc_v:>9f}\")\n",
    "        \n",
    "    elif mode == 'val':\n",
    "        print(f\"loss_a: {test_loss_a:>7f}, loss_v: {test_loss_v:>7f}\")\n",
    "        print(f\"Validation ccc_mean : {ccc_mean:>9f}, Arousal_ccc : {ccc_a:>9f}, Valence_ccc{ccc_v:>9f}\")    \n",
    " \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch 1----------------\n",
      "Training......\n",
      "loss_a: 7.687414, loss_b: 8.272012,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000001, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:38<1:03:55, 38.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 7.774595, loss_v: 8.763523\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000001, Valence_ccc-0.000000\n",
      "---------------Epoch 2----------------\n",
      "Training......\n",
      "loss_a: 7.497075, loss_b: 8.427500,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000001, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [01:14<1:00:33, 37.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 7.835331, loss_v: 8.494035\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000001, Valence_ccc 0.000000\n",
      "---------------Epoch 3----------------\n",
      "Training......\n",
      "loss_a: 7.739969, loss_b: 8.429028,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000001, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [01:52<1:00:14, 37.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 7.664093, loss_v: 8.288116\n",
      "Validation ccc_mean :  0.000000, Arousal_ccc :  0.000001, Valence_ccc 0.000000\n",
      "---------------Epoch 4----------------\n",
      "Training......\n",
      "loss_a: 7.594739, loss_b: 7.872143,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000001, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [02:30<1:00:06, 37.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 7.517113, loss_v: 8.035588\n",
      "Validation ccc_mean :  0.000000, Arousal_ccc :  0.000001, Valence_ccc-0.000000\n",
      "---------------Epoch 5----------------\n",
      "Training......\n",
      "loss_a: 7.079391, loss_b: 7.797729,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000001, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [03:06<58:57, 37.24s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 7.218483, loss_v: 7.950590\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000001, Valence_ccc-0.000000\n",
      "---------------Epoch 6----------------\n",
      "Training......\n",
      "loss_a: 7.143586, loss_b: 7.591214,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000001, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [03:42<57:19, 36.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 7.057078, loss_v: 7.827929\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000002, Valence_ccc 0.000000\n",
      "---------------Epoch 7----------------\n",
      "Training......\n",
      "loss_a: 6.943670, loss_b: 7.434670,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000002, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [04:19<57:17, 36.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 6.976690, loss_v: 7.431077\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000001, Valence_ccc-0.000000\n",
      "---------------Epoch 8----------------\n",
      "Training......\n",
      "loss_a: 6.683733, loss_b: 7.325918,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000001, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [04:58<57:35, 37.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 6.672863, loss_v: 7.298497\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000001, Valence_ccc 0.000000\n",
      "---------------Epoch 9----------------\n",
      "Training......\n",
      "loss_a: 6.580268, loss_b: 6.883039,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000002, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [05:34<56:17, 37.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 6.863797, loss_v: 7.286551\n",
      "Validation ccc_mean :  0.000000, Arousal_ccc :  0.000001, Valence_ccc-0.000000\n",
      "---------------Epoch 10----------------\n",
      "Training......\n",
      "loss_a: 6.331563, loss_b: 6.848270,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000001, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [06:11<55:17, 36.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 6.621343, loss_v: 7.226316\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000001, Valence_ccc 0.000000\n",
      "---------------Epoch 11----------------\n",
      "Training......\n",
      "loss_a: 6.316764, loss_b: 6.760934,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000002, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [06:45<53:41, 36.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 6.314035, loss_v: 7.183211\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000001, Valence_ccc 0.000000\n",
      "---------------Epoch 12----------------\n",
      "Training......\n",
      "loss_a: 6.191301, loss_b: 6.755591,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000001, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [07:19<51:49, 35.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 6.228573, loss_v: 6.852206\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000001, Valence_ccc-0.000000\n",
      "---------------Epoch 13----------------\n",
      "Training......\n",
      "loss_a: 6.117363, loss_b: 6.757939,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000001, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [07:53<50:37, 34.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 6.170891, loss_v: 6.734559\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000001, Valence_ccc-0.000000\n",
      "---------------Epoch 14----------------\n",
      "Training......\n",
      "loss_a: 5.833237, loss_b: 6.575402,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000002, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [08:26<49:18, 34.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 6.033768, loss_v: 6.598603\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000001, Valence_ccc-0.000000\n",
      "---------------Epoch 15----------------\n",
      "Training......\n",
      "loss_a: 5.774301, loss_b: 6.093687,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000002, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [09:00<48:28, 34.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 5.981503, loss_v: 6.506321\n",
      "Validation ccc_mean :  0.000000, Arousal_ccc :  0.000001, Valence_ccc 0.000000\n",
      "---------------Epoch 16----------------\n",
      "Training......\n",
      "loss_a: 5.637460, loss_b: 5.902683,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000002, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [09:34<47:55, 34.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 5.679735, loss_v: 6.150301\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000001, Valence_ccc-0.000000\n",
      "---------------Epoch 17----------------\n",
      "Training......\n",
      "loss_a: 5.333306, loss_b: 5.477013,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000001, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [10:08<47:14, 34.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 5.353405, loss_v: 5.864999\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000002, Valence_ccc-0.000000\n",
      "---------------Epoch 18----------------\n",
      "Training......\n",
      "loss_a: 5.214901, loss_b: 5.501711,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000002, Valence_ccc : 0.000001\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [10:42<46:30, 34.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 5.537450, loss_v: 5.970888\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000001, Valence_ccc-0.000000\n",
      "---------------Epoch 19----------------\n",
      "Training......\n",
      "loss_a: 5.031900, loss_b: 5.368186,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000002, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [11:16<46:12, 34.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 5.120789, loss_v: 5.476257\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000002, Valence_ccc-0.000000\n",
      "---------------Epoch 20----------------\n",
      "Training......\n",
      "loss_a: 5.060417, loss_b: 5.570872,  [    0/  403]\n",
      "ccc_mean : 0.000002, Arousal_ccc : 0.000003, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [11:52<46:17, 34.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 4.927151, loss_v: 5.431253\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000002, Valence_ccc-0.000000\n",
      "---------------Epoch 21----------------\n",
      "Training......\n",
      "loss_a: 5.063538, loss_b: 5.367692,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000002, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [12:29<46:27, 35.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 4.892674, loss_v: 5.239583\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000002, Valence_ccc-0.000000\n",
      "---------------Epoch 22----------------\n",
      "Training......\n",
      "loss_a: 5.025819, loss_b: 5.277986,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000001, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [13:06<46:44, 35.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 4.708638, loss_v: 5.308932\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000002, Valence_ccc-0.000000\n",
      "---------------Epoch 23----------------\n",
      "Training......\n",
      "loss_a: 4.748735, loss_b: 5.185116,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000002, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [13:45<47:07, 36.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 4.476430, loss_v: 4.841106\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000002, Valence_ccc-0.000000\n",
      "---------------Epoch 24----------------\n",
      "Training......\n",
      "loss_a: 4.480161, loss_b: 4.806254,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000002, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [14:23<47:04, 37.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 4.550421, loss_v: 4.916803\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000002, Valence_ccc-0.000000\n",
      "---------------Epoch 25----------------\n",
      "Training......\n",
      "loss_a: 4.102454, loss_b: 4.663664,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000002, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [15:01<46:53, 37.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 4.349610, loss_v: 4.706742\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000002, Valence_ccc 0.000000\n",
      "---------------Epoch 26----------------\n",
      "Training......\n",
      "loss_a: 4.393746, loss_b: 4.583443,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000002, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [15:41<46:56, 38.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 4.058856, loss_v: 4.455139\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000002, Valence_ccc-0.000000\n",
      "---------------Epoch 27----------------\n",
      "Training......\n",
      "loss_a: 4.217886, loss_b: 4.387292,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000002, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [16:20<46:43, 38.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 3.998944, loss_v: 4.275366\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000003, Valence_ccc-0.000000\n",
      "---------------Epoch 28----------------\n",
      "Training......\n",
      "loss_a: 4.003193, loss_b: 4.387146,  [    0/  403]\n",
      "ccc_mean : 0.000002, Arousal_ccc : 0.000003, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [17:00<46:48, 39.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 4.031186, loss_v: 4.314051\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000003, Valence_ccc-0.000000\n",
      "---------------Epoch 29----------------\n",
      "Training......\n",
      "loss_a: 3.865156, loss_b: 4.207847,  [    0/  403]\n",
      "ccc_mean : 0.000002, Arousal_ccc : 0.000004, Valence_ccc : 0.000001\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [17:40<46:19, 39.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 3.776591, loss_v: 4.079048\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000003, Valence_ccc-0.000000\n",
      "---------------Epoch 30----------------\n",
      "Training......\n",
      "loss_a: 3.516464, loss_b: 3.690990,  [    0/  403]\n",
      "ccc_mean : 0.000002, Arousal_ccc : 0.000003, Valence_ccc : 0.000001\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [18:19<45:33, 39.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 3.694464, loss_v: 3.971249\n",
      "Validation ccc_mean :  0.000002, Arousal_ccc :  0.000003, Valence_ccc 0.000000\n",
      "---------------Epoch 31----------------\n",
      "Training......\n",
      "loss_a: 3.594681, loss_b: 3.956710,  [    0/  403]\n",
      "ccc_mean : 0.000002, Arousal_ccc : 0.000003, Valence_ccc : 0.000001\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [18:58<45:02, 39.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 3.484275, loss_v: 3.827316\n",
      "Validation ccc_mean :  0.000002, Arousal_ccc :  0.000003, Valence_ccc 0.000000\n",
      "---------------Epoch 32----------------\n",
      "Training......\n",
      "loss_a: 3.202631, loss_b: 3.477483,  [    0/  403]\n",
      "ccc_mean : 0.000002, Arousal_ccc : 0.000004, Valence_ccc : 0.000001\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [19:35<43:47, 38.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 3.175045, loss_v: 3.606910\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000003, Valence_ccc-0.000001\n",
      "---------------Epoch 33----------------\n",
      "Training......\n",
      "loss_a: 3.175474, loss_b: 3.214342,  [    0/  403]\n",
      "ccc_mean : 0.000002, Arousal_ccc : 0.000004, Valence_ccc : 0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [20:14<43:10, 38.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 3.424249, loss_v: 3.584817\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000002, Valence_ccc 0.000000\n",
      "---------------Epoch 34----------------\n",
      "Training......\n",
      "loss_a: 3.096219, loss_b: 3.259962,  [    0/  403]\n",
      "ccc_mean : 0.000002, Arousal_ccc : 0.000002, Valence_ccc : 0.000001\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [20:53<42:28, 38.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 3.083645, loss_v: 3.396684\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000003, Valence_ccc-0.000000\n",
      "---------------Epoch 35----------------\n",
      "Training......\n",
      "loss_a: 3.020815, loss_b: 3.137458,  [    0/  403]\n",
      "ccc_mean : 0.000002, Arousal_ccc : 0.000003, Valence_ccc : 0.000001\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [21:31<41:51, 38.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 2.934545, loss_v: 3.280876\n",
      "Validation ccc_mean :  0.000002, Arousal_ccc :  0.000004, Valence_ccc-0.000000\n",
      "---------------Epoch 36----------------\n",
      "Training......\n",
      "loss_a: 2.861715, loss_b: 3.002808,  [    0/  403]\n",
      "ccc_mean : 0.000002, Arousal_ccc : 0.000004, Valence_ccc : 0.000001\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [22:10<41:20, 38.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 2.887892, loss_v: 3.074263\n",
      "Validation ccc_mean :  0.000001, Arousal_ccc :  0.000003, Valence_ccc-0.000001\n",
      "---------------Epoch 37----------------\n",
      "Training......\n",
      "loss_a: 2.877486, loss_b: 2.966521,  [    0/  403]\n",
      "ccc_mean : 0.000001, Arousal_ccc : 0.000001, Valence_ccc : 0.000001\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [22:49<40:34, 38.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 2.811957, loss_v: 2.984184\n",
      "Validation ccc_mean :  0.000002, Arousal_ccc :  0.000004, Valence_ccc 0.000000\n",
      "---------------Epoch 38----------------\n",
      "Training......\n",
      "loss_a: 2.708097, loss_b: 2.857301,  [    0/  403]\n",
      "ccc_mean : 0.000002, Arousal_ccc : 0.000004, Valence_ccc : 0.000001\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [23:27<39:44, 38.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 2.668701, loss_v: 2.931775\n",
      "Validation ccc_mean :  0.000002, Arousal_ccc :  0.000005, Valence_ccc-0.000000\n",
      "---------------Epoch 39----------------\n",
      "Training......\n",
      "loss_a: 2.488497, loss_b: 2.702600,  [    0/  403]\n",
      "ccc_mean : 0.000002, Arousal_ccc : 0.000004, Valence_ccc : -0.000000\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [24:03<38:23, 37.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 2.457895, loss_v: 2.595644\n",
      "Validation ccc_mean :  0.000002, Arousal_ccc :  0.000004, Valence_ccc-0.000001\n",
      "---------------Epoch 40----------------\n",
      "Training......\n",
      "loss_a: 2.509080, loss_b: 2.545574,  [    0/  403]\n",
      "ccc_mean : 0.000003, Arousal_ccc : 0.000005, Valence_ccc : 0.000001\n",
      "Test or Validation......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [24:37<36:47, 36.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_a: 2.400854, loss_v: 2.619709\n",
      "Validation ccc_mean :  0.000002, Arousal_ccc :  0.000004, Valence_ccc-0.000000\n",
      "---------------Epoch 41----------------\n",
      "Training......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [24:43<37:04, 37.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m---------------Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m----------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining......\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m train(train_dataloader, model_tf_mixer, loss_fn, optimizer)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest or Validation......\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m test(validation_dataloader, model_tf_mixer, loss_fn, mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[39], line 24\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     21\u001b[0m ccc_mean \u001b[39m=\u001b[39m (pred_ccc_a \u001b[39m+\u001b[39m pred_ccc_v) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 24\u001b[0m loss_a\u001b[39m.\u001b[39;49mbackward(retain_graph \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     25\u001b[0m loss_v\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     26\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/project/paradeigma/multi_modal/.venv/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/project/paradeigma/multi_modal/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "lr = 1e-3\n",
    "loss_fn = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(model_tf_mixer.parameters(), lr=lr)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"---------------Epoch {epoch+1}----------------\")\n",
    "    print(\"Training......\")\n",
    "    train(train_dataloader, model_tf_mixer, loss_fn, optimizer)\n",
    "    print(\"Test or Validation......\")\n",
    "    test(validation_dataloader, model_tf_mixer, loss_fn, mode = 'val')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "564397ef3f14238fe220c0b968cb968ca820ea6375fbb466d018d4bbc6f32a14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
