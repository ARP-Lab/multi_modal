{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a Original Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* if has not dataset, you must do unlock comment and excute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !./init y19"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "import shutil\n",
    "\n",
    "from utils.dfl import dfl_base, dfl_tools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"KEMDy19\"\n",
    "origin_dp = f\"{dir_name}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_info(\n",
    "    file_path: str=\"\"\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    csv_list = []\n",
    "    with open(file_path) as f:\n",
    "        r = csv.reader(f)\n",
    "\n",
    "        for l in r:\n",
    "            csv_list.append(l)\n",
    "\n",
    "    return pd.DataFrame(csv_list)\n",
    "\n",
    "\n",
    "def make_merged_data(\n",
    "    target_dir_list: List[str],\n",
    "    file_list: List[str],\n",
    "    session_name: str\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    assert session_name != None\n",
    "    \n",
    "    res: pd.DataFrame = None\n",
    "        \n",
    "    for _f in file_list:\n",
    "        _fds = {}\n",
    "        \n",
    "        for tdp in target_dir_list:\n",
    "            _td = tdp.split(\"/\")\n",
    "            \n",
    "            # print(f\"{session_name}, {file}, {target_dir[1]}\")\n",
    "            # Directory path form name is as like \"KEMDy19/EDA/Session01/Sess01_script01_User001F.csv\"\n",
    "            _fds[_td[1]] = read_csv_info(f\"./{_td[0]}/{_td[1]}/{session_name}/Original/{_f}\")\n",
    "            \n",
    "            if _td[1] == \"ECG\":\n",
    "                _fds[_td[1]] = _fds[_td[1]].drop(columns=_fds[_td[1]].columns[0])\n",
    "            else:\n",
    "                _fds[_td[1]] = _fds[_td[1]].drop(columns=_fds[_td[1]].columns[1])\n",
    "            _fds[_td[1]] = _fds[_td[1]].T.reset_index(drop=True).T\n",
    "        \n",
    "        # ** for check data\n",
    "        # for x in target_dir_list:\n",
    "        #     t = x.split(\"/\")\n",
    "        #     print(f\"{t[1]} : \")\n",
    "        #     print(file_datas[t[1]].to_string())\n",
    "        \n",
    "        # attatching column names\n",
    "        \n",
    "        _fds[\"EDA\"] = _fds[\"EDA\"].set_axis([\"eda\", \"timestamp\", \"sid\"], axis=1)\n",
    "        _fds[\"ECG\"] = _fds[\"ECG\"].set_axis([\"ecg\", \"timestamp\", \"sid\"], axis=1)\n",
    "        _fds[\"TEMP\"] = _fds[\"TEMP\"].set_axis([\"temp\", \"timestamp\", \"sid\"], axis=1)\n",
    "\n",
    "        # Merge \"TEMP\" table to \"EDA\" \n",
    "        _opd = pd.merge(\n",
    "            _fds[\"EDA\"], _fds[\"TEMP\"],\n",
    "            left_on='timestamp', right_on='timestamp', how='outer')\n",
    "        del _opd[\"sid_x\"]\n",
    "        _opd = _opd.rename(columns={\"sid_y\": \"sid\"})\n",
    "\n",
    "        # Merge \"ECG\" table to merged table(\"EDA\" and \"TEMP\")\n",
    "        _opd = pd.merge(\n",
    "            _opd, _fds[\"ECG\"],\n",
    "            left_on='timestamp', right_on='timestamp', how='outer')\n",
    "        _opd[\"sid_x\"] = _opd[\"sid_x\"].fillna(_opd[\"sid_y\"])\n",
    "        del _opd[\"sid_y\"]\n",
    "        _opd = _opd.rename(columns={\"sid_x\": \"sid\"})\n",
    "\n",
    "        # reorder following as \"timestamp\", \"sid\", \"eda\", \"temp\", \"ecg\"\n",
    "        _opd = _opd[[\"timestamp\", \"sid\", \"eda\", \"temp\", \"ecg\"]]\n",
    "        # sorting values from \"timestamp\" column\n",
    "        _opd = _opd.sort_values(\"timestamp\")\n",
    "        _opd = _opd.reset_index(drop=True)\n",
    "        \n",
    "        if res is None:\n",
    "            res = _opd\n",
    "        else:\n",
    "            res = pd.concat([res, _opd], sort=True)\n",
    "            # result = result.append(one_part_data_on_session, ignore_index=True)\n",
    "            \n",
    "    res = res[[\"timestamp\", \"sid\", \"eda\", \"temp\", \"ecg\"]]\n",
    "    res = res.sort_values(\"timestamp\")\n",
    "    res = res.reset_index(drop=True)\n",
    "    \n",
    "    # print(result.to_string())\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get organized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make wav directory to root\n",
    "org_dp = f\"org_{dir_name}\"\n",
    "\n",
    "dfl_base.make_dir(\".\", org_dp)\n",
    "\n",
    "_wd = dfl_tools.find_dfl_path(f\"./{dir_name}\", [\"wav\"], mode=\"d\", only_leaf=\"True\")\n",
    "_sl = dfl_tools.find_dfl_path(f\"{_wd[0]}\", [\"\"], mode=\"d\", only_leaf=\"True\", res_all=True)\n",
    "\n",
    "for l, r in _sl:\n",
    "    dfl_base.make_dir(f\"./{org_dp}\", r)\n",
    "    _ssl = dfl_tools.find_dfl_path(f\"{l}\", [\"\"], mode=\"d\", only_leaf=\"True\")\n",
    "    \n",
    "    _mv_path = f\"./{org_dp}/{r}\"\n",
    "    \n",
    "    for _d in _ssl:\n",
    "        _fl = dfl_tools.find_dfl_path(_d, [\"\"], mode=\"f\", only_leaf=\"True\")\n",
    "        for f in _fl:\n",
    "            shutil.move(f, _mv_path)\n",
    "\n",
    "src_ap = os.path.join(os.getcwd(), f\"{origin_dp}/annotation\")\n",
    "dest_ap = os.path.join(os.getcwd(), f\"{org_dp}/annotation\")\n",
    "\n",
    "target_dir_list = [\"EDA\", \"ECG\", \"TEMP\"]\n",
    "\n",
    "sd_list = []\n",
    "\n",
    "for _td in target_dir_list:\n",
    "    _sdl = dfl_tools.find_dfl_path(f\"./{origin_dp}/{_td}\", [\"Session\"], mode=\"d\", only_leaf=True, res_all=True)\n",
    "    sd_list += [x[1] for x in _sdl]\n",
    "    sd_list = list(set(sd_list))\n",
    "\n",
    "sd_list = sorted(sd_list)\n",
    "\n",
    "for _sn in sd_list:\n",
    "    _tf = []\n",
    "    \n",
    "    for _td in target_dir_list:\n",
    "        _sfl = dfl_tools.find_dfl_path(f\"./{origin_dp}/{_td}/{_sn}\", [\"\"], mode=\"f\", recur=True, only_leaf=True, res_all=True)\n",
    "        _tf += [x[1] for x in _sfl]\n",
    "        \n",
    "    _tf = list(set(_tf))\n",
    "    _tf = sorted(_tf)\n",
    "    \n",
    "    _smd = make_merged_data([f\"{origin_dp}/{x}\" for x in target_dir_list], _tf, _sn)\n",
    "    _smd.to_csv(f\"{org_dp}/{_sn}/{_sn}.csv\", sep=\",\", na_rep=\"NaN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bdc1fd12ca460d5768d71e9df3d9063ef832ce64a62e55a1a523c8c99752868e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
