{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working model for tensorfusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torchmetrics import F1Score\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wav, text데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Session01', 'Session02', 'Session03', 'Session04', 'Session05']) \n",
      "\n",
      " dict_keys(['file_names', 'text_embeddings', 'wav_embeddings', 'Emotion', 'Arousal', 'Valence'])\n"
     ]
    }
   ],
   "source": [
    "# wav and text data load\n",
    "dataset_file_lst = glob('./data/lou_dataset*.pkl')\n",
    "dataset_file_lst = sorted(dataset_file_lst)\n",
    "raw_dataset = {}\n",
    "for i in dataset_file_lst:\n",
    "    with open(i, 'rb') as f:\n",
    "        new_dataset = pickle.load(f)\n",
    "        raw_dataset  = dict(**raw_dataset, **new_dataset)\n",
    "session = 'Session01'\n",
    "print(raw_dataset.keys(),'\\n\\n', raw_dataset[session].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_lst = glob('../org_KEMDy20/annotation/*.csv')\n",
    "emotion_list = []\n",
    "for annot_file in annot_lst:\n",
    "    annot = pd.read_csv(annot_file, skiprows=1)\n",
    "    emotion_list.append(annot['Emotion'])\n",
    "emotion_list = list(pd.Series([j for i in emotion_list for j in i]).unique())\n",
    "len(emotion_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### \n",
    "emotion_lst = []\n",
    "sessions = ['Session01', 'Session02', 'Session03', 'Session04', 'Session05']\n",
    "\n",
    "for session in sessions:\n",
    "    emotion_lst.append(raw_dataset[session]['Emotion'].unique())\n",
    "\n",
    "emotion_lst = [j for i in emotion_lst for j in i]\n",
    "emotion_lst = list(pd.Series(emotion_lst).unique())\n",
    "len(emotion_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'happy': 0,\n",
       "  'neutral': 1,\n",
       "  'surprise': 2,\n",
       "  'surprise;neutral': 3,\n",
       "  'sad': 4,\n",
       "  'neutral;sad': 5,\n",
       "  'happy;neutral': 6,\n",
       "  'angry;neutral': 7,\n",
       "  'neutral;disqust': 8,\n",
       "  'angry': 9,\n",
       "  'fear': 10,\n",
       "  'neutral;fear': 11,\n",
       "  'disqust': 12,\n",
       "  'happy;surprise': 13,\n",
       "  'happy;angry;neutral': 14,\n",
       "  'angry;disqust': 15,\n",
       "  'happy;surprise;neutral': 16,\n",
       "  'happy;fear': 17,\n",
       "  'happy;neutral;fear': 18,\n",
       "  'angry;neutral;disqust': 19,\n",
       "  'neutral;disqust;sad': 20,\n",
       "  'angry;neutral;disqust;fear;sad': 21,\n",
       "  'happy;sad': 22,\n",
       "  'happy;neutral;disqust': 23},\n",
       " {0: 'happy',\n",
       "  1: 'neutral',\n",
       "  2: 'surprise',\n",
       "  3: 'surprise;neutral',\n",
       "  4: 'sad',\n",
       "  5: 'neutral;sad',\n",
       "  6: 'happy;neutral',\n",
       "  7: 'angry;neutral',\n",
       "  8: 'neutral;disqust',\n",
       "  9: 'angry',\n",
       "  10: 'fear',\n",
       "  11: 'neutral;fear',\n",
       "  12: 'disqust',\n",
       "  13: 'happy;surprise',\n",
       "  14: 'happy;angry;neutral',\n",
       "  15: 'angry;disqust',\n",
       "  16: 'happy;surprise;neutral',\n",
       "  17: 'happy;fear',\n",
       "  18: 'happy;neutral;fear',\n",
       "  19: 'angry;neutral;disqust',\n",
       "  20: 'neutral;disqust;sad',\n",
       "  21: 'angry;neutral;disqust;fear;sad',\n",
       "  22: 'happy;sad',\n",
       "  23: 'happy;neutral;disqust'})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding Emotion for whole data\n",
    "# 사전에 실제로 encoding한 끝 수가 마지막 linear layer의 끝자리랑 맞아야 합니다. 아니면 CUDA error: CUBLAS_STATUS_EXECUTION_FAILED가 나는 것 같아요.\n",
    "# 예를 들어, label이 0~9, 11,13이렇게 12개가 되었어도, 0~13은 14개니까 마지막 레이어에서 14개 unit을 받아야 multiclass classification이 에러없이 진행됩니다!\n",
    "encode_dict = {b:i for i, b in enumerate(emotion_list)}\n",
    "decode_dict = {i:b for i, b in enumerate(emotion_list)}\n",
    "encode_dict, decode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['file_names', 'text_embeddings', 'wav_embeddings', 'Emotion', 'Arousal', 'Valence'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset = {}\n",
    "for session_key in raw_dataset.keys():\n",
    "    raw_dataset[session_key]['Emotion'] = raw_dataset[session_key]['Emotion'].map(encode_dict) #encoding\n",
    "    \n",
    "    for data_name in raw_dataset[session_key].keys():\n",
    "        if data_name in merged_dataset.keys():\n",
    "            for data in raw_dataset[session_key][data_name]:\n",
    "                merged_dataset[data_name].append(data)\n",
    "        else:\n",
    "            merged_dataset[data_name] = []\n",
    "            for data in raw_dataset[session_key][data_name]:\n",
    "                merged_dataset[data_name].append(data)\n",
    "    \n",
    "for data_name in merged_dataset.keys():\n",
    "    if data_name == 'text_embeddings' or data_name == 'wav_embeddings':\n",
    "        merged_dataset[data_name] = torch.stack(merged_dataset[data_name])\n",
    "\n",
    "merged_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1323,\n",
       "         0: 107,\n",
       "         6: 33,\n",
       "         3: 6,\n",
       "         13: 3,\n",
       "         7: 9,\n",
       "         2: 13,\n",
       "         9: 15,\n",
       "         5: 7,\n",
       "         12: 8,\n",
       "         8: 6,\n",
       "         4: 12,\n",
       "         10: 6,\n",
       "         11: 1})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(merged_dataset['Emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_names:  1549\n",
      "text_embeddings:  1549\n",
      "wav_embeddings:  1549\n",
      "Emotion:  1549\n",
      "Arousal:  1549\n",
      "Valence:  1549\n"
     ]
    }
   ],
   "source": [
    "# check the length of each data column\n",
    "for i in merged_dataset.keys():\n",
    "    print(f\"{i}: \", len(merged_dataset[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temp, EDA data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Emotion.1</th>\n",
       "      <th>Valence.1</th>\n",
       "      <th>Arousal.1</th>\n",
       "      <th>...</th>\n",
       "      <th>Emotion.9</th>\n",
       "      <th>Valence.9</th>\n",
       "      <th>Arousal.9</th>\n",
       "      <th>Emotion.10</th>\n",
       "      <th>Valence.10</th>\n",
       "      <th>Arousal.10</th>\n",
       "      <th>index</th>\n",
       "      <th>eda</th>\n",
       "      <th>temp</th>\n",
       "      <th>new_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.578390</td>\n",
       "      <td>11.637391</td>\n",
       "      <td>Sess01_script01_User002M_001</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.06791500000000017, -0.110201, -0.025627999...</td>\n",
       "      <td>[34.81, 34.81, 34.81, 34.79, 34.79, 34.79, 34....</td>\n",
       "      <td>[10, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11.637391</td>\n",
       "      <td>23.334393</td>\n",
       "      <td>Sess01_script01_User002M_002</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.006407000000000274, -0.021784000000000248, ...</td>\n",
       "      <td>[34.79, 34.79, 34.79, 34.77, 34.77, 34.77, 34....</td>\n",
       "      <td>[10, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23.334393</td>\n",
       "      <td>31.558392</td>\n",
       "      <td>Sess01_script01_User002M_003</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.07944700000000005, 0.05125599999999997, 0.0...</td>\n",
       "      <td>[34.75, 34.75, 34.75, 34.75, 34.79, 34.79, 34....</td>\n",
       "      <td>[10, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          start        end                    segment_id  Emotion  Valence  \\\n",
       "0  1   3.578390  11.637391  Sess01_script01_User002M_001  neutral      3.4   \n",
       "1  2  11.637391  23.334393  Sess01_script01_User002M_002  neutral      3.1   \n",
       "2  3  23.334393  31.558392  Sess01_script01_User002M_003  neutral      3.1   \n",
       "\n",
       "   Arousal Emotion.1  Valence.1  Arousal.1  ... Emotion.9  Valence.9  \\\n",
       "0      2.9   neutral          3          3  ...   neutral          3   \n",
       "1      2.9   neutral          3          3  ...   neutral          3   \n",
       "2      3.0   neutral          3          3  ...   neutral          3   \n",
       "\n",
       "   Arousal.9 Emotion.10  Valence.10  Arousal.10 index  \\\n",
       "0          3    neutral           3           3     0   \n",
       "1          3    neutral           3           3     1   \n",
       "2          3    neutral           3           3     2   \n",
       "\n",
       "                                                 eda  \\\n",
       "0  [-0.06791500000000017, -0.110201, -0.025627999...   \n",
       "1  [0.006407000000000274, -0.021784000000000248, ...   \n",
       "2  [0.07944700000000005, 0.05125599999999997, 0.0...   \n",
       "\n",
       "                                                temp             new_emotion  \n",
       "0  [34.81, 34.81, 34.81, 34.79, 34.79, 34.79, 34....  [10, 0, 0, 0, 0, 0, 0]  \n",
       "1  [34.79, 34.79, 34.79, 34.77, 34.77, 34.77, 34....  [10, 0, 0, 0, 0, 0, 0]  \n",
       "2  [34.75, 34.75, 34.75, 34.75, 34.79, 34.79, 34....  [10, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data load\n",
    "# 아래 데이터에서 new_emotion의 라벨링 의미는 순서대로 ['neutral', 'happy', 'surprise', 'disgust', 'angry', 'sad', 'fear']\n",
    "with open('./data/lou_ts_dataset.pkl', 'rb') as f:\n",
    "    ts_dataset = pickle.load(f)\n",
    "    \n",
    "ts_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/107874/how-to-deal-with-a-skewed-class-in-binary-classification-having-many-features\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch dataset 만들기\n",
    "- 참고: https://tutorials.pytorch.kr/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EtriDataset(Dataset):\n",
    "    def __init__(self, file_names, \n",
    "                 text_embeddings, \n",
    "                 wav_embeddings, \n",
    "                 Temp,\n",
    "                 EDA,\n",
    "                 Emotion,\n",
    "                 Emotion_ext, \n",
    "                 Arousal, \n",
    "                 Valence):\n",
    "        self.file_names = file_names\n",
    "        self.text_embeddings = text_embeddings\n",
    "        self.wav_embeddings = wav_embeddings\n",
    "        self.temp = Temp\n",
    "        self.eda = EDA\n",
    "        self.label_emotion = Emotion\n",
    "        self.label_emotion_ext = Emotion_ext\n",
    "        self.label_arousal = Arousal\n",
    "        self.label_valence = Valence\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_embeddings = self.text_embeddings[idx]\n",
    "        wav_embeddings = self.wav_embeddings[idx]\n",
    "        temp = self.temp[idx]\n",
    "        eda = self.eda[idx]\n",
    "        label_emotion = self.label_emotion[idx]\n",
    "        label_emotion_ext = self.label_emotion_ext[idx]\n",
    "        label_arousal = self.label_arousal[idx]\n",
    "        label_valence = self.label_valence[idx]\n",
    "        return text_embeddings, wav_embeddings, temp, eda, label_emotion, label_emotion_ext, label_arousal, label_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load 및 나누기: https://076923.github.io/posts/Python-pytorch-11/\n",
    "\n",
    "# 개별 session 데이터 셋을 만들었을 때 \n",
    "# dataset = EtriDataset(raw_dataset[session]['file_names'],\n",
    "#                       raw_dataset[session]['text_embeddings'],\n",
    "#                       raw_dataset[session]['wav_embeddings'],\n",
    "#                       raw_dataset[session]['Emotion'],\n",
    "#                       raw_dataset[session]['Arousal'],\n",
    "#                       raw_dataset[session]['Valence'])\n",
    "\n",
    "# session을 통합시킨 데이터 셋을 만들었을 때\n",
    "dataset = EtriDataset(file_names = merged_dataset['file_names'],\n",
    "                      text_embeddings = merged_dataset['text_embeddings'],\n",
    "                      wav_embeddings = merged_dataset['wav_embeddings'],\n",
    "                      Emotion = merged_dataset['Emotion'],\n",
    "                      Arousal = merged_dataset['Arousal'],\n",
    "                      Valence = merged_dataset['Valence'],\n",
    "                      EDA = ts_dataset['eda'][:1549], ## 일부 세션 데이터만 사용하므로, 길이를 맞춰주기 위해 일부 slicing함\n",
    "                      Temp = ts_dataset['temp'][:1549], ## 일부 세션 데이터만 사용하므로, 길이를 맞춰주기 위해 일부 slicing함\n",
    "                      Emotion_ext = ts_dataset['new_emotion'][:1549]) ## 일부 세션 데이터만 사용하므로, 길이를 맞춰주기 위해 일부 slicing함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1084 233 232\n",
      "Training Data Size : 1084\n",
      "Validation Data Size : 232\n",
      "Testing Data Size : 233\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.7)\n",
    "validation_size = int(dataset_size * 0.15)\n",
    "test_size = dataset_size - train_size - validation_size\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
    "\n",
    "print(train_size, test_size, validation_size)\n",
    "print(f\"Training Data Size : {len(train_dataset)}\")\n",
    "print(f\"Validation Data Size : {len(validation_dataset)}\")\n",
    "print(f\"Testing Data Size : {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 49, 768])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data size\n",
    "merged_dataset['wav_embeddings'][0].shape \n",
    "# raw_dataset[session]['wav_embeddings'][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True, drop_last=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True, drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetWork 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNetwork_pre(nn.Module):\n",
    "    def __init__(self, input_length, input_width):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_length*input_width, 768)\n",
    "        self.gelu1 = nn.GELU()\n",
    "        self.bn1 = nn.BatchNorm1d(768)\n",
    "        self.fc2 = nn.Linear(768, 512)\n",
    "        self.gelu2 = nn.GELU()\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 32)\n",
    "        self.gelu3 = nn.GELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.gelu2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc3(x)\n",
    "        output = self.gelu3(x)\n",
    "        return output\n",
    "\n",
    "class MLPNetwork_final(nn.Module):\n",
    "    def __init__(self, input_length, input_width):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_length*input_width, 256)\n",
    "        self.gelu1 = nn.GELU()\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.gelu2 = nn.GELU()\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 14)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.gelu1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.gelu2(x)\n",
    "        x = self.bn2(x)\n",
    "        output = self.fc3(x)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n",
      "DataParallel(\n",
      "  (module): TensorFusionMixer(\n",
      "    (ModelA): MLPNetwork_pre(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=61440, out_features=768, bias=True)\n",
      "      (gelu1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc2): Linear(in_features=768, out_features=512, bias=True)\n",
      "      (gelu2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc3): Linear(in_features=512, out_features=32, bias=True)\n",
      "      (gelu3): GELU(approximate='none')\n",
      "    )\n",
      "    (ModelB): MLPNetwork_pre(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=37632, out_features=768, bias=True)\n",
      "      (gelu1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc2): Linear(in_features=768, out_features=512, bias=True)\n",
      "      (gelu2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc3): Linear(in_features=512, out_features=32, bias=True)\n",
      "      (gelu3): GELU(approximate='none')\n",
      "    )\n",
      "    (Model_mlp_final): MLPNetwork_final(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      (gelu1): GELU(approximate='none')\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (gelu2): GELU(approximate='none')\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fc3): Linear(in_features=64, out_features=14, bias=True)\n",
      "    )\n",
      "    (softmax): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class TensorFusionMixer(nn.Module):\n",
    "    def __init__(self, ModelA, ModelB):\n",
    "        super().__init__()\n",
    "        self.ModelA = ModelA\n",
    "        self.ModelB = ModelB\n",
    "        self.Model_mlp_final = MLPNetwork_final(32,32).to(device)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def tensor_fusion(self, batch_arr1, batch_arr2):\n",
    "        fusion_matrix_lst = []\n",
    "        for i, (arr1, arr2) in enumerate(zip(batch_arr1, batch_arr2)):\n",
    "            outer_matrix = torch.outer(arr1, arr2)\n",
    "            l, w = outer_matrix.shape\n",
    "            outer_matrix = outer_matrix.view(1, l, w)\n",
    "            fusion_matrix_lst.append(outer_matrix)\n",
    "        fusion_matrix = torch.concat(fusion_matrix_lst)\n",
    "        # print(fusion_matrix.shape)\n",
    "        return fusion_matrix\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.ModelA(x1)\n",
    "        x2 = self.ModelB(x2)\n",
    "        fusion_matrix = self.tensor_fusion(x1, x2) \n",
    "        x = self.Model_mlp_final(fusion_matrix)\n",
    "        output = self.softmax(x)\n",
    "        return output     \n",
    "\n",
    "\n",
    "# txt_input_length, txt_input_width = raw_dataset[session]['text_embeddings'][0].shape | 마지막엔 지울 것\n",
    "# _, wav_input_length, wav_input_width = raw_dataset[session]['wav_embeddings'][0].shape\n",
    "txt_input_length, txt_input_width = merged_dataset['text_embeddings'][0].shape\n",
    "_, wav_input_length, wav_input_width = merged_dataset['wav_embeddings'][0].shape\n",
    "\n",
    "# tf_mixer에 들어갈 wav mlp, txt mlp 선언\n",
    "model_mlp_txt = MLPNetwork_pre(txt_input_length,txt_input_width).to(device)\n",
    "model_mlp_wav = MLPNetwork_pre(wav_input_length,wav_input_width).to(device)\n",
    "\n",
    "# 최종 모델 선언\n",
    "model_tf_mixer = TensorFusionMixer(ModelA = model_mlp_txt, ModelB = model_mlp_wav).to(device)\n",
    "\n",
    "# model 병렬 학습 처리\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model_mlp_txt = nn.DataParallel(model_mlp_txt).to(device)\n",
    "    model_mlp_wav = nn.DataParallel(model_mlp_wav).to(device)\n",
    "    model_tf_mixer = nn.DataParallel(model_tf_mixer).to(device)\n",
    "print(model_tf_mixer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습을 위한 train, test method 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # data 순서: text_embeddings, wav_embeddings, temp, eda, label_emotion, label_emotion_ext, label_arousal, label_valence\n",
    "    for batch, (X_txt, X_wav, X_temp, X_eda, \n",
    "                    label_emotion, label_emotion_ext, label_arousal, label_valence) in enumerate(dataloader): \n",
    "        y = label_emotion # 라벨을 변경하고자 하면 이 변수만 바꿔주면 나머지는 y로 적용\n",
    "        # 예측 오류 계산\n",
    "        X_txt, X_wav, y = X_txt.to(device), X_wav.to(device),y.type(torch.LongTensor).to(device)\n",
    "        pred = model(X_txt, X_wav)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X_txt)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, mode = 'test'):\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    f1 = F1Score(task= 'multiclass', num_classes=14).to(device)   \n",
    "    preds = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        # data 순서: text_embeddings, wav_embeddings, temp, eda, label_emotion, label_emotion_ext, label_arousal, label_valence\n",
    "        for batch, (X_txt, X_wav, X_temp, X_eda, \n",
    "                        label_emotion, label_emotion_ext, label_arousal, label_valence) in enumerate(dataloader): \n",
    "            y = label_emotion # 라벨을 변경하고자 하면 이 변수만 바꿔주면 나머지는 y로 적용\n",
    "            # 예측 오류 계산\n",
    "            X_txt, X_wav, y = X_txt.to(device), X_wav.to(device),y.type(torch.LongTensor).to(device)\n",
    "            pred = model(X_txt, X_wav)\n",
    "            preds.append(pred)\n",
    "            targets.append(y)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    if mode == 'test':\n",
    "        print(torch.cat(preds), torch.cat(preds).shape)\n",
    "        print(\"f1 score: \", f1(torch.cat(preds).to(device), torch.cat(targets).to(device)))\n",
    "        print(f\"Test Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")\n",
    "    elif mode == 'val':\n",
    "        print(f\"Validation Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9309, 0.1459, 0.9916, 0.9961, 0.9923, 0.9955, 0.9787, 0.9942, 0.9961,\n",
       "        0.9903, 0.9961, 0.9994, 0.9948, 0.9981])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weigted loss for imbalance data: https://naadispeaks.wordpress.com/2021/07/31/handling-imbalanced-classes-with-weighted-loss-in-pytorch/\n",
    "weight_for_class = []\n",
    "for idx, value in sorted(Counter(merged_dataset['Emotion']).items()):\n",
    "    weight_for_class.append(1 - (value/len(merged_dataset['Emotion'])))\n",
    "weight_for_class = torch.Tensor(weight_for_class)\n",
    "weight_for_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(weight=weight_for_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Epoch 1----------------\n",
      "loss: 2.640114  [    0/ 1084]\n",
      "Validation Error: Accuracy: 0.0%, Avg loss: 2.640632 \n",
      "\n",
      "---------------Epoch 2----------------\n",
      "loss: 2.639903  [    0/ 1084]\n",
      "Validation Error: Accuracy: 0.0%, Avg loss: 2.640750 \n",
      "\n",
      "---------------Epoch 3----------------\n",
      "loss: 2.638678  [    0/ 1084]\n",
      "Validation Error: Accuracy: 0.0%, Avg loss: 2.640495 \n",
      "\n",
      "---------------Epoch 4----------------\n",
      "loss: 2.640101  [    0/ 1084]\n",
      "Validation Error: Accuracy: 0.0%, Avg loss: 2.640718 \n",
      "\n",
      "---------------Epoch 5----------------\n",
      "loss: 2.638709  [    0/ 1084]\n",
      "Validation Error: Accuracy: 0.0%, Avg loss: 2.640918 \n",
      "\n",
      "---------------Epoch 6----------------\n",
      "loss: 2.639854  [    0/ 1084]\n",
      "Validation Error: Accuracy: 0.0%, Avg loss: 2.640227 \n",
      "\n",
      "---------------Epoch 7----------------\n",
      "loss: 2.640402  [    0/ 1084]\n",
      "Validation Error: Accuracy: 0.0%, Avg loss: 2.640461 \n",
      "\n",
      "---------------Epoch 8----------------\n",
      "loss: 2.638827  [    0/ 1084]\n",
      "Validation Error: Accuracy: 0.0%, Avg loss: 2.640275 \n",
      "\n",
      "---------------Epoch 9----------------\n",
      "loss: 2.639639  [    0/ 1084]\n",
      "Validation Error: Accuracy: 0.0%, Avg loss: 2.640286 \n",
      "\n",
      "---------------Epoch 10----------------\n",
      "loss: 2.638679  [    0/ 1084]\n",
      "Validation Error: Accuracy: 0.0%, Avg loss: 2.639954 \n",
      "\n",
      "---------------Epoch 11----------------\n",
      "loss: 2.639186  [    0/ 1084]\n",
      "Validation Error: Accuracy: 0.0%, Avg loss: 2.640001 \n",
      "\n",
      "---------------Epoch 12----------------\n",
      "loss: 2.638262  [    0/ 1084]\n",
      "Validation Error: Accuracy: 0.0%, Avg loss: 2.639907 \n",
      "\n",
      "---------------Epoch 13----------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m---------------Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m----------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     train(train_dataloader, model_tf_mixer, loss_fn, optimizer)\n\u001b[1;32m     10\u001b[0m     test(validation_dataloader, model_tf_mixer, loss_fn, mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[74], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# 역전파\u001b[39;00m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     16\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m batch \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/project/lou/multi_modal/.venv/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/project/lou/multi_modal/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set the Training Parameters\n",
    "lr = 1e-2\n",
    "# loss_fn = nn.CrossEntropyLoss().to(device) # weigth를 주기위해 위의  loss로 임시 변경\n",
    "optimizer = optim.SGD(model_tf_mixer.parameters(), lr=lr)\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    print(f\"---------------Epoch {epoch+1}----------------\")\n",
    "    train(train_dataloader, model_tf_mixer, loss_fn, optimizer)\n",
    "    test(validation_dataloader, model_tf_mixer, loss_fn, mode = 'val')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험을 위해 모델 저장\n",
    "\n",
    "# PATH = './data/test_model.pkl'\n",
    "# torch.save(model_tf_mixer, PATH)\n",
    "\n",
    "# model_tf_mixer = torch.load(PATH)\n",
    "# model_tf_mixer.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic TensorFusionNet 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0684, 0.0713, 0.0663,  ..., 0.0762, 0.0644, 0.0712],\n",
      "        [0.0684, 0.0713, 0.0663,  ..., 0.0762, 0.0644, 0.0712],\n",
      "        [0.0684, 0.0713, 0.0663,  ..., 0.0762, 0.0644, 0.0712],\n",
      "        ...,\n",
      "        [0.0684, 0.0713, 0.0663,  ..., 0.0762, 0.0644, 0.0712],\n",
      "        [0.0684, 0.0713, 0.0663,  ..., 0.0762, 0.0644, 0.0712],\n",
      "        [0.0684, 0.0713, 0.0663,  ..., 0.0762, 0.0644, 0.0712]],\n",
      "       device='cuda:0') torch.Size([192, 14])\n",
      "f1 score:  tensor(0.0156, device='cuda:0')\n",
      "Test Error: Accuracy: 1.3%, Avg loss: 2.638653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(test_dataloader, model_tf_mixer, loss_fn, mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0381, -0.7603,  0.8985,  ..., -0.7949,  0.3474,  0.5243],\n",
      "         [-0.4802, -0.5332,  0.3545,  ..., -0.6228,  0.5918,  0.3131],\n",
      "         [ 0.3046, -0.5937,  0.9001,  ..., -0.5867,  0.5515,  0.3712],\n",
      "         ...,\n",
      "         [ 0.2341, -0.5206,  0.9087,  ..., -0.7585,  0.5719,  0.2424],\n",
      "         [ 0.4471, -0.4127,  0.5555,  ..., -0.8732,  0.6785,  0.2549],\n",
      "         [ 0.3333, -0.4066,  0.7885,  ..., -0.8892,  0.8451,  0.3848]],\n",
      "\n",
      "        [[ 0.6445, -0.2347,  1.4059,  ...,  0.7204,  0.3989,  1.3455],\n",
      "         [ 0.1357, -1.1550,  1.3380,  ...,  0.8550,  0.6634,  0.6536],\n",
      "         [ 0.4919, -1.1581,  1.2154,  ...,  0.6415,  1.0550,  0.8621],\n",
      "         ...,\n",
      "         [ 0.1621, -1.4575,  1.5977,  ...,  0.9408,  0.2274,  0.7194],\n",
      "         [ 0.4946, -1.2376,  1.5848,  ...,  0.4305,  0.0463,  0.8072],\n",
      "         [ 0.5632, -1.1244,  1.6278,  ...,  0.5977,  0.1313,  0.8748]],\n",
      "\n",
      "        [[ 0.0866, -0.8200,  1.1103,  ..., -0.1692,  1.0305,  0.2607],\n",
      "         [ 0.9904, -0.3519,  1.6237,  ..., -0.2196,  1.6568, -0.8233],\n",
      "         [-0.6725, -1.0335,  0.0920,  ...,  0.6041, -0.1006,  1.1750],\n",
      "         ...,\n",
      "         [ 1.2373, -1.3817,  0.8014,  ..., -0.2680,  0.9273, -0.9861],\n",
      "         [ 0.1656, -0.9640,  1.0433,  ..., -0.1855,  0.7627, -0.6094],\n",
      "         [ 0.1155, -1.2576,  0.7904,  ..., -0.3139,  0.8184, -0.0868]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5373, -0.8587,  0.1826,  ...,  0.2559,  1.0990,  1.1063],\n",
      "         [-0.5734, -0.9703,  0.3847,  ..., -0.0372,  1.4620,  1.0008],\n",
      "         [-1.4552, -1.3647, -0.1313,  ...,  1.0417,  1.3504,  1.4033],\n",
      "         ...,\n",
      "         [-0.4547, -1.0829,  0.2791,  ...,  0.1373,  1.5556,  1.0158],\n",
      "         [-0.4300, -1.0510,  0.2568,  ...,  0.1483,  1.4694,  1.0773],\n",
      "         [-0.2378, -0.8169,  0.1524,  ..., -0.0137,  1.4654,  1.0418]],\n",
      "\n",
      "        [[-0.4480, -2.8871,  0.3038,  ..., -0.5651,  1.3829, -0.2322],\n",
      "         [-0.4406, -2.8972,  1.7901,  ..., -0.4700,  0.8599,  0.4803],\n",
      "         [-0.8096, -2.9283,  0.3350,  ...,  0.2419, -0.1405,  1.0861],\n",
      "         ...,\n",
      "         [-0.6285, -3.0844,  0.6006,  ..., -0.4291,  1.3811, -0.0838],\n",
      "         [-0.3523, -2.6729,  0.4811,  ..., -0.1552,  1.4205, -0.2057],\n",
      "         [-0.2379, -2.5885,  0.4031,  ..., -0.1162,  1.4093, -0.2794]],\n",
      "\n",
      "        [[ 0.0931, -1.2654,  0.3601,  ..., -0.1343, -0.3242,  0.3245],\n",
      "         [ 0.9106, -0.5721,  1.0712,  ...,  0.0395,  1.2324,  0.2556],\n",
      "         [-0.9110, -1.2078,  0.3017,  ...,  0.4645, -0.6817,  1.3741],\n",
      "         ...,\n",
      "         [ 0.5672, -1.1005,  0.7882,  ..., -0.4484, -0.4228,  0.3006],\n",
      "         [ 0.5654, -1.3521,  0.5897,  ..., -0.1971, -0.5153,  0.2948],\n",
      "         [ 0.6394, -0.9189,  0.7282,  ..., -0.6068, -0.0061,  0.2070]]],\n",
      "       grad_fn=<StackBackward0>) tensor([[[[-6.3258e-01, -7.9199e-02, -1.2565e-01,  ...,  1.0751e-01,\n",
      "            1.1020e-01,  1.2712e-01],\n",
      "          [-6.3258e-01, -7.9199e-02, -1.2565e-01,  ...,  1.0751e-01,\n",
      "            1.1020e-01,  1.2712e-01],\n",
      "          [-6.3258e-01, -7.9199e-02, -1.2565e-01,  ...,  1.0751e-01,\n",
      "            1.1020e-01,  1.2712e-01],\n",
      "          ...,\n",
      "          [-9.6955e-01,  4.6781e-02, -3.3052e-03,  ..., -3.5350e-02,\n",
      "           -1.7722e-01,  5.8860e-02],\n",
      "          [-9.7034e-01,  4.8419e-02, -5.0071e-03,  ..., -3.5876e-02,\n",
      "           -1.8528e-01,  5.8121e-02],\n",
      "          [-9.7473e-01,  5.4728e-02, -1.3822e-03,  ..., -3.8552e-02,\n",
      "           -1.8326e-01,  7.4313e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0675e+00,  2.9170e-01, -3.0831e-01,  ...,  6.8211e-02,\n",
      "           -2.9276e-03,  1.3854e-01],\n",
      "          [-1.0675e+00,  2.9170e-01, -3.0831e-01,  ...,  6.8211e-02,\n",
      "           -2.9274e-03,  1.3854e-01],\n",
      "          [-1.0675e+00,  2.9170e-01, -3.0831e-01,  ...,  6.8211e-02,\n",
      "           -2.9274e-03,  1.3854e-01],\n",
      "          ...,\n",
      "          [-1.0763e+00, -2.8679e-03,  8.7841e-02,  ..., -6.2013e-02,\n",
      "           -1.8676e-01,  1.6234e-01],\n",
      "          [-1.0724e+00, -9.8487e-04,  8.6535e-02,  ..., -6.2363e-02,\n",
      "           -1.9063e-01,  1.5550e-01],\n",
      "          [-1.0722e+00,  2.3829e-03,  8.4049e-02,  ..., -6.1824e-02,\n",
      "           -1.8800e-01,  1.5044e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3973e+00,  3.8828e-01, -1.9782e-01,  ...,  3.0533e-02,\n",
      "            9.9534e-02,  1.8086e-01],\n",
      "          [-1.3973e+00,  3.8828e-01, -1.9782e-01,  ...,  3.0533e-02,\n",
      "            9.9534e-02,  1.8086e-01],\n",
      "          [-1.3973e+00,  3.8828e-01, -1.9782e-01,  ...,  3.0533e-02,\n",
      "            9.9535e-02,  1.8086e-01],\n",
      "          ...,\n",
      "          [-1.2655e+00,  1.9558e-01,  3.0309e-02,  ..., -7.8082e-03,\n",
      "           -2.2599e-01, -1.2953e-02],\n",
      "          [-1.2616e+00,  1.9320e-01,  3.2392e-02,  ..., -6.8542e-03,\n",
      "           -2.2478e-01, -1.1169e-02],\n",
      "          [-1.2599e+00,  1.9418e-01,  3.2196e-02,  ..., -6.5883e-03,\n",
      "           -2.2223e-01, -1.0616e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.8609e-01, -6.7268e-02, -1.1256e-01,  ...,  1.0402e-01,\n",
      "            1.6788e-01,  2.5746e-01],\n",
      "          [-5.8609e-01, -6.7268e-02, -1.1256e-01,  ...,  1.0402e-01,\n",
      "            1.6788e-01,  2.5746e-01],\n",
      "          [-5.8609e-01, -6.7268e-02, -1.1256e-01,  ...,  1.0402e-01,\n",
      "            1.6788e-01,  2.5746e-01],\n",
      "          ...,\n",
      "          [-1.0769e+00,  8.8421e-02,  2.0720e-02,  ..., -4.3274e-03,\n",
      "           -1.6824e-01,  1.3246e-01],\n",
      "          [-9.8075e-01,  6.8975e-02,  2.3330e-02,  ..., -2.6843e-02,\n",
      "           -1.5511e-01,  9.8673e-02],\n",
      "          [-9.8420e-01,  7.5645e-02,  1.8411e-02,  ..., -2.5829e-02,\n",
      "           -1.6429e-01,  1.0596e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.5731e-01,  4.7407e-02, -1.0540e-01,  ...,  1.3809e-01,\n",
      "            1.5467e-01,  1.3481e-01],\n",
      "          [-7.5731e-01,  4.7407e-02, -1.0540e-01,  ...,  1.3809e-01,\n",
      "            1.5467e-01,  1.3481e-01],\n",
      "          [-7.5731e-01,  4.7407e-02, -1.0540e-01,  ...,  1.3809e-01,\n",
      "            1.5467e-01,  1.3481e-01],\n",
      "          ...,\n",
      "          [-1.0087e+00,  6.3411e-02,  1.8731e-02,  ..., -5.2092e-02,\n",
      "           -1.7008e-01,  1.3601e-01],\n",
      "          [-9.9432e-01,  6.2777e-02,  1.6297e-02,  ..., -4.8103e-02,\n",
      "           -1.7557e-01,  1.2199e-01],\n",
      "          [-1.0031e+00,  8.0784e-02,  7.2218e-03,  ..., -4.4462e-02,\n",
      "           -1.6660e-01,  1.1910e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0007e+00,  1.5010e-01, -1.8092e-01,  ...,  4.0598e-02,\n",
      "            9.1297e-02,  1.5055e-01],\n",
      "          [-1.0007e+00,  1.5010e-01, -1.8092e-01,  ...,  4.0598e-02,\n",
      "            9.1296e-02,  1.5055e-01],\n",
      "          [-1.0007e+00,  1.5010e-01, -1.8092e-01,  ...,  4.0598e-02,\n",
      "            9.1296e-02,  1.5055e-01],\n",
      "          ...,\n",
      "          [-1.1814e+00,  7.1656e-02,  1.5078e-01,  ..., -4.8994e-03,\n",
      "           -5.8648e-02,  2.1826e-01],\n",
      "          [-1.0978e+00,  3.1806e-02,  1.3595e-01,  ..., -3.0662e-02,\n",
      "           -6.6721e-02,  1.4799e-01],\n",
      "          [-1.0914e+00,  2.3365e-02,  1.3611e-01,  ..., -3.8778e-02,\n",
      "           -7.4594e-02,  1.3978e-01]]]]) tensor([ 2,  1,  1,  4,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         0,  1,  1,  1,  3,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  3,  7,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 12,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1])\n",
      "tensor([[[ 0.8162, -1.5875,  0.0877,  ..., -0.9933,  0.1292, -0.4323],\n",
      "         [ 0.9566, -1.3268, -0.0064,  ..., -0.5736,  0.4747, -0.5004],\n",
      "         [ 0.0987, -0.6701, -0.4790,  ..., -0.2576, -0.1767, -0.6532],\n",
      "         ...,\n",
      "         [ 1.1061, -1.0845,  0.3909,  ..., -0.9477,  0.0991, -0.2683],\n",
      "         [ 0.8696, -1.3936,  0.3717,  ..., -1.0420,  0.0887, -0.4337],\n",
      "         [ 0.8122, -1.4203,  0.3139,  ..., -1.1294,  0.0962, -0.4573]],\n",
      "\n",
      "        [[ 0.4227, -1.6638,  0.7593,  ..., -0.3170, -0.3830,  1.4653],\n",
      "         [ 1.6121, -0.7297,  0.5726,  ...,  0.1991, -0.0735,  1.1544],\n",
      "         [ 1.1614, -2.2363,  0.8983,  ...,  0.2368,  0.7375,  0.5795],\n",
      "         ...,\n",
      "         [ 0.6660, -1.5632,  1.0086,  ..., -0.4743,  0.0753,  1.0004],\n",
      "         [ 0.6703, -1.3883,  0.9084,  ..., -0.5266,  0.1244,  0.9575],\n",
      "         [ 0.6869, -1.3871,  0.9895,  ..., -0.3139,  0.2377,  1.0132]],\n",
      "\n",
      "        [[ 0.5146, -0.2627,  1.9151,  ..., -1.1599,  0.3243, -0.5262],\n",
      "         [ 0.6351, -0.3053,  1.3011,  ..., -0.4947, -1.1692, -0.2872],\n",
      "         [ 1.0379,  0.4164,  1.4331,  ..., -0.8081, -0.1415, -0.0052],\n",
      "         ...,\n",
      "         [ 0.6031, -0.5510,  1.9115,  ..., -0.8758,  0.7608, -1.0285],\n",
      "         [ 0.7264, -0.2688,  1.6584,  ..., -1.2188,  0.7460, -0.9350],\n",
      "         [ 0.8157, -0.2218,  1.7845,  ..., -1.0700,  0.5300, -0.8851]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4959,  0.4408,  0.9094,  ...,  0.3316,  0.6567,  0.8362],\n",
      "         [-0.5162,  0.2441,  1.0385,  ...,  0.3066,  1.1400,  0.4593],\n",
      "         [ 0.4228,  0.3542,  1.0290,  ...,  0.1759,  1.3566,  0.5058],\n",
      "         ...,\n",
      "         [ 0.5369,  0.3656,  1.0379,  ...,  0.3731,  0.9914,  0.5829],\n",
      "         [ 0.6451,  0.1426,  0.8905,  ...,  0.2699,  1.1480,  0.5691],\n",
      "         [ 0.6913,  0.1587,  0.8453,  ...,  0.3015,  0.9349,  0.6659]],\n",
      "\n",
      "        [[ 0.5605, -0.9090,  1.1739,  ...,  1.3210,  1.0669,  0.2731],\n",
      "         [-1.1097, -1.3746,  0.4415,  ...,  1.3536,  0.6529,  0.9658],\n",
      "         [ 0.1641, -1.7170,  1.0959,  ...,  1.0971,  0.9295, -0.3291],\n",
      "         ...,\n",
      "         [ 0.8314, -1.2206,  0.7559,  ...,  0.6940,  0.5156, -0.2972],\n",
      "         [ 0.7714, -1.3217,  0.7772,  ...,  0.4963,  0.7475, -0.1817],\n",
      "         [ 0.7463, -1.2899,  0.8810,  ...,  0.9204,  1.0169, -0.2741]],\n",
      "\n",
      "        [[ 0.4715, -1.4781,  0.3342,  ...,  0.0221, -0.0788, -0.0792],\n",
      "         [ 0.8814, -1.3804,  0.7441,  ...,  0.0881,  0.6043, -1.0305],\n",
      "         [ 0.7165, -0.7782,  0.2789,  ...,  0.4963, -0.0568, -0.7571],\n",
      "         ...,\n",
      "         [ 0.7103, -1.3304,  0.3246,  ..., -0.0551,  0.2327, -0.2894],\n",
      "         [ 0.6355, -0.8085,  0.0542,  ...,  0.2977,  0.2736, -0.1006],\n",
      "         [ 0.8767, -1.2475,  0.3164,  ...,  0.2403,  0.3007, -0.3326]]],\n",
      "       grad_fn=<StackBackward0>) tensor([[[[-1.0375e+00,  3.4067e-01, -3.1397e-01,  ...,  3.0840e-02,\n",
      "            2.1698e-02,  1.7630e-01],\n",
      "          [-1.0375e+00,  3.4067e-01, -3.1397e-01,  ...,  3.0840e-02,\n",
      "            2.1698e-02,  1.7630e-01],\n",
      "          [-1.0375e+00,  3.4067e-01, -3.1397e-01,  ...,  3.0840e-02,\n",
      "            2.1698e-02,  1.7630e-01],\n",
      "          ...,\n",
      "          [-1.0585e+00, -1.7164e-02,  1.0147e-02,  ..., -4.1827e-02,\n",
      "           -1.4685e-01,  1.3192e-01],\n",
      "          [-1.0510e+00, -1.3113e-02,  3.6631e-03,  ..., -4.2438e-02,\n",
      "           -1.3819e-01,  1.2318e-01],\n",
      "          [-1.0592e+00, -5.5012e-03, -6.7609e-03,  ..., -4.4916e-02,\n",
      "           -1.3310e-01,  1.1700e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0141e+00,  1.5214e-01, -2.5156e-01,  ...,  5.1130e-02,\n",
      "            6.9246e-02,  1.4125e-01],\n",
      "          [-1.0141e+00,  1.5214e-01, -2.5156e-01,  ...,  5.1130e-02,\n",
      "            6.9247e-02,  1.4124e-01],\n",
      "          [-1.0141e+00,  1.5214e-01, -2.5156e-01,  ...,  5.1130e-02,\n",
      "            6.9247e-02,  1.4125e-01],\n",
      "          ...,\n",
      "          [-1.0869e+00, -3.1193e-02,  4.7612e-02,  ..., -3.6772e-02,\n",
      "           -1.5353e-01,  7.8085e-02],\n",
      "          [-1.0711e+00, -3.0308e-02,  5.4867e-02,  ..., -4.0102e-02,\n",
      "           -1.7159e-01,  6.7220e-02],\n",
      "          [-1.0667e+00,  9.3234e-04,  5.1977e-02,  ..., -4.2825e-02,\n",
      "           -1.7064e-01,  7.7495e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.6616e-01, -1.5611e-01, -1.8475e-01,  ...,  1.4327e-01,\n",
      "            1.6195e-01,  1.2586e-01],\n",
      "          [-7.6616e-01, -1.5611e-01, -1.8475e-01,  ...,  1.4327e-01,\n",
      "            1.6195e-01,  1.2586e-01],\n",
      "          [-7.6616e-01, -1.5611e-01, -1.8475e-01,  ...,  1.4327e-01,\n",
      "            1.6195e-01,  1.2586e-01],\n",
      "          ...,\n",
      "          [-9.8958e-01,  1.1146e-03, -6.0774e-02,  ..., -4.7398e-03,\n",
      "           -1.5297e-01,  8.3811e-02],\n",
      "          [-9.8312e-01,  2.2288e-06, -5.8957e-02,  ..., -8.5208e-03,\n",
      "           -1.6496e-01,  7.9744e-02],\n",
      "          [-9.5648e-01, -2.0171e-03, -5.3401e-02,  ..., -1.2063e-02,\n",
      "           -1.7775e-01,  6.3098e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0217e+00,  1.5461e-01, -2.6270e-01,  ...,  4.7993e-02,\n",
      "            1.0480e-02,  1.4520e-01],\n",
      "          [-1.0217e+00,  1.5461e-01, -2.6270e-01,  ...,  4.7993e-02,\n",
      "            1.0479e-02,  1.4520e-01],\n",
      "          [-1.0217e+00,  1.5461e-01, -2.6270e-01,  ...,  4.7993e-02,\n",
      "            1.0479e-02,  1.4520e-01],\n",
      "          ...,\n",
      "          [-1.1152e+00,  4.8378e-02,  7.8334e-03,  ..., -4.1093e-02,\n",
      "           -1.0661e-01,  1.2223e-01],\n",
      "          [-1.1153e+00,  4.4864e-02,  9.1109e-03,  ..., -4.1430e-02,\n",
      "           -1.1277e-01,  1.1999e-01],\n",
      "          [-1.1052e+00,  4.1100e-02,  6.8014e-03,  ..., -4.3082e-02,\n",
      "           -1.2534e-01,  1.1058e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.4461e-01,  2.1319e-01, -1.7859e-01,  ...,  1.1826e-01,\n",
      "            1.0027e-01,  9.9591e-02],\n",
      "          [-8.4461e-01,  2.1319e-01, -1.7859e-01,  ...,  1.1826e-01,\n",
      "            1.0027e-01,  9.9591e-02],\n",
      "          [-8.4461e-01,  2.1319e-01, -1.7859e-01,  ...,  1.1826e-01,\n",
      "            1.0027e-01,  9.9591e-02],\n",
      "          ...,\n",
      "          [-9.6342e-01,  1.0817e-01,  1.2704e-02,  ..., -7.9526e-02,\n",
      "           -1.7958e-01,  1.0585e-01],\n",
      "          [-9.6872e-01,  1.0943e-01,  1.1963e-02,  ..., -8.0051e-02,\n",
      "           -1.8521e-01,  1.0680e-01],\n",
      "          [-9.6920e-01,  1.1709e-01,  1.3176e-02,  ..., -7.9209e-02,\n",
      "           -1.8769e-01,  1.1500e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1679e+00,  2.0732e-01, -2.9651e-01,  ...,  4.3459e-02,\n",
      "            4.4618e-02,  2.2074e-01],\n",
      "          [-1.1679e+00,  2.0732e-01, -2.9651e-01,  ...,  4.3459e-02,\n",
      "            4.4618e-02,  2.2074e-01],\n",
      "          [-1.1679e+00,  2.0732e-01, -2.9651e-01,  ...,  4.3459e-02,\n",
      "            4.4618e-02,  2.2074e-01],\n",
      "          ...,\n",
      "          [-1.1246e+00,  2.7537e-02, -7.3080e-03,  ..., -8.2136e-02,\n",
      "           -1.1195e-01,  1.6294e-01],\n",
      "          [-1.1247e+00,  2.8053e-02,  2.9378e-03,  ..., -8.7136e-02,\n",
      "           -1.0095e-01,  1.5664e-01],\n",
      "          [-1.1349e+00,  4.0192e-02, -5.8202e-04,  ..., -8.3812e-02,\n",
      "           -1.1961e-01,  1.5661e-01]]]]) tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 6, 1, 0, 1, 1, 1, 1, 1, 1])\n",
      "tensor([[[ 1.1436e+00, -1.6729e+00,  1.1835e+00,  ..., -7.5214e-01,\n",
      "           8.7627e-01, -5.2303e-01],\n",
      "         [ 1.0536e+00, -2.3247e+00,  9.8184e-01,  ..., -5.4639e-01,\n",
      "           1.5141e+00, -9.5445e-01],\n",
      "         [ 3.9996e-01, -1.9826e+00,  1.0672e+00,  ..., -3.3578e-01,\n",
      "           1.2944e+00, -7.7763e-01],\n",
      "         ...,\n",
      "         [ 8.3010e-01, -1.5482e+00,  1.1648e+00,  ..., -6.3172e-01,\n",
      "           9.9484e-01, -5.3677e-01],\n",
      "         [ 6.9867e-01, -1.5363e+00,  1.0425e+00,  ..., -6.9095e-01,\n",
      "           9.2429e-01, -2.6813e-01],\n",
      "         [ 6.5856e-01, -1.5711e+00,  9.8570e-01,  ..., -6.9395e-01,\n",
      "           8.8595e-01, -2.8697e-01]],\n",
      "\n",
      "        [[ 5.2564e-01, -1.5321e+00,  1.6545e+00,  ...,  2.9072e-01,\n",
      "           7.2635e-01, -1.4192e-01],\n",
      "         [-3.7706e-01, -2.3219e+00,  1.2927e+00,  ...,  2.3196e-01,\n",
      "           1.1669e+00, -6.0201e-01],\n",
      "         [-6.8843e-01, -1.4732e+00,  1.4810e+00,  ...,  9.8414e-01,\n",
      "           9.7796e-01,  1.0043e+00],\n",
      "         ...,\n",
      "         [ 3.4437e-01, -1.6148e+00,  1.8001e+00,  ...,  1.7296e-01,\n",
      "           6.0205e-01, -3.3596e-01],\n",
      "         [ 1.6478e-01, -1.5511e+00,  1.6527e+00,  ...,  2.4865e-01,\n",
      "           8.9428e-01, -3.5514e-01],\n",
      "         [ 1.2520e-01, -1.3474e+00,  1.7529e+00,  ...,  2.1996e-01,\n",
      "           1.0096e+00, -3.5354e-01]],\n",
      "\n",
      "        [[ 4.3186e-02,  9.6191e-02,  1.3772e+00,  ..., -4.4789e-01,\n",
      "          -6.1793e-01,  1.0109e+00],\n",
      "         [-4.5072e-01, -1.7705e-01,  1.5158e+00,  ..., -5.2237e-01,\n",
      "           4.3308e-01,  4.5526e-01],\n",
      "         [-9.9902e-01, -2.4559e-01,  8.9681e-01,  ...,  5.3536e-01,\n",
      "          -1.6150e-01,  1.7397e+00],\n",
      "         ...,\n",
      "         [ 6.3280e-02, -5.9579e-03,  1.6211e+00,  ..., -7.0433e-01,\n",
      "          -5.5436e-01,  5.2536e-01],\n",
      "         [-6.7986e-02, -1.7880e-02,  1.3251e+00,  ..., -8.7288e-01,\n",
      "          -2.7521e-01,  5.8548e-01],\n",
      "         [-2.1222e-01, -1.3846e-03,  1.2426e+00,  ..., -6.8036e-01,\n",
      "           1.4129e-01,  5.7113e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0134e+00, -2.1441e+00,  1.0689e-02,  ..., -1.3956e-01,\n",
      "          -5.1543e-01,  7.1401e-01],\n",
      "         [-4.9409e-01, -1.3135e+00,  9.1167e-01,  ..., -1.0601e-01,\n",
      "           5.6681e-01,  3.3714e-01],\n",
      "         [-1.0767e+00, -1.3687e+00,  1.3918e-01,  ...,  4.7067e-01,\n",
      "          -2.8948e-01,  1.4849e+00],\n",
      "         ...,\n",
      "         [-4.4310e-01, -2.4068e+00,  4.8538e-01,  ...,  3.4488e-01,\n",
      "           1.6398e-01, -3.6006e-02],\n",
      "         [-3.0793e-01, -2.0918e+00,  4.0603e-01,  ..., -1.0410e-01,\n",
      "          -3.9743e-01,  1.7328e-01],\n",
      "         [-7.1591e-01, -1.8988e+00,  5.4453e-01,  ..., -2.8757e-01,\n",
      "          -4.1239e-01,  1.2774e-01]],\n",
      "\n",
      "        [[-9.4794e-01, -5.3421e-01, -9.8274e-02,  ..., -8.3726e-01,\n",
      "          -2.6027e-01,  1.1846e+00],\n",
      "         [-1.1052e+00, -1.4810e-01,  3.4869e-02,  ..., -4.8343e-01,\n",
      "           6.9225e-01,  3.6492e-01],\n",
      "         [-2.0207e+00, -5.4117e-01,  5.6673e-01,  ...,  6.5146e-01,\n",
      "           6.0747e-02,  1.4392e+00],\n",
      "         ...,\n",
      "         [-5.1704e-01, -8.1122e-01,  1.4676e-01,  ..., -9.6916e-01,\n",
      "           3.5526e-01,  1.0102e+00],\n",
      "         [-4.1700e-01, -9.7546e-01,  2.0907e-01,  ..., -1.1086e+00,\n",
      "           1.1481e-01,  1.0855e+00],\n",
      "         [-4.8446e-01, -9.8344e-01,  6.1892e-02,  ..., -1.1704e+00,\n",
      "           2.6411e-01,  1.0591e+00]],\n",
      "\n",
      "        [[ 6.5468e-01, -7.7564e-01,  1.7037e+00,  ..., -4.5229e-01,\n",
      "           1.0402e+00,  1.9837e+00],\n",
      "         [ 3.9321e-01, -6.3255e-01,  1.6731e+00,  ...,  1.9011e-01,\n",
      "           8.9991e-01,  1.0497e+00],\n",
      "         [ 1.2046e+00, -2.7775e-01,  1.9291e+00,  ..., -3.1766e-01,\n",
      "           2.4546e+00,  8.3681e-01],\n",
      "         ...,\n",
      "         [ 6.5188e-01, -8.4548e-01,  1.8775e+00,  ..., -4.7553e-01,\n",
      "           1.4207e+00,  1.6134e+00],\n",
      "         [ 7.4767e-01, -3.4755e-01,  1.7625e+00,  ..., -4.2053e-01,\n",
      "           1.4966e+00,  1.2315e+00],\n",
      "         [ 4.6770e-01, -5.3848e-01,  1.7663e+00,  ..., -3.0871e-01,\n",
      "           9.7039e-01,  1.4908e+00]]], grad_fn=<StackBackward0>) tensor([[[[-6.4289e-01, -1.1852e-01, -1.2224e-01,  ...,  1.2362e-01,\n",
      "            1.5997e-01,  2.4189e-01],\n",
      "          [-6.4289e-01, -1.1852e-01, -1.2224e-01,  ...,  1.2362e-01,\n",
      "            1.5997e-01,  2.4189e-01],\n",
      "          [-6.4289e-01, -1.1852e-01, -1.2224e-01,  ...,  1.2362e-01,\n",
      "            1.5997e-01,  2.4189e-01],\n",
      "          ...,\n",
      "          [-9.6739e-01, -2.3870e-02,  2.5926e-02,  ..., -4.4727e-02,\n",
      "           -1.3030e-01,  1.3283e-01],\n",
      "          [-8.7463e-01, -1.0263e-02,  3.2308e-04,  ..., -4.3371e-02,\n",
      "           -1.4144e-01,  8.4054e-02],\n",
      "          [-8.6281e-01, -8.1434e-03, -4.5045e-03,  ..., -4.2036e-02,\n",
      "           -1.4713e-01,  7.5872e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.4943e-01,  8.1450e-02, -2.5748e-01,  ...,  6.7100e-02,\n",
      "            7.1804e-02,  1.7705e-01],\n",
      "          [-8.4943e-01,  8.1450e-02, -2.5748e-01,  ...,  6.7100e-02,\n",
      "            7.1803e-02,  1.7705e-01],\n",
      "          [-8.4943e-01,  8.1451e-02, -2.5748e-01,  ...,  6.7100e-02,\n",
      "            7.1804e-02,  1.7705e-01],\n",
      "          ...,\n",
      "          [-1.1604e+00,  4.1319e-02, -3.7582e-02,  ..., -1.4838e-01,\n",
      "           -2.0524e-01,  1.3862e-02],\n",
      "          [-1.1583e+00,  4.0286e-02, -3.9145e-02,  ..., -1.4774e-01,\n",
      "           -2.0179e-01,  1.3353e-02],\n",
      "          [-1.1588e+00,  4.0036e-02, -4.2816e-02,  ..., -1.4832e-01,\n",
      "           -2.0297e-01,  1.1854e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.6629e-01, -3.9599e-02, -9.3777e-02,  ...,  1.8782e-01,\n",
      "            4.5803e-02,  7.8955e-02],\n",
      "          [-9.6629e-01, -3.9599e-02, -9.3777e-02,  ...,  1.8782e-01,\n",
      "            4.5803e-02,  7.8955e-02],\n",
      "          [-9.6629e-01, -3.9599e-02, -9.3777e-02,  ...,  1.8782e-01,\n",
      "            4.5803e-02,  7.8955e-02],\n",
      "          ...,\n",
      "          [-1.1922e+00,  1.5593e-01,  1.3523e-02,  ..., -5.9809e-02,\n",
      "           -1.2705e-01,  1.2626e-01],\n",
      "          [-1.1883e+00,  1.5401e-01,  6.5367e-03,  ..., -5.6517e-02,\n",
      "           -1.2913e-01,  1.1483e-01],\n",
      "          [-1.1887e+00,  1.5045e-01, -8.4545e-05,  ..., -5.5557e-02,\n",
      "           -1.3565e-01,  1.1086e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.6619e-01,  6.1452e-02, -1.3906e-01,  ...,  1.5558e-01,\n",
      "            1.4028e-01,  1.7556e-01],\n",
      "          [-6.6619e-01,  6.1452e-02, -1.3906e-01,  ...,  1.5558e-01,\n",
      "            1.4028e-01,  1.7556e-01],\n",
      "          [-6.6619e-01,  6.1452e-02, -1.3906e-01,  ...,  1.5558e-01,\n",
      "            1.4028e-01,  1.7556e-01],\n",
      "          ...,\n",
      "          [-1.2332e+00,  3.2961e-01,  3.7344e-02,  ..., -3.1714e-02,\n",
      "           -8.2559e-02,  1.8302e-01],\n",
      "          [-1.1013e+00,  2.4824e-01,  2.2070e-02,  ..., -2.0929e-02,\n",
      "           -7.0781e-02,  1.7113e-01],\n",
      "          [-1.0757e+00,  2.2713e-01,  1.8511e-02,  ..., -1.6658e-02,\n",
      "           -6.8379e-02,  1.5990e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2401e+00,  3.2263e-01, -3.3512e-01,  ...,  9.2731e-02,\n",
      "           -5.6987e-02,  9.0467e-02],\n",
      "          [-1.2401e+00,  3.2263e-01, -3.3512e-01,  ...,  9.2732e-02,\n",
      "           -5.6987e-02,  9.0468e-02],\n",
      "          [-1.2401e+00,  3.2263e-01, -3.3512e-01,  ...,  9.2732e-02,\n",
      "           -5.6988e-02,  9.0467e-02],\n",
      "          ...,\n",
      "          [-9.9794e-01,  1.5769e-02,  2.2096e-03,  ..., -5.8321e-02,\n",
      "           -2.1248e-01,  1.2267e-01],\n",
      "          [-9.9540e-01,  1.7355e-02,  2.8731e-03,  ..., -5.8023e-02,\n",
      "           -2.0945e-01,  1.2195e-01],\n",
      "          [-9.9571e-01,  2.1243e-02,  1.7721e-03,  ..., -5.8232e-02,\n",
      "           -2.0422e-01,  1.2067e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1838e+00,  1.9972e-01, -1.9959e-01,  ...,  6.2421e-02,\n",
      "            3.4860e-02,  1.3325e-01],\n",
      "          [-1.1838e+00,  1.9972e-01, -1.9959e-01,  ...,  6.2421e-02,\n",
      "            3.4860e-02,  1.3325e-01],\n",
      "          [-1.1838e+00,  1.9972e-01, -1.9959e-01,  ...,  6.2421e-02,\n",
      "            3.4860e-02,  1.3325e-01],\n",
      "          ...,\n",
      "          [-1.2331e+00,  1.7223e-01, -3.5087e-03,  ..., -6.3087e-02,\n",
      "           -2.1859e-01, -3.0287e-02],\n",
      "          [-1.2302e+00,  1.7055e-01, -2.5077e-03,  ..., -6.1435e-02,\n",
      "           -2.1622e-01, -3.0067e-02],\n",
      "          [-1.2286e+00,  1.6928e-01, -1.5435e-03,  ..., -6.2428e-02,\n",
      "           -2.1572e-01, -3.3833e-02]]]]) tensor([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch, (X_txt, X_wav, X_temp, X_eda, \n",
    "                        label_emotion, label_emotion_ext, label_arousal, label_valence) in list(enumerate(test_dataloader))[:3]:\n",
    "     print(X_txt,X_wav,label_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n",
      "angry;neutral\n"
     ]
    }
   ],
   "source": [
    "probs = model_tf_mixer(X_txt.to(device), X_wav.to(device))\n",
    "for i in torch.argmax(probs, dim=1):\n",
    "    print(decode_dict[int(i)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>eda</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sess01_script01_User002M_001</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[2.856493, 2.788578, 2.678377, 2.652749, 2.645...</td>\n",
       "      <td>[34.81, 34.81, 34.81, 34.79, 34.79, 34.79, 34....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sess01_script01_User002M_002</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[2.647035, 2.653442, 2.631658, 2.614999, 2.623...</td>\n",
       "      <td>[34.79, 34.79, 34.79, 34.77, 34.77, 34.77, 34....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sess01_script01_User002M_003</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3</td>\n",
       "      <td>[2.896217, 2.975664, 3.02692, 3.071769, 3.0922...</td>\n",
       "      <td>[34.75, 34.75, 34.75, 34.75, 34.79, 34.79, 34....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     segment_id  emotion valence arousal  \\\n",
       "0  Sess01_script01_User002M_001  neutral     3.4     2.9   \n",
       "1  Sess01_script01_User002M_002  neutral     3.1     2.9   \n",
       "2  Sess01_script01_User002M_003  neutral     3.1       3   \n",
       "\n",
       "                                                 eda  \\\n",
       "0  [2.856493, 2.788578, 2.678377, 2.652749, 2.645...   \n",
       "1  [2.647035, 2.653442, 2.631658, 2.614999, 2.623...   \n",
       "2  [2.896217, 2.975664, 3.02692, 3.071769, 3.0922...   \n",
       "\n",
       "                                                temp  \n",
       "0  [34.81, 34.81, 34.81, 34.79, 34.79, 34.79, 34....  \n",
       "1  [34.79, 34.79, 34.79, 34.77, 34.77, 34.77, 34....  \n",
       "2  [34.75, 34.75, 34.75, 34.75, 34.79, 34.79, 34....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "# data load\n",
    "\n",
    "with open('./data/ts_data.pkl', 'rb') as f:\n",
    "    ts_dataset = pickle.load(f)\n",
    "    \n",
    "ts_dataset[1].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 10, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 36, 37, 38, 40] \n",
      " [9, 11, 13, 16, 29, 33, 35, 39]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# TS데이터가 없는 세션 drop\n",
    "del ts_dataset[12]\n",
    "del ts_dataset[17] \n",
    "\n",
    "\n",
    "ts_session_index = list(range(1,40+1))\n",
    "# ts data가 없는 session 추출대상 index에서 제외\n",
    "ts_session_index.remove(12) \n",
    "ts_session_index.remove(17)\n",
    "\n",
    "# 80% random하게 train으로 추출, 20%를 테스트로 추출\n",
    "ts_session_index_train = random.sample(ts_session_index, k = int(38*.8))\n",
    "ts_session_index_train = sorted(ts_session_index_train)\n",
    "ts_session_index_test = [i for i in ts_session_index if i not in ts_session_index_train]\n",
    "ts_session_index_test = sorted(ts_session_index_test)\n",
    "print(ts_session_index_train, '\\n',ts_session_index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>eda</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sess01_script01_User002M_001</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[2.856493, 2.788578, 2.678377, 2.652749, 2.645...</td>\n",
       "      <td>[34.81, 34.81, 34.81, 34.79, 34.79, 34.79, 34....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sess01_script01_User002M_002</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[2.647035, 2.653442, 2.631658, 2.614999, 2.623...</td>\n",
       "      <td>[34.79, 34.79, 34.79, 34.77, 34.77, 34.77, 34....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sess01_script01_User002M_003</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3</td>\n",
       "      <td>[2.896217, 2.975664, 3.02692, 3.071769, 3.0922...</td>\n",
       "      <td>[34.75, 34.75, 34.75, 34.75, 34.79, 34.79, 34....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sess01_script01_User002M_004</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>[3.689019, 3.692863, 3.659546, 3.409672, 3.123...</td>\n",
       "      <td>[34.77, 34.77, 34.77, 34.77, 34.77, 34.77, 34....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sess01_script01_User001F_001</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>[4.412055, 4.536246, 4.630991, 4.669401, 4.661...</td>\n",
       "      <td>[34.55, 34.55, 34.55, 34.55, 34.55, 34.55, 34....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     segment_id  emotion valence arousal  \\\n",
       "0  Sess01_script01_User002M_001  neutral     3.4     2.9   \n",
       "1  Sess01_script01_User002M_002  neutral     3.1     2.9   \n",
       "2  Sess01_script01_User002M_003  neutral     3.1       3   \n",
       "3  Sess01_script01_User002M_004  neutral     3.7     3.1   \n",
       "4  Sess01_script01_User001F_001  neutral     3.8     2.8   \n",
       "\n",
       "                                                 eda  \\\n",
       "0  [2.856493, 2.788578, 2.678377, 2.652749, 2.645...   \n",
       "1  [2.647035, 2.653442, 2.631658, 2.614999, 2.623...   \n",
       "2  [2.896217, 2.975664, 3.02692, 3.071769, 3.0922...   \n",
       "3  [3.689019, 3.692863, 3.659546, 3.409672, 3.123...   \n",
       "4  [4.412055, 4.536246, 4.630991, 4.669401, 4.661...   \n",
       "\n",
       "                                                temp  \n",
       "0  [34.81, 34.81, 34.81, 34.79, 34.79, 34.79, 34....  \n",
       "1  [34.79, 34.79, 34.79, 34.77, 34.77, 34.77, 34....  \n",
       "2  [34.75, 34.75, 34.75, 34.75, 34.79, 34.79, 34....  \n",
       "3  [34.77, 34.77, 34.77, 34.77, 34.77, 34.77, 34....  \n",
       "4  [34.55, 34.55, 34.55, 34.55, 34.55, 34.55, 34....  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_dataset[1].head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bdc1fd12ca460d5768d71e9df3d9063ef832ce64a62e55a1a523c8c99752868e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
